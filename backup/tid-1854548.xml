<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>【终于等到了】 基于深度学习的漫画去字工具</title>
    <link>https://bbs.saraba1st.com/2b/</link>
    <description>【终于等到了】 基于深度学习的漫画去字工具</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 09 Jul 2020 18:12:36 +0000</lastBuildDate>
    <item>
      <title>【终于等到了】 基于深度学习的漫画去字工具[0-50]</title>
      <link>https://bbs.saraba1st.com/2b/thread-1854548-1-1.html</link>
      <description>【终于等到了】 基于深度学习的漫画去字工具&#13;
 本帖最后由 whzfjk 于 2019-8-19 23:15 编辑 

韩国人的项目：https://github.com/KUR-creative/SickZil-Machine
&#13;
拿漫画原图和对应的纯文字版本，用 U-Net 训练出图像分割模型，制作掩膜，再拿掩膜用 deepfill2 给原图去字，主要是针对拟声词的吧，我看气泡里反而去得不是很干净。
&#13;
最早的 commit 才到 7 月份，挺新鲜的一个项目。
&#13;
以前突发奇想的时候找到过另外一个项目：https://github.com/Kocarus/Manga-Translator-TesseractOCR
&#13;
先用 opencv 定位气泡，然后再对气泡里的文字用 tesseract 进行 OCR，送给谷歌在线翻译，再覆盖到原图上。感觉以此为后端做一个气泡级无图像操作嵌字的傻瓜前端还是很不错的。不知道现在的汉化组大手子都是怎么提高生产率的？
&#13;
不过 tesseract 识别率感觉还不是很好，有道、腾讯的那些收费 OCR API 试过一次，感觉十分强大，不愧是在线+收费的。</description>
      <content:encoded><![CDATA[<p><b>whzfjk: </b><br>
<span>【终于等到了】 基于深度学习的漫画去字工具</span><br>
<span> 本帖最后由 whzfjk 于 2019-8-19 23:15 编辑 </span><br>
<span>韩国人的项目：https://github.com/KUR-creative/SickZil-Machine</span><br>
<span>拿漫画原图和对应的纯文字版本，用 U-Net 训练出图像分割模型，制作掩膜，再拿掩膜用 deepfill2 给原图去字，主要是针对拟声词的吧，我看气泡里反而去得不是很干净。</span><br>
<span>最早的 commit 才到 7 月份，挺新鲜的一个项目。</span><br>
<span>以前突发奇想的时候找到过另外一个项目：https://github.com/Kocarus/Manga-Translator-TesseractOCR</span><br>
<span>先用 opencv 定位气泡，然后再对气泡里的文字用 tesseract 进行 OCR，送给谷歌在线翻译，再覆盖到原图上。感觉以此为后端做一个气泡级无图像操作嵌字的傻瓜前端还是很不错的。不知道现在的汉化组大手子都是怎么提高生产率的？</span><br>
<span>不过 tesseract 识别率感觉还不是很好，有道、腾讯的那些收费 OCR API 试过一次，感觉十分强大，不愧是在线+收费的。</span><br>
</p><p><b>白房子: </b><br>
<span>灵魂三问：能用吗？好用吗？怎么用？</span><br>
</p><p><b>whzfjk: </b><br>
<span>看了一下对背景的损害还是有一点的，不如人工去字（</span><br>
</p><p><b>烦恼寺: </b><br>
<span>下一步是不是改把文字翻译下，然后P上去？</span><br>
</p><p><b>whzfjk: </b><br>
<span>烦恼寺 发表于 2019-8-19 22:54</span><br>
<span>下一步是不是改把文字翻译下，然后P上去？</span><br>
<span>我提的第二个项目就是干这事的</span><br>
</p><p><b>zhDesire: </b><br>
<span>看了一下项目，蛮不错的，就是有的原图有点损害</span><br>
<span>另外觉得主楼里mask翻译成蒙版比掩码更合适</span><br>
</p><p><b>whzfjk: </b><br>
<span>zhDesire 发表于 2019-8-19 23:07</span><br>
<span>看了一下项目，蛮不错的，就是有的原图有点损害</span><br>
<span>另外觉得主楼里mask翻译成蒙版比掩码更合适 ...</span><br>
<span>搜了一下，图像语境叫掩膜的好像比较多</span><br>
</p><p><b>若荼泱: </b><br>
<span>早上看到了懒得开楼，就借楼说一下。有个github repo叫anime4k说是能把动画高清成4k(2160p)(可能有偏差)……歪一下，对不起。和madvr有点像</span><br>
</p><p><b>carroy: </b><br>
<span>有没有网点转灰度</span><br>
<span>或者自动扣图</span><br>
</p><p><b>shadow001: </b><br>
<span>甚麼時候有把硬字幕自動轉成外掛字幕的工具</span><br>
</p><p><b>临界点: </b><br>
<span>若荼泱 发表于 2019-8-19 23:25</span><br>
<span>早上看到了懒得开楼，就借楼说一下。有个github repo叫anime4k说是能把动画高清成4k(2160p)(可能有偏差)… ...</span><br>
<span>类似的技术都用了好几年了吧当初**字幕组是运用的最积极的 因为很多**只出DVD版表番字幕组倒是很少见太可惜了</span><br>
</p><p><b>pf67: </b><br>
<span> 本帖最后由 pf67 于 2019-8-20 02:36 编辑 </span><br>
<span>我就想问只是提取mask为啥会损害被背景画质的。。。deepfill的锅？</span><br>
<span>至于第二个项目，既然精确定位了，orc不如自己做。</span><br>
</p><p><b>有口皆悲: </b><br>
<span>临界点 发表于 2019-8-20 00:47</span><br>
<span>类似的技术都用了好几年了吧当初**字幕组是运用的最积极的 因为很多**只出DVD版表番字幕组倒是很少见 ...</span><br>
<span>这次这个宣称3ms完成转换，真是这样的话可以实时。</span><br>
</p><p><b>由莉亚100式: </b><br>
<span>如果能成熟的话倒是不错，减少劳动量</span><br>
</p><p><b>whzfjk: </b><br>
<span>pf67 发表于 2019-8-20 02:28</span><br>
<span>我就想问只是提取mask为啥会损害被背景画质的。。。deepfill的锅？</span><br>
<span>至于第二个项目，既然精确定位了，orc不 ...</span><br>
<span>deepfill2还是要画边界线来提示的，这个直接把字覆盖住，肯定对背景物体的边界没有认知的</span><br>
</p><p><b>Amadeuszhao: </b><br>
<span> 本帖最后由 Amadeuszhao 于 2019-8-20 10:36 编辑 </span><br>
<span>啥时候能有人做字体识别</span><br>
</p><p><b>西岚不是花: </b><br>
<span>已经是很大进步了 </span><br>
<span>-- 来自 能看大图的 Stage1官方 Android客户端</span><br>
</p><p><b>ClampZZZ: </b><br>
<span>看了下，这是把鼻孔也识别成片假名了？  要是做中文的漫画项目是不是误操作率更高一点</span><br>
</p><p><b>星月肥纪: </b><br>
<span>这个有点厉害</span><br>
<span>—— 來自 Google Pixel 2, Android 10上的 S1Next-鵝版 v2.1.2</span><br>
</p><p><b>扫地机器人: </b><br>
<span>刚刚试了一下，几个问题</span><br>
<span>1、眼睛被当成文字</span><br>
<span>2、拟声字的边缘模糊，我的建议做成软分割，或者宁缺毋滥</span><br>
</p><p><b>冰原狼: </b><br>
<span>那么有没有只去气泡字不管拟声词的版本呢</span><br>
</p><p><b>性欲モンスター: </b><br>
<span>能不能把谷歌翻译的拍照实时翻译功能移植过去？</span><br>
</p><p><b>whzfjk: </b><br>
<span>冰原狼 发表于 2019-8-20 23:10</span><br>
<span>那么有没有只去气泡字不管拟声词的版本呢</span><br>
<span>另一个项目：https://github.com/Kocarus/Manga-Translator-TesseractOCR</span><br>
</p><p><b>冰原狼: </b><br>
<span>whzfjk 发表于 2019-8-20 23:28</span><br>
<span>另一个项目：https://github.com/Kocarus/Manga-Translator-TesseractOCR</span><br>
<span>看到了，不过这个更像是即时翻译，对于汉化嵌字来说好像还是用处不大……</span><br>
</p><p><b>whzfjk: </b><br>
<span>冰原狼 发表于 2019-8-21 01:03</span><br>
<span>看到了，不过这个更像是即时翻译，对于汉化嵌字来说好像还是用处不大…… ...</span><br>
<span>翻译只是最后一道流程，opencv识框+OCR定位文字区域之后可以接入到人肉翻译、嵌字的流程，反正代码都在那里（</span><br>
</p>]]></content:encoded>
      <guid isPermaLink="false">1854548[0-50]</guid>
    </item>
  </channel>
</rss>
