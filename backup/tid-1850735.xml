<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>9102年了，有实用化的深度学习插帧软件吗？</title>
    <link>https://bbs.saraba1st.com/2b/</link>
    <description>9102年了，有实用化的深度学习插帧软件吗？</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 09 Jul 2020 18:36:23 +0000</lastBuildDate>
    <item>
      <title>9102年了，有实用化的深度学习插帧软件吗？[0-50]</title>
      <link>https://bbs.saraba1st.com/2b/thread-1850735-1-1.html</link>
      <description>9102年了，有实用化的深度学习插帧软件吗？&#13;
现在流行的插帧，与其叫插帧不如叫动态模糊，插入的过渡帧基本都是根据原有帧进行模糊混合而来，效果嘛某些场合不错有些场合就没啥效果。
&#13;
基于深度学习的插帧，自动判断原始帧画面物体的位移并计算出中间帧，这方面科研论文倒是不少，黄老板的广告也有，但好像没见到普通大众能使用的软件？</description>
      <content:encoded><![CDATA[<p><b>处男鉴黄师: </b><br>
<span>9102年了，有实用化的深度学习插帧软件吗？</span><br>
<span>现在流行的插帧，与其叫插帧不如叫动态模糊，插入的过渡帧基本都是根据原有帧进行模糊混合而来，效果嘛某些场合不错有些场合就没啥效果。</span><br>
<span>基于深度学习的插帧，自动判断原始帧画面物体的位移并计算出中间帧，这方面科研论文倒是不少，黄老板的广告也有，但好像没见到普通大众能使用的软件？</span><br>
</p><p><b>qwased: </b><br>
<span>黄老板的超级慢动作</span><br>
<span>不过似乎还没开放使用</span><br>
<span>—— 来自 Xiaomi MI 6, Android 9上的 S1Next-鹅版 v2.1.2</span><br>
</p><p><b>laotoutou: </b><br>
<span>个人觉得现在的插帧不用也罢。</span><br>
<span>也就偶尔几下平移顺滑。</span><br>
</p><p><b>Vicarious: </b><br>
<span>找GitHub上的论文实现吧（</span><br>
</p><p><b>win8: </b><br>
<span>…其实不少视频的很多帧本来就是糊的。插帧也是糊上插糊。</span><br>
</p><p><b>mimighost: </b><br>
<span>比较鸡肋吧，我觉得效果一般般</span><br>
</p><p><b>处男鉴黄师: </b><br>
<span>这种效果已经可以了</span><br>
<span>https://github.com/avinashpaliwal/Super-SloMo</span><br>
</p><p><b>KanaiYuu: </b><br>
<span>cv领域，插帧太冷门了，发不了paper</span><br>
</p><p><b>伊可费斯: </b><br>
<span>要实现实时低延迟分析和插值肯定要寒武纪这类专门的计算芯片了。</span><br>
</p><p><b>Sza: </b><br>
<span>A厂新显卡芯片割了插帧的电路后，感觉新一代显卡自带插帧的只能看老黄家能不能放出训练包了，短期内也没得选。</span><br>
</p><p><b>临界点: </b><br>
<span>你觉得普通民用的机子能跑得动？</span><br>
</p><p><b>FirstSnow: </b><br>
<span>我搞不懂为什么不少人对插帧乐此不疲</span><br>
</p><p><b>处男鉴黄师: </b><br>
<span>临界点 发表于 2019-8-24 09:52</span><br>
<span>你觉得普通民用的机子能跑得动？</span><br>
<span>不追求实时嘛</span><br>
</p><p><b>treexper: </b><br>
<span>只能做离线处理，没什么实时性能。</span><br>
</p><p><b>lyz1196: </b><br>
<span>FirstSnow 发表于 2019-8-24 09:59</span><br>
<span>我搞不懂为什么不少人对插帧乐此不疲</span><br>
<span>我一直认为追求帧率是游戏带来的影响</span><br>
</p><p><b>sirlion: </b><br>
<span>我对帧数极其敏感，对4k完全没感觉，不知道为何这么多人追求4k</span><br>
</p><p><b>临界点: </b><br>
<span>处男鉴黄师 发表于 2019-8-24 09:59</span><br>
<span>不追求实时嘛</span><br>
<span>现在有专业的应对动画制作的软件但就算运用到动画制作前端 也只有日常动作才行 动作镜头一复杂就没戏了</span><br>
</p><p><b>临界点: </b><br>
<span>lyz1196 发表于 2019-8-24 10:36</span><br>
<span>我一直认为追求帧率是游戏带来的影响</span><br>
<span>游戏的帧率问题跟影视的帧数是不一样的   特别是动画流不流畅其实更多是原画师跟动画师的水准问题 而不是张数的问题</span><br>
</p><p><b>dogfight: </b><br>
<span>ggxx等游戏倒是致力于减少过度帧，做出动画般的效果</span><br>
</p><p><b>Sza: </b><br>
<span>借楼问一下7楼的那个开源的超级慢动作相关问题，之前关站一个月问不了。</span><br>
<span>上次我用colab跑这个程序，用原作者提供的adobe240fps预训练模型给日本动画片段补帧，伪影严重。</span><br>
<span>目前没有N卡，不清楚训练时的显存占用和时长。我也折腾不明白别家的云计算平台。</span><br>
<span>就想问问大佬们：如果以手绘动画作为训练素材，重新生成预训练模型，效果会不会好点？考虑到律表、运动作画画面不连贯和一拍三之类的重复帧的因素。</span><br>
<span>-- 来自 能搜索的 Stage1官方 iOS客户端</span><br>
</p><p><b>处男鉴黄师: </b><br>
<span>今天看到这个新闻，你们搞的这个东西啊，exciting</span><br>
<span>让电影动漫统统变丝滑，480帧也毫无卡顿，交大博士生开源插帧软件DAIN</span><br>
<span>http://tech.sina.com.cn/csj/2020-01-28/doc-iihnzhha5055260.shtml</span><br>
<span>github</span><br>
<span>https://github.com/baowenbo/DAIN</span><br>
</p><p><b>elxy: </b><br>
<span>处男鉴黄师 发表于 2020-1-28 19:34</span><br>
<span>今天看到这个新闻，你们搞的这个东西啊，exciting</span><br>
<span>让电影动漫统统变丝滑，480帧也毫无卡顿，交大博 ...</span><br>
<span>现在这些算法要直接拿来用还有蛮多不足的，场景切换、大动作、字幕等地方都需要针对性处理。</span><br>
<span>—— 来自 Xiaomi Mi A3, Android 9上的 S1Next-鹅版 v2.2.0.1</span><br>
</p><p><b>catxing: </b><br>
<span>处男鉴黄师 发表于 2020-1-28 19:34</span><br>
<span>今天看到这个新闻，你们搞的这个东西啊，exciting</span><br>
<span>让电影动漫统统变丝滑，480帧也毫无卡顿，交大博 ...</span><br>
<span>厉害了这东西</span><br>
</p><p><b>real_zyf: </b><br>
<span>华为那个7680fps也是号称ai插的吧</span><br>
</p><p><b>magpte: </b><br>
<span>处男鉴黄师 发表于 2020-1-28 19:34</span><br>
<span>今天看到这个新闻，你们搞的这个东西啊，exciting</span><br>
<span>让电影动漫统统变丝滑，480帧也毫无卡顿，交大博 ...</span><br>
<span>这东西看了一些效果图很可以了</span><br>
<span>—— 来自 Sony G8142, Android 9上的 S1Next-鹅版 v2.2.0.1</span><br>
</p><p><b>lixianfyss: </b><br>
<span>处男鉴黄师 发表于 2020-1-28 19:34</span><br>
<span>今天看到这个新闻，你们搞的这个东西啊，exciting</span><br>
<span>让电影动漫统统变丝滑，480帧也毫无卡顿，交大博 ...</span><br>
<span>真是厉害，不知道训练要多久。</span><br>
</p><p><b>567478: </b><br>
<span>处男鉴黄师 发表于 2019-8-2 13:40</span><br>
<span>这种效果已经可以了</span><br>
<span>https://github.com/avinashpaliwal/Super-SloMo</span><br>
<span>MARK</span><br>
</p><p><b>伊可费斯: </b><br>
<span>加长测试了下国内那个，实拍效果更好。 https://weibo.com/1937849871/IssKsv9BF</span><br>
</p><p><b>Sza: </b><br>
<span> 本帖最后由 Sza 于 2020-2-3 14:29 编辑 </span><br>
<span>伊可费斯 发表于 2020-2-3 12:23</span><br>
<span>加长测试了下国内那个，实拍效果更好。 https://weibo.com/1937849871/IssKsv9BF</span><br>
<span>评论区分享的那个插帧软件挺有趣，用SVP之类的插值算法多次升降帧数并压制，可能对ACG内容更友好。</span><br>
<span>我之前发帖的时候楼里一位网友同样推荐了DAIN。看了下它训练用的训练集是“Vimeo90K triplet dataset”，都是连续三帧图像为一组的数据集。</span><br>
<span>这种数据集来训练可能有其局限性，比如在手绘动画那种1秒8~12张原画张&动画张+12~16张重复帧的情况下，对物体的变加速运动和周期运动预测会和实际有误差，比如说钟摆运动。</span><br>
<span>再加上和手绘动画格格不入的涂抹感，这种算法还是插摄影素材更合适。</span><br>
<span>如果想用来插电视剧或者电影可能都不合适。楼上也有人说了，目前的版本对“场景切换、大动作、字幕”处理有不足，插值用时又需要70倍以上的原视频时长。</span><br>
</p><p><b>暗铁: </b><br>
<span>动画插帧出来总感觉一股劣质3D味</span><br>
</p><p><b>Sza: </b><br>
<span> 本帖最后由 Sza 于 2020-2-4 04:45 编辑 </span><br>
<span>暗铁 发表于 2020-2-3 19:06</span><br>
<span>动画插帧出来总感觉一股劣质3D味</span><br>
<span>我看了优土be的演示视频，感觉太过平滑。</span><br>
<span>这么说起来倒是可以反过来想，优秀3D动画是怎么处理力度感的，可能是抽张的一拍二动画，可能它们最多是24帧/秒的一拍一动画，也可能它们在60帧/秒下用了其他的技法。我觉得对动画补帧来说，目前的60帧or120帧是伪需求，实际需求是需要24帧的全动作动画。保留每秒8~12张原画帧，有选择的删除剩下的重复帧，根据运动规律补足剩下的帧数，使视频回到24帧。</span><br>
<span>这样可能就不会有奇怪的流畅感，不过实际产物就如同某个B站视频说的“大塚康生：(手冢先生的虫制作公司)确实是在用一拍二作画没有错，但是只不过是将原本用在一拍三上的原画和原画之间改变动画张数而已，一拍二特有的画法也好细致之处也好完全没有加进去”。软件插帧到一拍一还是有限动画，只是这样插值力度感保留了，动作更流畅了，但人物动作还是简化的。</span><br>
<span>目前的DAIN我想是做不到这种效果的。之前我试了下动画去除重复帧后用superslomo插帧，画面涂抹严重的看不下去，不过深度学习插帧的效果还是很amazing </span><br>
</p><p><b>mcq_2: </b><br>
<span>sirlion 发表于 2019-8-24 10:45</span><br>
<span>我对帧数极其敏感，对4k完全没感觉，不知道为何这么多人追求4k</span><br>
<span>你屏幕不够大</span><br>
</p><p><b>mcq_2: </b><br>
<span> 本帖最后由 mcq_2 于 2020-2-3 20:16 编辑 </span><br>
<span>Sza 发表于 2020-2-3 19:38</span><br>
<span>我看了优土be的演示视频，感觉太过平滑。</span><br>
<span>这么说起来倒是可以反过来想，优秀3D动画是怎么处理力度感的，可 ...</span><br>
<span>24帧没问题的，问题是快速动作的过渡帧动画大家都在偷工减料，过渡帧画面的变形就没花心思做，流畅感当然打折扣，其实怎么省钱怎么来没什么错就是了。最近那部蜘蛛侠删了所有的过渡帧，看的眼睛疼。</span><br>
</p><p><b>Sza: </b><br>
<span>mcq_2 发表于 2020-2-3 20:14</span><br>
<span>24帧没问题的，问题是快速动作的过渡帧动画大家都在偷工减料，过渡帧画面的变形就没花心思做，流畅感当然 ...</span><br>
<span>就是省钱嘛，一拍二一拍三混用加上作画缩水。关键帧、过渡帧和重复帧混在一起的24帧动画，深度学习不看律表帧数插上天都救不了 ——鲁迅</span><br>
</p><p><b>暗铁: </b><br>
<span>Sza 发表于 2020-2-3 19:38</span><br>
<span>我看了优土be的演示视频，感觉太过平滑。</span><br>
<span>这么说起来倒是可以反过来想，优秀3D动画是怎么处理力度感的，可 ...</span><br>
<span>优秀的3D动画是原生60帧的动作捕捉吧，纸片人一拍三这种你补成线性运动没有意义啊</span><br>
<span>—— 来自 samsung SM-G9650, Android 9上的 S1Next-鹅版 v2.2.0.1</span><br>
</p><p><b>Sza: </b><br>
<span>暗铁 发表于 2020-2-3 21:14</span><br>
<span>优秀的3D动画是原生60帧的动作捕捉吧，纸片人一拍三这种你补成线性运动没有意义啊</span><br>
<span>—— 来自 sam ...</span><br>
<span>我不清楚手绘的一拍一的全动作动画插到60帧及以上会有不自然感吗？有的话还是得抽张。。。</span><br>
</p><p><b>mcq_2: </b><br>
<span>Sza 发表于 2020-2-3 21:21</span><br>
<span>我不清楚手绘的一拍一的全动作动画插到60帧及以上会有不自然感吗？有的话还是得抽张。。。 ...</span><br>
<span>有个帖子讲为什么真人电影24帧就很流畅，而游戏144帧还觉得卡。问题是实景拍摄的24帧画面你暂停下来看基本都是模糊的代拖尾的，尤其在影视作品里，大量随机的这种画面的动态变形不是你插帧能弥补的。往往最终插出来的效果就是更卡顿。忽快忽慢。</span><br>
</p><p><b>Sza: </b><br>
<span>mcq_2 发表于 2020-2-4 00:36</span><br>
<span>有个帖子讲为什么真人电影24帧就很流畅，而游戏144帧还觉得卡。问题是实景拍摄的24帧画面你暂停下来看基本 ...</span><br>
<span>我看以前的一集B站视频的解释（av5824251)，视频流畅与否还是看张数。游戏60帧和电影24帧相比不流畅是因为游戏实时生成每帧时间不一致，3D动画没动态模糊一样流畅（视频中用秦时明月电影和定格动画举例）。看看啥时候软件算法能以假乱真吧，大幅度不规则形变确实不好处理。。。</span><br>
</p><p><b>mcq_2: </b><br>
<span>Sza 发表于 2020-2-4 04:21</span><br>
<span>我看以前的一集B站视频的解释（av5824251)，视频流畅与否还是看张数。游戏60帧和电影24帧相比不流畅是因 ...</span><br>
<span>现在纯增加帧数的做法可能还是有点问题。大方向还是简单的把24帧插到60帧。这就跟李安的120帧电影一样。即便技术成熟了能补到120帧了，但是就拿实拍片来说，120帧对比24帧，观赏差异依然很大。我想是不是能直接用算法修改中间帧画面的几何变形，来实现24帧动画更流畅的目的。</span><br>
</p><p><b>Sza: </b><br>
<span> 本帖最后由 Sza 于 2020-2-4 10:33 编辑 </span><br>
<span>mcq_2 发表于 2020-2-4 09:17</span><br>
<span>现在纯增加帧数的做法可能还是有点问题。大方向还是简单的把24帧插到60帧。这就跟李安的120帧电影一样。 ...</span><br>
<span>你说的就是提取视频中的实际原画帧，去除重复帧再插帧嘛。之前的帖子里有网友说可能要用到GAN，那样的算力开销我有点不敢想象。</span><br>
<span>隔壁chh 17年也有人讨论过插帧，树导提到过GAN补间动画（ https://www.chiphell.com/forum.php?mod=viewthread&tid=1770248&ordertype=1&page=1。）</span><br>
<span>楼里提到的动画业界用的插值方法这季新番的映像研里也展示过，能做简单运动的补帧，我贴个截图。说起来我记得汤浅监督之前的动画也用过flash之类的软件制作（ https://www.bilibili.com/video/av38772248/。）</span><br>
</p><p><b>mcq_2: </b><br>
<span>Sza 发表于 2020-2-4 09:29</span><br>
<span>你说的就是提取视频中的实际原画帧，去除重复帧再插帧嘛。之前的帖子里有网友说可能要用到GAN，那样的算力 ...</span><br>
<span>其实这种插帧的技术问题可能还不是核心。蜘蛛侠平行宇宙不是把过渡帧都删掉了么，这种出于艺术表现需要，完全抛弃过渡帧的做法也是有的。实际上，即便是实拍电影24帧转变到120帧，演出方式都有了极大改变，动作细节变多了，对于演员的表演要求也更高了。而说到动画，可能也存在类似的情况。如果真的有能力能制作完全平滑过渡的动画，那每秒24帧可能会增加多少信息量呢？换句话说，用现今各种季番的质量跟表现要求上来看，至少在过渡帧的技术方面是能够满足需要的。也许插帧运算以及算法的研究目的更多的还是为了降低作画成本吧。</span><br>
</p><p><b>Sza: </b><br>
<span> 本帖最后由 Sza 于 2020-2-4 12:31 编辑 </span><br>
<span>mcq_2 发表于 2020-2-4 12:09</span><br>
<span>其实这种插帧的技术问题可能还不是核心。蜘蛛侠平行宇宙不是把过渡帧都删掉了么，这种出于艺术表现需要， ...</span><br>
<span>对的，日式动画的有限动画的技法已经能很好满足了目前的一拍二一拍三张数规格。如果是原画师动画师水平较低作监来不及改，又或是项目因较为拮据的预算和工期所限，运动的流畅感光靠算法是很难拯救的。</span><br>
<span>我想如你所说，对动画而言，插帧算法的发展方向还是降低制作公司成本，用更少的人月达到合格的品质。对普通观众面临的困难实在是太多，前面网友总结的场景切换、字幕、大幅度运动和运动形变就够喝一壶了，更不用说目前的软件算力不支持实时处理，插一集24分钟动画显卡要跑一天。还有插帧至60帧及以上后的视频文件体积的问题。</span><br>
</p><p><b>马台街48: </b><br>
<span>23.9叙事高帧率赛事转播慢门甩镜头制造幻觉影视领域毕竟沿袭了几十年的创作规律   李安站的高度跟我们肯定是不一样能看到我们看不到的风景但就目前来说高帧率还是成本太受限他自己的两部也不卖座</span><br>
</p>]]></content:encoded>
      <guid isPermaLink="false">1850735[0-50]</guid>
    </item>
  </channel>
</rss>
