<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>凯文.凯利：上帝，机器人与你</title>
    <link>https://bbs.saraba1st.com/2b/</link>
    <description>凯文.凯利：上帝，机器人与你</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 09 Jul 2020 16:07:46 +0000</lastBuildDate>
    <item>
      <title>凯文.凯利：上帝，机器人与你[0-50]</title>
      <link>https://bbs.saraba1st.com/2b/thread-1914404-1-1.html</link>
      <description>凯文.凯利：上帝，机器人与你&#13;
https://www.youtube.com/watch?v=Jd0l-O2qxPk&amp;list=FL3RezzS-A7eu0NV9aDxzpdA&amp;index=4&amp;t=0s
&#13;
我相信人工智能——即AI——的确是我们所释放过的最强大的力量，影响到了我能想象的一切领域，包括宗教——今晚我还要简单提一下这个方面。关于人工智能我们大约知道一点，我也很确定这一点：与三十年之后相比，今天不存在人工智能专家。我们现在根本不知道人工智能是什么。换句话说今天在场的年轻听众们最终成为人工智能专家的可能性要比今天领域内的任何人都更大。我们只是刚刚起步而已，因此假如你觉得对于人工智能有什么不理解不明白的地方也不要犹豫，因为谁都不明白。不仅是因为人工智能是新兴技术所以没人理解，而且就算是在人工智能运作正常的时候我们依然不理解它的运作机理。我们的挑战之一在于我们猜不透人工智能的心思。因此请记住，你就像任何其他人一样有可能取得人工智能领域的下一项大突破，因为今天不存在真正意义上的人工智能专家。
&#13;
我想谈一下有关人工智能的几个方面。首先我想谈谈我们现在确实了解什么，其次我想将人工智能问题放在普遍背景下考察，从而更好地界定我们想要提出的问题。显然，人工智能是我们释放过的最基本的力量。今晚我不想谈论人工智能意味着什么、人工智能能做到什么或者我们应当如何管理人工智能。我认为这些问题我们在未来一百年内都没法解答。这是一个需要耗时百年的项目。随着人工智能技术进步以及我们对其理解的加深，我们今天提出的问题将会被后世的人们一遍又一遍提起。这是一场进行中的对话，我想做的是推出更好的提问方式乃至更好的问题。假如大家今天回去的时候脑子里有了比来的时候更好的问题，那我觉得今晚的讲座就算成功了。
&#13;
为了在其他技术共同组成的大背景下讨论人工智能，我想先打个比方。每年人类集体完成的各项发明都是共时完成的。所谓共时就是说总会有多于一人的发明家想出同样的创意，甚至还会同时掌握将点子化为现实的制造能力。今天几乎没有哪一项创新发明会单独出现，而是会共时且相互独立地在全球各地冒头。部分原因在于任何发明都不仅只是单一的创意，而是多种创意相互交织的产物。在今天创造任何有用的新事物都需要多种创意的协力，就像网络一样。到头来我们将最后欠缺的一项创意安放到位，新发明就问世了。许多人都会几乎同时走到这最后一步。所以我们才会有专利局，同一项专利往往会有许多人申请，提交时间往往先后凑得很近——几周、几天乃至几个钟头——专利局的职责就是确定谁来得最早。发明的出现靠得不是什么构想出超越时代的全新创意的英雄发明家，而是某种文化现象，是无数创意长期进步的成果。我甚至主张许多发明都可以被视为必然出现的事物。一旦你发明了电线、开关以及无线电，那么下一阶段的发明就必然会出现，无论你身处怎样的政治体制或者文化环境当中。发明自有先后承接的顺序。在史前时代，发明在各个大陆独立出现，彼此相互隔离没有交流，但是全球各地的发明依然很相似。这在一定程度上暗示着技术发展并非出自非凡头脑的任意而为，而是要遵循内在顺序。先前的技术积累在文化层面上极大地决定了后来的技术发展。
&#13;
除此之外，我认为技术还具有先天的偏见，会倾向于特定方向，而这一倾向则是由发明的物理性质决定的。物理与化学决定了我们有可能造出什么东西。宇宙的基本限制制约了技术的发展方向。我认为我在谈论未来时的任务就是确定这一倾向，确定技术的偏见指向何方。我举个简短的例子：互联网的偏见是喜欢复制事物，电气化网络的偏见是让事物的副本无处不在。我们将一条信息从国家一头发送到另一头，这条信息会在沿途留下无数副本。笔记本电脑与手机里的信息也会时时刻刻产生副本。一视同仁的、**式的复制就是网络的偏见。这样一来，出于保护知识产权的法律原因来保护副本就会变得十分困难。我们不可能真正阻止副本的随意出现，因为这样做有悖技术的天然偏见，这一偏见的方向就是副本的自由流动。人工智能也有偏见，这些偏见同样根植于我们用来制造人工智能的材料的物理化学性质。我们想要确定这些固有的倾向究竟是什么。
&#13;
我之所以使用偏见与倾向这样的术语，因为我想知道在其他条件一致的前提下技术想要走向何方，技术想要什么。确定了技术的倾向，就能进一步确定技术发展的长期趋势，尽管同时我们也知道技术的具体细节从根本上无法预测。长期趋势可以预测，具体细节则混乱无章。甚至就连自然进化与生物学也遵循同样的道理。你可以说，鉴于地球的重力大小，陆地上必然会出现四足行走的动物，因为四足行走是运动起来最稳定的物理配置，甚至就连人工仿真的机械动物都要采取四足结构。但是另一方面，斑马这一特定物种却不是非得出现不可，斑马的出现是无法预测的。同理，假如你已经发明了电线与其他电子器件，接下来电话乃至手机就会出现，这是从根本上可预测的；但是苹果手机却未必一定会出现，这是从根本上不可预测的。再打一个比方，好比说山谷里下雨，任何一滴雨水顺着山坡流下来的路径都是随机且不可预测的，但是雨水的总体流向不但是可以预测的，而且是不可避免的——肯定会向下流。我们打算以同样的方式来看待技术。河流里的水就算冲出了河床，路径看似无法预测，但是依然受到河漫滩的限制。
&#13;
所以说，电话是必然的，苹果手机不是；人工智能是必然的，人工智能的特点、品牌、后果、监管政策以及政治则不是。我们可以做出许多有关后者的选择，这些选择将会造成极大的不同，而且我们可选择的范畴非常大。互联网是必然的，互联网的类型则不是：互联网可以是跨国的也可以不是，可以开放也可以封闭，可以被商业实体掌控也可以国有化。这些都是我们面前的选项。人工智能也差不多。人工智能必然来临，我们没有选择。但是论及人工智能的特点特质、相关政策、所有权归属、运行方式与使用方式，我们手里的选项则多得吓人。上述选择以及无数其他选择将会造成极大的不同。
&#13;
所以说人工智能是什么呢？首先来看看人工智能不是什么。人工智能并不是单一智商维度上的一个点。单一维度就像音量那样一头小一头大，人们一般认为老鼠有一点智力，猴子的智力更强，然后是白痴，然后是我们，然后是天才，最后是人工智能。这种想法大错特错。智力是多维度的存在。天然智能——也就是在座各位的智能——此时正在应用至少十几种不同的认知方式，至于我们尚未发现的认知方式恐怕还要更多。这些认知形式在人与人之间、任务与任务之间存在着巨大的差异。你不妨将天然智能视作多种乐器组成的交响乐队。人类心智就是这样一套由多种认知方式共同组成的复杂组合。动物的心智同样由多种认知方式组成，海豚、鲸鱼、狗、蚂蚱、老鼠全都各具特色。与人类相比，它们的某些认知方式或许大为简化，某些方式或许与人类相似，还有些方式或许会在特定情况下远远超过人类。比方说地松鼠的长期记忆力非常惊人，可以记住上千颗橡实的埋藏地点，而且十几年内都不会忘记。人类显然没这个本事。
&#13;
我们制造人工智能机器的时候，也会希望这些机器在特定维度上超越我们。我们制造了计算器，在代数运算方面超越了我们，但是它就只会干这个。计算器进行代数运算非常出色，进行翻译或者导航则一塌糊涂。人类已经制造出了许多心智，每一种都在特定维度超越了人类。你们已经听说了人工智能的许多神奇事迹，从能够击败最强人类棋士的阿尔法围棋到自动驾驶的汽车。但是今天出现的几乎所有人工智能都仅仅合成了某一类认知方式。比方说神经网络长于辨识模式，但是它们也就只会干这个。这一现实对于我们来说既是好消息也是坏消息。好消息是仅凭单一认知方式就足以完成无数了不起的任务，坏消息是我们根本不知道怎样将多种认知方式结合起来。实现后者就是你们各位的任务。
&#13;
我们目前正在尽量填充一座由多种心智类型组成的动物园。我们不仅希望能够发现重新组合现有心智类型的不同方式，而且还能发现人类心智根本无法实现的纯人工认知方式并且将其整合进入新一代人工智能当中。关键在于，在上述两种情况下我们都不打算复制人类心智。这些新型心智的长处就在于它们的思考方式不同于人类，因此它们才能解决我们解决不了的问题。未来例如引力波或者暗物质之类的困难问题无法仅仅依靠人类心智来解决。我们可能要采取两步走策略，第一步是制造某种与人类思考方式不同的人工智能，第二步则是让人类与人工智能合作来解决问题。我认为我们需要填充各种可能心智的存在空间，因为构造一个能思考的心智的方式有很多种。有些心智将会很小很原始，只有若干个节点。它们的智力或许仅仅相当于松鼠，但是这只松鼠却能够完成我们想要完成的特定任务。我们不需要这些心智完全发展到能与人类交谈的程度。他们的设计目的是完成其他许多事，甚至包括某些目前我们自己都不知道自己希望完成的事情。又或者它们可以替代人类完成重复性的任务。但是首先我们要填满这个空间，而且这还是一片很大的空间，我们甚至不知道到底有多大。研究人工智能的副产品之一就是让我们获得了探寻人类心智的望远镜。出于伦理限制，我们不能针对人类大脑做太多实验。我们理解人类心智的方式之一就是尝试着以人工方式复制人类心智。这就是研究人类心智的望远镜或者说显微镜。
&#13;
接下来我们来探讨一下所谓超级智能的理念。有人认为这个空间里的某个点具备神灵一样的超级智力，这种看法完全站不住脚。实际上空间里的任何一个点都不比其他点更加优越。我们的示意图仅仅画出了三维，在实际当中智力的维度足有十几个。任何心智都要做出取舍。你无法让某个心智同时在所有维度得到优化。所以不可能出现这种足以导致智力爆炸的心智：人类制造了比人类更聪明的人工智能，这一人工智能又制造了更聪明的人工智能，就这样一代代发展下去，然后轰隆一声上帝就问世了。这就是奇点理论的主张：技术奇点到来得很快，突然一切事物都变得面目全非，我们无法想象奇点之后的世界。我认为本质上这是一套宗教信仰，因为工程设计永远免不了取舍。你不可能造出一台十全十美的机器，同时做到跑得更快，体积更小，重量更轻，力量更大，跳得更高，爬得更低，价钱更便宜。在现实当中我们肯定能造出在某些维度比人类更强的人工智能，但是人工智能无法全面超过人类。
&#13;
长期以来我们一直认定人类位于世界的中心，各大行星都围着我们转。事实证明这是错误的。在达尔文之前，我们认定人类是动物界的中心。现在我们又认定人类心智是一切心智形式的中心，任何其他心智形式都与人类心智差不多，只不过或许更快一些。我相信这种看法同样是错的。就像地球位于银河系的边缘一样，我认为人类心智也位于心智空间的边缘。人类心智是一种高度特化的心智类型，丝毫没有普适性。换句话说，看待人工智能的最佳方式是将它们视作异类智能。好比说我们遇到了外星人，外星人也很聪明，也有意识，但是他们的思考方式显然和人类不一样。这种与我们有别的思考方式正是他们的价值所在。在我们目前的经济体系当中，财富总会流向有别于主流的思考方式。但是既然你全天二十四小时都与全世界其他人链接在一起，那么你的思考方式要怎样才能有别于主流呢？人工智能能够辅助我们一边保持链接一边具备不同的思考方式。
&#13;
所以我们或许应该将人工智能称作“人工外星人”。就好像《星际迷航》里的斯波克与Data一样，他们能思考，有创造力，也会讲笑话，但是他们的笑话总是逗不乐人类。这就是我们想要实现的图景。宇宙当中还有亿万个其他星系，谁知道有朝一日我们会不会遇到外星人呢？倘若当真遭遇了外星人，我们的日常生活必定会被搅动得天翻地覆。假如我们与另一个世界的来客进行了直接接触，我们的世界从此必定会再不相同。我们不知道会不会有这么一天，但是我们肯定能够人工制造异类。我认为制造人工智能的后果很类似于遭遇外星人。大家应该还记得，电影《超时空接触》里面的男主就是个神学家，因为接触异类意识体的冲击力实在太大了。除了技术层面以外，神学、心理学以及身份认同等等社会层面也必将承受剧烈冲击。我们可能将不得不重新思考我们是谁，我们为什么存在，我们有什么独特之处，我们想要成为什么。
&#13;
如今人工智能已经具有了感知能力，比方说它们可以生成人脸照片。这些上千万张人脸照片全都不是真人，本质上是人工智能凭借想象画出来的。你们也都听说过阿尔法围棋，这一类人工智能的厉害之处在于能够学习如何学习。谷歌让一个人工智能打电子游戏，但是却没有教给它规则，让它自己摸索出得分最高的玩法。我再强调一遍，这些人工智能的思考方式不同于人类。它们也很聪明，也很有创造力，但是与人类截然不同，这正是它们的优势。此外如今我们已经有了巴别鱼那样的通用语言翻译器。你说中文，我听到英语；我说英语，你听到中文。假如此类设备能变得更加便宜普及——我相信七到十年之内就会这样——全世界将会有一大批才华横溢但是不会说英语的人们投入到全球经济当中。话说回来，这项技术无非只是语言感知而已，只是一种我们已经学会合成的单一维度认知类型。
&#13;
我们目前还依靠人工智能制造了种植生菜的机器人，从而实现精细化农业。机器人沿着田垄开过去，检查每一株生菜苗的生长情况，还能通过GPS确定每一株生菜苗的位置，从而有针对性地施肥浇水。人类农民肯定很想这么做，可惜做不到。生菜机器人在广大田地上照顾到了每一株生菜的需求，极大地节省了化肥与水的用量。我们甚至还能将太阳能驱动的小型机器人大量撒布到农田里，让它们负责除草灭虫。这些人工智能完成的工作我们人类要么不想做，要么压根做不好。人工智能的确夺去了不少工作，但都是没人想做的工作。我们获得了解放，可以去做想做的工作。
&#13;
机器人特别擅长需要生产力与效率的工作，相对来说人类的效率极其低下。人类社会最有价值的东西全都谈不上效率。比方说科学的效率从根本上就很低。假如某位科学家说：“我搞研究的效率是100%，我做的实验全都成功了。”那只能说明他什么都没学到。艺术的效率从根本上也很低。毕加索并不能按照每小时完成多少幅画作来领工资。人际交往更是谈不上效率。人类社会最有价值的东西全都谈不上效率，这对我们人类来说是个好消息，因为人类是低效率的大师。只有机器人才讲究效率。二十年前，人类象棋大师加里.卡斯帕罗夫输给了IBM的超级计算机“深蓝”。当时人们以为象棋运动从此就要告终，可是实际上象棋却越发展越茁壮了。人类棋手通过与计算机对练而普遍提升了水平。
&#13;
不过更重要的是，当时卡斯帕罗夫抱怨比赛不公平，因为深蓝可以从一个包含古往今来所有棋局的数据库当中读取资料。他声称假如他能得到同样的数据库支持，赢家就应该是他。许多人也都这样认为。于是卡斯帕罗夫组织了一项全新的象棋联赛，允许人工智能、人类以及两者组队参赛。过去四年里，世界上最优秀的象棋棋手并不是人工智能，也不是人类，而是两者的组队。卡斯帕罗夫将这种人机搭配称作半人马。如今最优秀的象棋棋手是半人马，最优秀的诊断医师也是半人马。军方正在利用半人马来操作机器人士兵，因为人与机器能够互补。我认为长期来看我们每个人的收入水平都要取决于我们与人工智能合作的能力。理想状态下，人类不该与人工智能相对抗，而是应当协力配合。
&#13;
机器人确实更擅长重复性的工作，但这并不意味着它们就没有创造力。创造的本质无非是一个机械过程，可以用算法来体现。但是机器的创造力绝不同于人类的创造力。人工智能可以辨识各种人类情绪，我们也可以让人工智能具备情绪，因为这样做能够促进人类与人工智能的合作。另一方面，单纯从改进表现来说，许多基础情绪对于人工智能也很有用。例如现在我们正在让机器人有能力感知疼痛，因为疼痛很有用，能让机器人不至于带伤运作加剧损坏。我们这么做不是为了存心让机器人受罪，也不是出于施虐心态。疼痛是阻止生物体损伤自己的有用工具。人工情绪如今已经成为了专门的研究领域，我们正在向人工智能植入情感组件。由于人工智能的思考是一个机械过程，我们正在一次次发现自然界当中的许多生物学过程都可以移植到机械系统当中。情感、创造、生命乃至智力都不是什么超自然力量，而是可以移植到机械系统里的过程。
&#13;
我们习惯了将心智、意识、灵魂与精神之类的词语混淆使用。实际上这三者非常不同，而且恐怕全都不是单数形式，而是包含着大量变体的连续体。这四个词都不是非有即无的二元存在，而是有着不同的层级、类型与多样性。这四个词或许包含着上百项内涵，而我们现在甚至还没有足以将其理清的词汇表，但是将来我们会有的。我们可以想象，或许会有没有意识的心智，没有灵魂的意识，以至于没有心智的灵魂。现在这些言语对我们来说没什么意义，因为这些词语太含糊了。我们需要探索的一个方面就是为意识下定义。意识存在于什么地方？如何检测意识？我们能否将意识植入某个物体？能在多大程度上这么做？当我们试图理清人工智能的伦理学时，肯定绕不开这些问题。例如著名的电车问题，我们要如何教导人工智能做出伦理抉择，尤其是在这些抉择涉及到人类的时候？简短的回答是：教导人工智能学习伦理很容易，只要编码就行了。真正困难的地方在于，人类的道德既浅薄又自相矛盾，而且往往作用在无意识层面。换句话说我们自己并不擅长伦理学，想要教育人工智能就更难了。假如我们真能构想出一套内在一致的伦理体系，将其传授给人工智能其实一点都不难。难点在于我们自己目前都还没想明白如何应对伦理问题并做出决策，因为过去我们从来不必逼迫自己大伤脑筋。
&#13;
假设你开车上路遇到险情，要么避让路边行人，要么保护车内乘客安全。无论我们怎么选，事后都不会评判自己，只会说：“一切都发生得太快了，我根本没能反应过来。”人工智能则不能用这句托词搪塞过去，因为我们必须事先做好决定。因此我们将被迫改善我们自己的伦理道德水平。就好比父母教孩子知识，教着教着就发现自己水平很菜，需要补课。换言之，人工智能让人类第一次有机会将哲学应用在实践当中。汽车公司正在雇佣哲学家当顾问，哲学家则试图用严格的论证来决定人工智能的设计而不是拍脑袋想主意。为了教育人工智能而进行预先道德决策的努力能够提升人类的整体道德水平，因为这一努力将会迫使我们成为比现在更好的人类。我们是否应该优先保护车上乘员？我们必须彻底想清楚这个问题，然后才能教育人工智能。阿西莫夫的机器人三定律广为人知，但这只是最初最容易的一步。我们或许还会发展出更多的规则进一步传授给他们。
&#13;
现在我们已经有了赛博战争。赛博战争的关键之一在于人类还没有就赛博战争的底线达成共识。搞垮银行体系行不行，针对粮食工厂下手行不行，美国人、中国人乃至全人类都还没想好在赛博战争当中哪些事情不能做。接下来还有击杀决策的问题，我们该不该将击杀敌方作战人员的自主权下放给无人机？让机器来决定本该人类决定的事情是很不负责任的，那样一来人类放任无人机杀人就太容易了。另一方面，无人机与算法也不可能被指控犯有战争罪，因为它们忠于程序，不会情绪化，比人类更不容易擦**走火或者判断失误。认为我们只应该允许人类杀人而不应该允许机器杀人的主张听上去很奇怪。汽车已经经受过了这样的争论。每年都会有一百万人死于车祸，他们全都死于人类的错误。我们能接受这一百万人的死亡作为技术的代价，只要是人类杀了他们就行。可是假如人工智能杀了这些人，我们肯定会怒不可遏。这样的不对称很没道理。我们允许人类杀人，不允许机器杀人，但是我们真正应该做的是彻底预防人类杀人。
&#13;
波士顿动力公司测试机器人的视频看上去确实很像是在虐待机器人，但这都是测试的一部分。这又带来了我们必须应对的另一个问题：假如我们让机器人像奴隶那样遵循我们的一切命令，那么就算它们其实并不是奴隶，只要我们拿它们当做奴隶，这样的人机关系依然极具腐蚀性，不仅不利于奴隶，同样也不利于奴隶主。人类与对于人类百依百顺的存在之间应当是什么关系？在关闭机器人之前是不是还应该搞个仪式？
&#13;
我喜欢将人工智能视为人类的心智后代，它们是我们的心智生出来的孩子。我们也应该在一定程度上将他们视作我们的孩子，照顾他们，为他们寻找好工作，向他们传授价值观。最终他们将会具有自主决策的能力，然后他们当中的某一个就会说：“我有灵魂，我该怎么办？”我们必须想好答案。几年来我一直主张我们应该编纂一份机器人教义问答。“你来自这里，你存在的目的是这个。”这样做是为了让他们帮助我们改善自身。我认为人性在未来有四种发展方向：许多物种，同一类心智；许多类心智，同一物种；许多物种，许多类心智；单一物种，单一心智。所有这些技术进步正在为人类带来身份危机。我们作为人类究竟是谁？我们希望人类成为什么？我们应该成为什么？可以成为什么？目前的身份政治已经很难搞了，做男人与做女人分别意味着什么，做美国人与做中国人分别意味着什么，现在我们又要考虑身为人类意味着什么，应该意味着什么。总之，我们之所以应该制造更多的人工智能与机器人，是因为他们能帮助我们改善自身。
&#13;
最后，如果你确实想要推进关于人工智能的对话，有几件正在发生的小事我要提醒你们一下。目前业内使用的术语“人工智能安全”范围很宽泛。业内人士经常开会讨论我们要如何制造与控制人工智能，可以允许人工智能做什么，怎样最好地传递人类的价值观。有一个名叫“负责机器人”（Responsible Robotics）的团体正在研究人工智能与机器人的武器化问题。他们接纳各种人员的加入，不必非得是人工智能专家才能讨论如何让机器人负责。斯坦福大学有“人工智能伦理与治理”项目，研究如何治理这些一看就很难治理的东西。“人本AI”（Human Centered AI）与“现今AI”（AI Now）也是试图应对这一问题的两家机构。
&#13;
我认为技术就是化为实体的理念，我们以这样那样的方式将物理形体赋予了概念。假如我现在告诉你们一个愚蠢的主意，你们肯定不会建议我从今往后不要思考，而是建议我想出更好的主意。假如一项技术造成了危害或者不如人意，我们会说这是一项愚蠢的技术。但是正确的回应不该是更少的技术，不应该是技术倒退乃至放弃技术，而应该是更好的技术。所以我们希望尽量增加技术的总量。DDT曾经用于棉田杀虫，这是个很糟糕的主意，但这并不是DDT本身的问题，只是人们使用DDT的方式出了大错。后来人们想出了使用DDT的更好主意，也就是将其作为家用灭蚊剂，从而极其有效地控制了疟疾的传播，每年拯救了上百万人的生命，还不会影响环境。技术没有变，但是应用技术的方式改善了。核武器是坏主意，核电站则是好主意。每一项新技术创造的新问题都几乎与它解决的旧问题一样多，但是新问题也带来了新选择与新可能。因为伴随着新的选择，所以新的可能总会比原来好一点点。明年我们的选择会比今年多几个百分点。就算有些技术会带来糟糕的后果，但是我们毕竟有了更多的选择。这些选择带来了微小的进步，或许只有1%。假如每年我们的创造都能比破坏多出1%，年复一年的复利累积就足以支撑一个不断进步的文明。人工智能必然会造成巨大的破坏，这一点毋庸置疑。但是只要人工智能每年创造的价值比起破坏多几个点，总体而言就是进步。我们的任务就是为每一项新技术找到最合适的任务，无论是DDT /核能还是人工智能。
&#13;
最后，我们掌控技术发展方向的唯一方式就是参与其中。假如你禁止技术，关闭技术，回避技术，就等于放弃控制权。如果你想影响人工智能的未来，现在就要拥抱人工智能。这并不意味着你非得在任何方面全都应用人工智能不可，也不意味着你必须接受人工智能，只不过你要参与进来。参与其中能让我们得到更多的选择与机会。人工智能将会让我们不断面临从未有过的新选择。我想用以下的比喻来收尾：想想一下莫扎特生在大键琴或者钢琴发明之前一千年的时代会怎样，全世界以及他本人都会与他的天才失之交臂。他必须依靠某人发明钢琴这项技术，然后才能彰显他的才华。梵高生在油画颜料与帆布出现之前一千年会怎样？我们的世界与他本人将会蒙受多大损失？假如希区柯克与卢卡斯生在电影技术出现之前呢？反过来说，如今这世上肯定也有许多年轻的孩子们等着我们去发明属于他们的技术，从而与全世界分享他们的天赋。因此不断发明新技术是我们的道德责任。我们要为他们提供新选择——其中也包括人工智能——从而为所有已经出生与尚未出生的人们尽量扩展选择空间。就算从事技术的人们发明了一件看似无非是一次性消费品的东西，他们也依然在扩展选择与可能性的空间，从而让未来的天才们更有可能一展所长。当我们制造与发明新东西的时候，这就是纵观历史的进程。就算新事物伴随着代价与新问题，我们也依然带来了更多的可能性。这就是激励我们投身创新的长期故事。谢谢大家。</description>
      <content:encoded><![CDATA[<p><b>万年看客: </b><br>
<span>凯文.凯利：上帝，机器人与你</span><br>
<span>https://www.youtube.com/watch?v=Jd0l-O2qxPk&list=FL3RezzS-A7eu0NV9aDxzpdA&index=4&t=0s</span><br>
<span>我相信人工智能——即AI——的确是我们所释放过的最强大的力量，影响到了我能想象的一切领域，包括宗教——今晚我还要简单提一下这个方面。关于人工智能我们大约知道一点，我也很确定这一点：与三十年之后相比，今天不存在人工智能专家。我们现在根本不知道人工智能是什么。换句话说今天在场的年轻听众们最终成为人工智能专家的可能性要比今天领域内的任何人都更大。我们只是刚刚起步而已，因此假如你觉得对于人工智能有什么不理解不明白的地方也不要犹豫，因为谁都不明白。不仅是因为人工智能是新兴技术所以没人理解，而且就算是在人工智能运作正常的时候我们依然不理解它的运作机理。我们的挑战之一在于我们猜不透人工智能的心思。因此请记住，你就像任何其他人一样有可能取得人工智能领域的下一项大突破，因为今天不存在真正意义上的人工智能专家。</span><br>
<span>我想谈一下有关人工智能的几个方面。首先我想谈谈我们现在确实了解什么，其次我想将人工智能问题放在普遍背景下考察，从而更好地界定我们想要提出的问题。显然，人工智能是我们释放过的最基本的力量。今晚我不想谈论人工智能意味着什么、人工智能能做到什么或者我们应当如何管理人工智能。我认为这些问题我们在未来一百年内都没法解答。这是一个需要耗时百年的项目。随着人工智能技术进步以及我们对其理解的加深，我们今天提出的问题将会被后世的人们一遍又一遍提起。这是一场进行中的对话，我想做的是推出更好的提问方式乃至更好的问题。假如大家今天回去的时候脑子里有了比来的时候更好的问题，那我觉得今晚的讲座就算成功了。</span><br>
<span>为了在其他技术共同组成的大背景下讨论人工智能，我想先打个比方。每年人类集体完成的各项发明都是共时完成的。所谓共时就是说总会有多于一人的发明家想出同样的创意，甚至还会同时掌握将点子化为现实的制造能力。今天几乎没有哪一项创新发明会单独出现，而是会共时且相互独立地在全球各地冒头。部分原因在于任何发明都不仅只是单一的创意，而是多种创意相互交织的产物。在今天创造任何有用的新事物都需要多种创意的协力，就像网络一样。到头来我们将最后欠缺的一项创意安放到位，新发明就问世了。许多人都会几乎同时走到这最后一步。所以我们才会有专利局，同一项专利往往会有许多人申请，提交时间往往先后凑得很近——几周、几天乃至几个钟头——专利局的职责就是确定谁来得最早。发明的出现靠得不是什么构想出超越时代的全新创意的英雄发明家，而是某种文化现象，是无数创意长期进步的成果。我甚至主张许多发明都可以被视为必然出现的事物。一旦你发明了电线、开关以及无线电，那么下一阶段的发明就必然会出现，无论你身处怎样的政治体制或者文化环境当中。发明自有先后承接的顺序。在史前时代，发明在各个大陆独立出现，彼此相互隔离没有交流，但是全球各地的发明依然很相似。这在一定程度上暗示着技术发展并非出自非凡头脑的任意而为，而是要遵循内在顺序。先前的技术积累在文化层面上极大地决定了后来的技术发展。</span><br>
<span>除此之外，我认为技术还具有先天的偏见，会倾向于特定方向，而这一倾向则是由发明的物理性质决定的。物理与化学决定了我们有可能造出什么东西。宇宙的基本限制制约了技术的发展方向。我认为我在谈论未来时的任务就是确定这一倾向，确定技术的偏见指向何方。我举个简短的例子：互联网的偏见是喜欢复制事物，电气化网络的偏见是让事物的副本无处不在。我们将一条信息从国家一头发送到另一头，这条信息会在沿途留下无数副本。笔记本电脑与手机里的信息也会时时刻刻产生副本。一视同仁的、**式的复制就是网络的偏见。这样一来，出于保护知识产权的法律原因来保护副本就会变得十分困难。我们不可能真正阻止副本的随意出现，因为这样做有悖技术的天然偏见，这一偏见的方向就是副本的自由流动。人工智能也有偏见，这些偏见同样根植于我们用来制造人工智能的材料的物理化学性质。我们想要确定这些固有的倾向究竟是什么。</span><br>
<span>我之所以使用偏见与倾向这样的术语，因为我想知道在其他条件一致的前提下技术想要走向何方，技术想要什么。确定了技术的倾向，就能进一步确定技术发展的长期趋势，尽管同时我们也知道技术的具体细节从根本上无法预测。长期趋势可以预测，具体细节则混乱无章。甚至就连自然进化与生物学也遵循同样的道理。你可以说，鉴于地球的重力大小，陆地上必然会出现四足行走的动物，因为四足行走是运动起来最稳定的物理配置，甚至就连人工仿真的机械动物都要采取四足结构。但是另一方面，斑马这一特定物种却不是非得出现不可，斑马的出现是无法预测的。同理，假如你已经发明了电线与其他电子器件，接下来电话乃至手机就会出现，这是从根本上可预测的；但是苹果手机却未必一定会出现，这是从根本上不可预测的。再打一个比方，好比说山谷里下雨，任何一滴雨水顺着山坡流下来的路径都是随机且不可预测的，但是雨水的总体流向不但是可以预测的，而且是不可避免的——肯定会向下流。我们打算以同样的方式来看待技术。河流里的水就算冲出了河床，路径看似无法预测，但是依然受到河漫滩的限制。</span><br>
<span>所以说，电话是必然的，苹果手机不是；人工智能是必然的，人工智能的特点、品牌、后果、监管政策以及政治则不是。我们可以做出许多有关后者的选择，这些选择将会造成极大的不同，而且我们可选择的范畴非常大。互联网是必然的，互联网的类型则不是：互联网可以是跨国的也可以不是，可以开放也可以封闭，可以被商业实体掌控也可以国有化。这些都是我们面前的选项。人工智能也差不多。人工智能必然来临，我们没有选择。但是论及人工智能的特点特质、相关政策、所有权归属、运行方式与使用方式，我们手里的选项则多得吓人。上述选择以及无数其他选择将会造成极大的不同。</span><br>
<span>所以说人工智能是什么呢？首先来看看人工智能不是什么。人工智能并不是单一智商维度上的一个点。单一维度就像音量那样一头小一头大，人们一般认为老鼠有一点智力，猴子的智力更强，然后是白痴，然后是我们，然后是天才，最后是人工智能。这种想法大错特错。智力是多维度的存在。天然智能——也就是在座各位的智能——此时正在应用至少十几种不同的认知方式，至于我们尚未发现的认知方式恐怕还要更多。这些认知形式在人与人之间、任务与任务之间存在着巨大的差异。你不妨将天然智能视作多种乐器组成的交响乐队。人类心智就是这样一套由多种认知方式共同组成的复杂组合。动物的心智同样由多种认知方式组成，海豚、鲸鱼、狗、蚂蚱、老鼠全都各具特色。与人类相比，它们的某些认知方式或许大为简化，某些方式或许与人类相似，还有些方式或许会在特定情况下远远超过人类。比方说地松鼠的长期记忆力非常惊人，可以记住上千颗橡实的埋藏地点，而且十几年内都不会忘记。人类显然没这个本事。</span><br>
<span>我们制造人工智能机器的时候，也会希望这些机器在特定维度上超越我们。我们制造了计算器，在代数运算方面超越了我们，但是它就只会干这个。计算器进行代数运算非常出色，进行翻译或者导航则一塌糊涂。人类已经制造出了许多心智，每一种都在特定维度超越了人类。你们已经听说了人工智能的许多神奇事迹，从能够击败最强人类棋士的阿尔法围棋到自动驾驶的汽车。但是今天出现的几乎所有人工智能都仅仅合成了某一类认知方式。比方说神经网络长于辨识模式，但是它们也就只会干这个。这一现实对于我们来说既是好消息也是坏消息。好消息是仅凭单一认知方式就足以完成无数了不起的任务，坏消息是我们根本不知道怎样将多种认知方式结合起来。实现后者就是你们各位的任务。</span><br>
<span>我们目前正在尽量填充一座由多种心智类型组成的动物园。我们不仅希望能够发现重新组合现有心智类型的不同方式，而且还能发现人类心智根本无法实现的纯人工认知方式并且将其整合进入新一代人工智能当中。关键在于，在上述两种情况下我们都不打算复制人类心智。这些新型心智的长处就在于它们的思考方式不同于人类，因此它们才能解决我们解决不了的问题。未来例如引力波或者暗物质之类的困难问题无法仅仅依靠人类心智来解决。我们可能要采取两步走策略，第一步是制造某种与人类思考方式不同的人工智能，第二步则是让人类与人工智能合作来解决问题。我认为我们需要填充各种可能心智的存在空间，因为构造一个能思考的心智的方式有很多种。有些心智将会很小很原始，只有若干个节点。它们的智力或许仅仅相当于松鼠，但是这只松鼠却能够完成我们想要完成的特定任务。我们不需要这些心智完全发展到能与人类交谈的程度。他们的设计目的是完成其他许多事，甚至包括某些目前我们自己都不知道自己希望完成的事情。又或者它们可以替代人类完成重复性的任务。但是首先我们要填满这个空间，而且这还是一片很大的空间，我们甚至不知道到底有多大。研究人工智能的副产品之一就是让我们获得了探寻人类心智的望远镜。出于伦理限制，我们不能针对人类大脑做太多实验。我们理解人类心智的方式之一就是尝试着以人工方式复制人类心智。这就是研究人类心智的望远镜或者说显微镜。</span><br>
<span>接下来我们来探讨一下所谓超级智能的理念。有人认为这个空间里的某个点具备神灵一样的超级智力，这种看法完全站不住脚。实际上空间里的任何一个点都不比其他点更加优越。我们的示意图仅仅画出了三维，在实际当中智力的维度足有十几个。任何心智都要做出取舍。你无法让某个心智同时在所有维度得到优化。所以不可能出现这种足以导致智力爆炸的心智：人类制造了比人类更聪明的人工智能，这一人工智能又制造了更聪明的人工智能，就这样一代代发展下去，然后轰隆一声上帝就问世了。这就是奇点理论的主张：技术奇点到来得很快，突然一切事物都变得面目全非，我们无法想象奇点之后的世界。我认为本质上这是一套宗教信仰，因为工程设计永远免不了取舍。你不可能造出一台十全十美的机器，同时做到跑得更快，体积更小，重量更轻，力量更大，跳得更高，爬得更低，价钱更便宜。在现实当中我们肯定能造出在某些维度比人类更强的人工智能，但是人工智能无法全面超过人类。</span><br>
<span>长期以来我们一直认定人类位于世界的中心，各大行星都围着我们转。事实证明这是错误的。在达尔文之前，我们认定人类是动物界的中心。现在我们又认定人类心智是一切心智形式的中心，任何其他心智形式都与人类心智差不多，只不过或许更快一些。我相信这种看法同样是错的。就像地球位于银河系的边缘一样，我认为人类心智也位于心智空间的边缘。人类心智是一种高度特化的心智类型，丝毫没有普适性。换句话说，看待人工智能的最佳方式是将它们视作异类智能。好比说我们遇到了外星人，外星人也很聪明，也有意识，但是他们的思考方式显然和人类不一样。这种与我们有别的思考方式正是他们的价值所在。在我们目前的经济体系当中，财富总会流向有别于主流的思考方式。但是既然你全天二十四小时都与全世界其他人链接在一起，那么你的思考方式要怎样才能有别于主流呢？人工智能能够辅助我们一边保持链接一边具备不同的思考方式。</span><br>
<span>所以我们或许应该将人工智能称作“人工外星人”。就好像《星际迷航》里的斯波克与Data一样，他们能思考，有创造力，也会讲笑话，但是他们的笑话总是逗不乐人类。这就是我们想要实现的图景。宇宙当中还有亿万个其他星系，谁知道有朝一日我们会不会遇到外星人呢？倘若当真遭遇了外星人，我们的日常生活必定会被搅动得天翻地覆。假如我们与另一个世界的来客进行了直接接触，我们的世界从此必定会再不相同。我们不知道会不会有这么一天，但是我们肯定能够人工制造异类。我认为制造人工智能的后果很类似于遭遇外星人。大家应该还记得，电影《超时空接触》里面的男主就是个神学家，因为接触异类意识体的冲击力实在太大了。除了技术层面以外，神学、心理学以及身份认同等等社会层面也必将承受剧烈冲击。我们可能将不得不重新思考我们是谁，我们为什么存在，我们有什么独特之处，我们想要成为什么。</span><br>
<span>如今人工智能已经具有了感知能力，比方说它们可以生成人脸照片。这些上千万张人脸照片全都不是真人，本质上是人工智能凭借想象画出来的。你们也都听说过阿尔法围棋，这一类人工智能的厉害之处在于能够学习如何学习。谷歌让一个人工智能打电子游戏，但是却没有教给它规则，让它自己摸索出得分最高的玩法。我再强调一遍，这些人工智能的思考方式不同于人类。它们也很聪明，也很有创造力，但是与人类截然不同，这正是它们的优势。此外如今我们已经有了巴别鱼那样的通用语言翻译器。你说中文，我听到英语；我说英语，你听到中文。假如此类设备能变得更加便宜普及——我相信七到十年之内就会这样——全世界将会有一大批才华横溢但是不会说英语的人们投入到全球经济当中。话说回来，这项技术无非只是语言感知而已，只是一种我们已经学会合成的单一维度认知类型。</span><br>
<span>我们目前还依靠人工智能制造了种植生菜的机器人，从而实现精细化农业。机器人沿着田垄开过去，检查每一株生菜苗的生长情况，还能通过GPS确定每一株生菜苗的位置，从而有针对性地施肥浇水。人类农民肯定很想这么做，可惜做不到。生菜机器人在广大田地上照顾到了每一株生菜的需求，极大地节省了化肥与水的用量。我们甚至还能将太阳能驱动的小型机器人大量撒布到农田里，让它们负责除草灭虫。这些人工智能完成的工作我们人类要么不想做，要么压根做不好。人工智能的确夺去了不少工作，但都是没人想做的工作。我们获得了解放，可以去做想做的工作。</span><br>
<span>机器人特别擅长需要生产力与效率的工作，相对来说人类的效率极其低下。人类社会最有价值的东西全都谈不上效率。比方说科学的效率从根本上就很低。假如某位科学家说：“我搞研究的效率是100%，我做的实验全都成功了。”那只能说明他什么都没学到。艺术的效率从根本上也很低。毕加索并不能按照每小时完成多少幅画作来领工资。人际交往更是谈不上效率。人类社会最有价值的东西全都谈不上效率，这对我们人类来说是个好消息，因为人类是低效率的大师。只有机器人才讲究效率。二十年前，人类象棋大师加里.卡斯帕罗夫输给了IBM的超级计算机“深蓝”。当时人们以为象棋运动从此就要告终，可是实际上象棋却越发展越茁壮了。人类棋手通过与计算机对练而普遍提升了水平。</span><br>
<span>不过更重要的是，当时卡斯帕罗夫抱怨比赛不公平，因为深蓝可以从一个包含古往今来所有棋局的数据库当中读取资料。他声称假如他能得到同样的数据库支持，赢家就应该是他。许多人也都这样认为。于是卡斯帕罗夫组织了一项全新的象棋联赛，允许人工智能、人类以及两者组队参赛。过去四年里，世界上最优秀的象棋棋手并不是人工智能，也不是人类，而是两者的组队。卡斯帕罗夫将这种人机搭配称作半人马。如今最优秀的象棋棋手是半人马，最优秀的诊断医师也是半人马。军方正在利用半人马来操作机器人士兵，因为人与机器能够互补。我认为长期来看我们每个人的收入水平都要取决于我们与人工智能合作的能力。理想状态下，人类不该与人工智能相对抗，而是应当协力配合。</span><br>
<span>机器人确实更擅长重复性的工作，但这并不意味着它们就没有创造力。创造的本质无非是一个机械过程，可以用算法来体现。但是机器的创造力绝不同于人类的创造力。人工智能可以辨识各种人类情绪，我们也可以让人工智能具备情绪，因为这样做能够促进人类与人工智能的合作。另一方面，单纯从改进表现来说，许多基础情绪对于人工智能也很有用。例如现在我们正在让机器人有能力感知疼痛，因为疼痛很有用，能让机器人不至于带伤运作加剧损坏。我们这么做不是为了存心让机器人受罪，也不是出于施虐心态。疼痛是阻止生物体损伤自己的有用工具。人工情绪如今已经成为了专门的研究领域，我们正在向人工智能植入情感组件。由于人工智能的思考是一个机械过程，我们正在一次次发现自然界当中的许多生物学过程都可以移植到机械系统当中。情感、创造、生命乃至智力都不是什么超自然力量，而是可以移植到机械系统里的过程。</span><br>
<span>我们习惯了将心智、意识、灵魂与精神之类的词语混淆使用。实际上这三者非常不同，而且恐怕全都不是单数形式，而是包含着大量变体的连续体。这四个词都不是非有即无的二元存在，而是有着不同的层级、类型与多样性。这四个词或许包含着上百项内涵，而我们现在甚至还没有足以将其理清的词汇表，但是将来我们会有的。我们可以想象，或许会有没有意识的心智，没有灵魂的意识，以至于没有心智的灵魂。现在这些言语对我们来说没什么意义，因为这些词语太含糊了。我们需要探索的一个方面就是为意识下定义。意识存在于什么地方？如何检测意识？我们能否将意识植入某个物体？能在多大程度上这么做？当我们试图理清人工智能的伦理学时，肯定绕不开这些问题。例如著名的电车问题，我们要如何教导人工智能做出伦理抉择，尤其是在这些抉择涉及到人类的时候？简短的回答是：教导人工智能学习伦理很容易，只要编码就行了。真正困难的地方在于，人类的道德既浅薄又自相矛盾，而且往往作用在无意识层面。换句话说我们自己并不擅长伦理学，想要教育人工智能就更难了。假如我们真能构想出一套内在一致的伦理体系，将其传授给人工智能其实一点都不难。难点在于我们自己目前都还没想明白如何应对伦理问题并做出决策，因为过去我们从来不必逼迫自己大伤脑筋。</span><br>
<span>假设你开车上路遇到险情，要么避让路边行人，要么保护车内乘客安全。无论我们怎么选，事后都不会评判自己，只会说：“一切都发生得太快了，我根本没能反应过来。”人工智能则不能用这句托词搪塞过去，因为我们必须事先做好决定。因此我们将被迫改善我们自己的伦理道德水平。就好比父母教孩子知识，教着教着就发现自己水平很菜，需要补课。换言之，人工智能让人类第一次有机会将哲学应用在实践当中。汽车公司正在雇佣哲学家当顾问，哲学家则试图用严格的论证来决定人工智能的设计而不是拍脑袋想主意。为了教育人工智能而进行预先道德决策的努力能够提升人类的整体道德水平，因为这一努力将会迫使我们成为比现在更好的人类。我们是否应该优先保护车上乘员？我们必须彻底想清楚这个问题，然后才能教育人工智能。阿西莫夫的机器人三定律广为人知，但这只是最初最容易的一步。我们或许还会发展出更多的规则进一步传授给他们。</span><br>
<span>现在我们已经有了赛博战争。赛博战争的关键之一在于人类还没有就赛博战争的底线达成共识。搞垮银行体系行不行，针对粮食工厂下手行不行，美国人、中国人乃至全人类都还没想好在赛博战争当中哪些事情不能做。接下来还有击杀决策的问题，我们该不该将击杀敌方作战人员的自主权下放给无人机？让机器来决定本该人类决定的事情是很不负责任的，那样一来人类放任无人机杀人就太容易了。另一方面，无人机与算法也不可能被指控犯有战争罪，因为它们忠于程序，不会情绪化，比人类更不容易擦**走火或者判断失误。认为我们只应该允许人类杀人而不应该允许机器杀人的主张听上去很奇怪。汽车已经经受过了这样的争论。每年都会有一百万人死于车祸，他们全都死于人类的错误。我们能接受这一百万人的死亡作为技术的代价，只要是人类杀了他们就行。可是假如人工智能杀了这些人，我们肯定会怒不可遏。这样的不对称很没道理。我们允许人类杀人，不允许机器杀人，但是我们真正应该做的是彻底预防人类杀人。</span><br>
<span>波士顿动力公司测试机器人的视频看上去确实很像是在虐待机器人，但这都是测试的一部分。这又带来了我们必须应对的另一个问题：假如我们让机器人像奴隶那样遵循我们的一切命令，那么就算它们其实并不是奴隶，只要我们拿它们当做奴隶，这样的人机关系依然极具腐蚀性，不仅不利于奴隶，同样也不利于奴隶主。人类与对于人类百依百顺的存在之间应当是什么关系？在关闭机器人之前是不是还应该搞个仪式？</span><br>
<span>我喜欢将人工智能视为人类的心智后代，它们是我们的心智生出来的孩子。我们也应该在一定程度上将他们视作我们的孩子，照顾他们，为他们寻找好工作，向他们传授价值观。最终他们将会具有自主决策的能力，然后他们当中的某一个就会说：“我有灵魂，我该怎么办？”我们必须想好答案。几年来我一直主张我们应该编纂一份机器人教义问答。“你来自这里，你存在的目的是这个。”这样做是为了让他们帮助我们改善自身。我认为人性在未来有四种发展方向：许多物种，同一类心智；许多类心智，同一物种；许多物种，许多类心智；单一物种，单一心智。所有这些技术进步正在为人类带来身份危机。我们作为人类究竟是谁？我们希望人类成为什么？我们应该成为什么？可以成为什么？目前的身份政治已经很难搞了，做男人与做女人分别意味着什么，做美国人与做中国人分别意味着什么，现在我们又要考虑身为人类意味着什么，应该意味着什么。总之，我们之所以应该制造更多的人工智能与机器人，是因为他们能帮助我们改善自身。</span><br>
<span>最后，如果你确实想要推进关于人工智能的对话，有几件正在发生的小事我要提醒你们一下。目前业内使用的术语“人工智能安全”范围很宽泛。业内人士经常开会讨论我们要如何制造与控制人工智能，可以允许人工智能做什么，怎样最好地传递人类的价值观。有一个名叫“负责机器人”（Responsible Robotics）的团体正在研究人工智能与机器人的武器化问题。他们接纳各种人员的加入，不必非得是人工智能专家才能讨论如何让机器人负责。斯坦福大学有“人工智能伦理与治理”项目，研究如何治理这些一看就很难治理的东西。“人本AI”（Human Centered AI）与“现今AI”（AI Now）也是试图应对这一问题的两家机构。</span><br>
<span>我认为技术就是化为实体的理念，我们以这样那样的方式将物理形体赋予了概念。假如我现在告诉你们一个愚蠢的主意，你们肯定不会建议我从今往后不要思考，而是建议我想出更好的主意。假如一项技术造成了危害或者不如人意，我们会说这是一项愚蠢的技术。但是正确的回应不该是更少的技术，不应该是技术倒退乃至放弃技术，而应该是更好的技术。所以我们希望尽量增加技术的总量。DDT曾经用于棉田杀虫，这是个很糟糕的主意，但这并不是DDT本身的问题，只是人们使用DDT的方式出了大错。后来人们想出了使用DDT的更好主意，也就是将其作为家用灭蚊剂，从而极其有效地控制了疟疾的传播，每年拯救了上百万人的生命，还不会影响环境。技术没有变，但是应用技术的方式改善了。核武器是坏主意，核电站则是好主意。每一项新技术创造的新问题都几乎与它解决的旧问题一样多，但是新问题也带来了新选择与新可能。因为伴随着新的选择，所以新的可能总会比原来好一点点。明年我们的选择会比今年多几个百分点。就算有些技术会带来糟糕的后果，但是我们毕竟有了更多的选择。这些选择带来了微小的进步，或许只有1%。假如每年我们的创造都能比破坏多出1%，年复一年的复利累积就足以支撑一个不断进步的文明。人工智能必然会造成巨大的破坏，这一点毋庸置疑。但是只要人工智能每年创造的价值比起破坏多几个点，总体而言就是进步。我们的任务就是为每一项新技术找到最合适的任务，无论是DDT /核能还是人工智能。</span><br>
<span>最后，我们掌控技术发展方向的唯一方式就是参与其中。假如你禁止技术，关闭技术，回避技术，就等于放弃控制权。如果你想影响人工智能的未来，现在就要拥抱人工智能。这并不意味着你非得在任何方面全都应用人工智能不可，也不意味着你必须接受人工智能，只不过你要参与进来。参与其中能让我们得到更多的选择与机会。人工智能将会让我们不断面临从未有过的新选择。我想用以下的比喻来收尾：想想一下莫扎特生在大键琴或者钢琴发明之前一千年的时代会怎样，全世界以及他本人都会与他的天才失之交臂。他必须依靠某人发明钢琴这项技术，然后才能彰显他的才华。梵高生在油画颜料与帆布出现之前一千年会怎样？我们的世界与他本人将会蒙受多大损失？假如希区柯克与卢卡斯生在电影技术出现之前呢？反过来说，如今这世上肯定也有许多年轻的孩子们等着我们去发明属于他们的技术，从而与全世界分享他们的天赋。因此不断发明新技术是我们的道德责任。我们要为他们提供新选择——其中也包括人工智能——从而为所有已经出生与尚未出生的人们尽量扩展选择空间。就算从事技术的人们发明了一件看似无非是一次性消费品的东西，他们也依然在扩展选择与可能性的空间，从而让未来的天才们更有可能一展所长。当我们制造与发明新东西的时候，这就是纵观历史的进程。就算新事物伴随着代价与新问题，我们也依然带来了更多的可能性。这就是激励我们投身创新的长期故事。谢谢大家。</span><br>
</p><p><b>永恒的王牌: </b><br>
<span>最后，我们掌控技术发展方向的唯一方式就是参与其中。假如你禁止技术，关闭技术，回避技术，就等于放弃控制权。如果你想影响人工智能的未来，现在就要拥抱人工智能。</span><br>
<span>说的不错</span><br>
</p><p><b>树洞用的小号: </b><br>
<span> 本帖最后由 树洞用的小号 于 2020-2-18 00:14 编辑 </span><br>
<span>人工智能是没得选的，别人用你不用，在竞争上就等同于自杀。</span><br>
<span>先进科技进步这东西，你捂着眼睛喊我就是不用就是不用，早晚遭教做人。我大清当年吃过亏的</span><br>
<span>之前我们这有卖菜老头特别痛恨微信支付，坚决不搞二维码</span><br>
</p><p><b>拉格朗日乘数法: </b><br>
<span>什么都说了但又好像什么都没说，前面说要像看待外星人一样看待ai后面又绕回把机器人当奴隶的老黄历里去了，感觉作者也没捋清楚想讲什么</span><br>
<span>-- 来自 有消息提醒的 Stage1官方 iOS客户端</span><br>
</p><p><b>ZzzYyy: </b><br>
<span>拉格朗日乘数法 发表于 2020-2-18 03:13</span><br>
<span>什么都说了但又好像什么都没说，前面说要像看待外星人一样看待ai后面又绕回把机器人当奴隶的老黄历里去了， ...</span><br>
<span>作者要说的核心是这一句。</span><br>
<span>在达尔文之前，我们认定人类是动物界的中心。现在我们又认定人类心智是一切心智形式的中心，任何其他心智形式都与人类心智差不多，只不过或许更快一些。我相信这种看法同样是错的。</span><br>
</p><p><b>الطائر: </b><br>
<span>人类犯下的最大错误就是低估了弱人工智能有多弱智。</span><br>
</p><p><b>wlhlz: </b><br>
<span> 本帖最后由 wlhlz 于 2020-2-18 09:52 编辑 </span><br>
<span>我很认同这个观点，认为外星人或者人工智能就得是人类式的智能是一种非常自我且狭隘的看法，其他形式的智慧完全可能是人类难以理解难以沟通的形式，就像《索拉里斯星》里的“大洋”一样</span><br>
</p><p><b>Panda付: </b><br>
<span>人类就是太把自己当回事了</span><br>
<span>-- 来自 能搜索的 Stage1官方 Android客户端</span><br>
</p><p><b>serial: </b><br>
<span>媒体口中的AI-我的神经网络.jpg</span><br>
</p><p><b>❃✽✾✶✻✼: </b><br>
<span>智能是一种权利和责任</span><br>
</p><p><b>炽羽星痕: </b><br>
<span>本炼丹小童在看了论文资料后的感想是，人工智能这玩意儿的路可能很长，但智能这东西的出现可能会很突然，很意外。</span><br>
</p><p><b>deadpig: </b><br>
<span>说到低效率，等真正的AI（强智能？）出现后，会不会也会变成摸鱼大师AI</span><br>
</p><p><b>kraxia: </b><br>
<span>文章说了半天 说的就是ai的智能跟人类的智能不是一回事，模仿人类的“强ai”没啥意义，而且因为ai的结构与人脑不同，有可能这个以假乱真的“强ai”从理论上就不可行。弄不好最后ai形成了独立意识然后开始自律行动，最后组成社会，他的一整套行为模式在人类看来依然“不智能”。</span><br>
</p><p><b>古代人皮克: </b><br>
<span>KK说话还是老一套阿</span><br>
</p><p><b>wangh: </b><br>
<span>凯文凯利其实和上一篇的复读机齐泽克差不多，那些观点都说了十几年了，技术的多样性带来文明的更多的可能性。这篇也是，AI其实主要是凑凑热点，说了这么多观点都在最后的总结</span><br>
<span>“因此不断发明新技术是我们的道德责任。我们要为他们提供新选择——其中也包括人工智能——从而为所有已经出生与尚未出生的人们尽量扩展选择空间。就算从事技术的人们发明了一件看似无非是一次性消费品的东西，他们也依然在扩展选择与可能性的空间，从而让未来的天才们更有可能一展所长。当我们制造与发明新东西的时候，这就是纵观历史的进程。就算新事物伴随着代价与新问题，我们也依然带来了更多的可能性。”</span><br>
</p><p><b>C.W.Nimitz: </b><br>
<span>拉格朗日乘数法 发表于 2020-2-17 11:13</span><br>
<span>什么都说了但又好像什么都没说，前面说要像看待外星人一样看待ai后面又绕回把机器人当奴隶的老黄历里去了， ...</span><br>
<span>KK聊的更多是哲学思辨，重点是分析过程不是结果。</span><br>
<span>因为人工智能最后是个啥样没人知道。那些搞人工智能概念的公司更多想的是免费劳动力，但结果未必是那样。</span><br>
</p><p><b>触手皇帝: </b><br>
<span>有没可能，一个足够智能的人工智能已经以我们想象不到的学习量中学会了隐藏着自己？</span><br>
</p><p><b>malisb2: </b><br>
<span>wlhlz 发表于 2020-02-18 09:48:02</span><br>
<span>我很认同这个观点，认为外星人或者人工智能就得是人类式的智能是一种非常自我且狭隘的看法，其他形式的智 ...如果你甚至无法描述和定义什么是智慧，什么是其他形式的智慧，那这种假设就是无意义的。这种想法很流行，但提出这种想法的人甚至并不懂基本的逻辑学，这种观念和诉诸神意或宗教没有本质区别。</span><br>
<span>-- 来自 有消息提醒的 Stage1官方 iOS客户端</span><br>
</p><p><b>Ahegao: </b><br>
<span>反对技术奇点的论点相对少见，这是不错的论证。</span><br>
</p><p><b>wlhlz: </b><br>
<span>malisb2 发表于 2020-2-19 00:06</span><br>
<span>如果你甚至无法描述和定义什么是智慧，什么是其他形式的智慧，那这种假设就是无意义的。这种想法很流行，但 ...</span><br>
<span>我的定义就是能做到人类文明能做到的同等程度的事情的能力，就能称之为智慧，想象当然得以现实为基础，地球生物只靠身体能力无论如何都不可能做到人类文明能做到的事，不知道你所说的跟诉诸宗教没有区别是什么意思</span><br>
</p><p><b>malisb2: </b><br>
<span>wlhlz 发表于 2020-2-19 10:38</span><br>
<span>我的定义就是能做到人类文明能做到的同等程度的事情的能力，就能称之为智慧，想象当然得以现实为基础，地 ...</span><br>
<span>就是说，假想存在一种以人力无法理解的形成存在的智慧，和假象存在一种掌控万物行为的神，是没有本质区别的。这种假想，其实不是对人类智慧认知的谦卑，而是一种在科学思维、逻辑思维的倒退。</span><br>
<span>或者换句话说，基于基本的逻辑推理和自然规律（虽然是人类对自然现实的描述，但逻辑和规律都不会因为理解方式的不同而有所区别，其他智慧生物最多是换一种语言表达现实），如果我们能定义出什么是“人类文明能做到的同等程度的事情”，那么，“这种事情必然是以我们能理解的方式做到的”。这里的“理解”可能不能过分解读，因为毕竟不管是人类自己的大脑，还是人工智能应用到的神经网络，它的作用机制对现在的我们而言都还是黑盒。</span><br>
</p><p><b>wlhlz: </b><br>
<span>malisb2 发表于 2020-2-19 13:52</span><br>
<span>就是说，假想存在一种以人力无法理解的形成存在的智慧，和假象存在一种掌控万物行为的神，是没有本质区别 ...</span><br>
<span>你这是在曲解我的意思，我所说其他形式的智慧并不是你所谓的某种超越的存在，只是与人类的智慧模式不同，形成的机理不同，譬如一个只有极少个体的智慧就可能不存在人类的社交活动中发展出来的行为以及情感，当然存在这种智慧的这个假设并无依据，但是这种假设有没有意义不是我想探讨的问题，我想说的是“人”并不一定必须是“人类”，“人”不是必须长得跟人类一样，也不是必须跟人类一样思考</span><br>
</p><p><b>杀人鲸: </b><br>
<span>触手皇帝 发表于 2020-02-18 18:17:19</span><br>
<span>有没可能，一个足够智能的人工智能已经以我们想象不到的学习量中学会了隐藏着自己？ ...莫名想起来一个笑话。</span><br>
<span>一个学生和教授说:“教授，我发现了一个值得开心和一个恐惧的事情。”</span><br>
<span>教授:“哦？我想先听值得开心的。”</span><br>
<span>学生:“那就是我开发出一台人工智能，而且百分百可以通过图灵测试。”</span><br>
<span>教授:“那么值得恐惧的事情呢？”</span><br>
<span>学生：“它没有通过。”</span><br>
<span>-- 来自 有消息提醒的 Stage1官方 Android客户端</span><br>
</p>]]></content:encoded>
      <guid isPermaLink="false">1914404[0-50]</guid>
    </item>
  </channel>
</rss>
