<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>为何特斯拉侧撞卡车Bug再次致死无法避免</title>
    <link>https://bbs.saraba1st.com/2b/</link>
    <description>为何特斯拉侧撞卡车Bug再次致死无法避免</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 09 Jul 2020 20:14:32 +0000</lastBuildDate>
    <item>
      <title>为何特斯拉侧撞卡车Bug再次致死无法避免[50-100]</title>
      <link>https://bbs.saraba1st.com/2b/thread-1834981-1-1.html</link>
      <description>为何特斯拉侧撞卡车Bug再次致死无法避免&#13;
 本帖最后由 xburke 于 2019-5-28 13:27 编辑 

原帖 https://zhuanlan.zhihu.com/p/66362276
&#13;
“只要发生事故的可能性存在，不管可能性多么小，这个事故迟早会发生的。”——墨菲定律
&#13;
本周，美国NTSB(国家运输安全委员会)公布了2019年3月1日美国佛罗里达州发生的特斯拉自动驾驶致死事故的初步调查结果。事故中，该特斯拉Model 3以110公里每小时(限速90公里每小时)的速度从侧向撞击了一辆正在穿过马路的白色拖挂卡车：撞击当时车辆处于自动驾驶模式，但司机以及特斯拉的Autopilot系统都未作出任何回避动作，导致车子撞击并从卡车下方穿过，车子上半部分被切掉（如图），50岁男性司机当场毙命，该车滑行了约500m后停在了路中间的绿化带里。https://pic4.zhimg.com/80/v2-53467a20750bad8008ab17dcbf37e63f_hd.pnghttps://pic4.zhimg.com/80/v2-11962149384968058ade271101705b03_hd.png
&#13;
这起事故单独看似乎并不特别显眼，毕竟Autopilot致死事故已经发生多起。但这起事故却与第一起特斯拉Autopilot系统致死事故如出一辙：2016年5月7日弗罗里达州一位名叫Joshua Brown的40岁大哥开着Model S同样钻到了一辆正在过马路中的白色拖挂卡车的下面并变成了敞篷的Tesla Roadster（如图），司机当场死亡。https://pic3.zhimg.com/80/v2-9427acadf88d729809b4cf0d05052d62_hd.jpg
&#13;
https://pic2.zhimg.com/80/v2-9dc3bd7b5ca09c80dfeda215b5edffed_hd.jpg这起发生在2016年的事故中，驾驶员以及特斯拉Autopilot系统同样都未对横在马路中间的卡车进行任何有效的反应（转向或减速）。可以说，面对白色拖挂卡车过马路这个场景，时隔2年9个月特斯拉并未有效地解决这个Bug，马路中横置白色卡车成为了特斯拉自动驾驶系统的“顽疾”。本文暂不谈驾驶员是否应该时刻保持警惕，随时接管。但我们依旧想知道，为什么经过了近3年的发展，1次重大传感器方案升级，3次计算平台升级以及数次重大软件版本升级，特斯拉还是无法解决这一已知致死（足够严重）的Bug？
&#13;
两次事故之间特斯拉做了什么首先我们对比一下2016年出事的Model S与2019年出事的Model 3在自动驾驶配置上的异同：
&#13;
https://pic4.zhimg.com/80/v2-d66889e50f580443995a8f80c72dcf1f_hd.png
&#13;
可以看到，特斯拉通过传感器以及计算平台进行了非常大幅的改进。传感器方面。参与感知的摄像头从1个升级到了7个。从约720p分辨率升级到了约1080p的分辨率。通过前向的3个不同焦距的前视摄像头，从原理上希望可以解决侧向白色卡车的检测问题——通过广角镜头比较完整得看到白色卡车的全貌，从而将其与桥梁/广告牌区分开并进行有效检测。此外，将毫米波雷达安装位置提高到了牌照侧面而不是在牌照下方，并更换了毫米波雷达的供应商。以笔者的了解，大陆ARS毫米波雷达可以支持更多目标点的同时跟踪，并且在相邻车道的有效监测距离上有更好的效果。
&#13;
https://pic2.zhimg.com/80/v2-ef2691a7a97f0032aed265f893ed7185_hd.png
&#13;
这套传感器被特斯拉工程团队认为是可以满足当前自动驾驶所需的一套传感器配置，并被大量安装在所有特斯拉的产品中——无论是Model S 3 X Y，他们的自动驾驶传感器配置都是一致的。计算平台方面，经过2次大幅的重新设计，其计算性能已经提升了很多。但依旧无法满足计算需求：当前的计算平台可以支持6路图像的实时感知（暂时舍弃了长距离前向摄像头），并且只有1路中距离前向摄像头拥有比较高的感知帧率，其余5个摄像头都降频进行处理。笔者认为降频的主要原因是当前的计算平台无法支持如此多的实时图像处理，所以不得已而进行了取舍。与此同时，特斯拉也在研发全新的“全自动驾驶”计算平台，并于2019年4月22日对外发布。该计算平台外部统称FSD（Full Self-Driving）全自动驾驶平台，内部称为HW 3.0版本。其使用自研的SoC芯片对计算能力以及算法进行统一的构架以及性能优化。不过在2019年3月1日事故中的特斯拉Model 3尚未升级为该版本的计算单元。https://pic4.zhimg.com/80/v2-ea37967b2e514f28ff5d5207c609f33b_hd.png虽然特斯拉做了非常多的改进与提升，但为什么这个首次致死的Bug还是没有通过这些方案解决？笔者尝试从一个自动驾驶工程师的角度叙述可能的原因，以及后续避免此类车祸的方式方法。为什么还是漏检了由于在事故发生的时刻，系统并未进行任何有效的规避操作，可以认为系统存在漏检。首先我们从整个系统入手，分析为什么产生漏检：从传感器方面，我们认为当前Tesla的传感器配置只有前向广角近距离摄像头可以有效“看到”正在横过马路的白色拖挂卡车，其余的传感器与2016年版本并无区别：毫米波从拖挂箱体下侧直接穿过；其他前视摄像头只看得到拖挂卡车的局部（悬空），容易误认为是悬空的广告牌或桥梁；超声波雷达监测距离过近，对该场景无效。而基于单目摄像头获取深度也受到拖挂车白色涂装影响无法有效提取特征点，从而无法进行有效的深度恢复(Structure from Motion, SFM)。所以，当一辆特斯拉面前有一辆正在穿过马路的白色拖挂卡车时，正向广角镜头是整个感知系统唯一可用的输入。在这唯一可用传感器的情况下有两个问题：首先，广角摄像头由于视角过大，导致目标可检测距离变短。基于网上公开的2018年10月Autopilot 18.39.6 版本，在同样的算法下，中距离镜头可以得到约100m的有效检测距离，但广角镜头只能看到约50m处的车辆（并且还存在未成功融合的问题，同一辆车通过两个摄像头识别的结果产生了不同的ID以及不同的距离）。在本次事故中，当车辆以30 m/s的速度行驶时，留给系统的反应时间只有短短的2s，这远远满足不了刹车所需的时间与距离。其次，在这一场景上我们的感知输入，也就是传感器配置失去了冗余。在一旦检测失败或传感器失效，这一场景将没有任何可靠的解决方法。从墨菲定律的角度出发，这一Bug的重现完全在意料之中。由于本次事故车辆并未进行任何的规避行为，我们可以认为，在事故中Autopilot系统存在检测失效的问题，这是本次事故的核心原因。从计算平台及感知模块方面分析，当前的HW 2.5基于双Nvidia Parker SoC加单块GP106独立显卡的方案，在多达8路2Mpixel@30fps的摄像头输入下性能捉襟见肘。最终其性能只能支持1路高速视频流及5路低速视频流的实时处理。很不幸广角摄像头被放在了低速视频处理的流水线中，这进一步引入了延迟。从被动安全角度，一旦特斯拉从拖挂车下方穿过，几乎没有任何方式可以保证车上人员的被动安全，因为在这个场景中，没有任何车体溃缩和缓冲的空间与时间。车上人员的死亡在该类事故中的概率非常高。
&#13;
如何解决此类Bug让我们尝试从技术路径上寻找特斯拉解决此类Bug的可能性：首先，传感器方面，需要增加传感器的冗余度，以保证在该场景中，有至少两种传感器可以有效检测出目标物体，使得系统有足够的输入进行判断并作出有效规避。两种传感器代表通过不同测量方式，测量不同物理量的两种传感器，例如摄像头与红外摄像头（波长不同），或摄像头与毫米波雷达（波长及测量方式不同）等，同时也要保证不同传感器间检测距离，可视角度以及分辨率的匹配。其次，需要对道路进行更加细致的分类以及标注，以增加语义道路信息。我们发现，这两起事故都发生在类似高速但有交叉路口的道路上。但在特斯拉的Autopilot系统中并未对两种道路情况进行区分，其决策依据也没有区别。只有通过语义地图，我们才可以在传感器检测范围覆盖前了解到前方的路口以及可能的来车方向，以此提前对来车方向进行检测，并做出减速/预刹车等行为，来提高系统在此类问题上的安全表现。再次，是强调模拟测试的重要性。在今年Tesla的FSD发布会上，Elon Musk也坦承特斯拉的模拟器无法捕捉到每一种现实中的长尾场景(Long tail of weird things that happen in the real word)，这使得特斯拉无法解决它没看到过的场景。特斯拉的模拟器只能模拟其见过的场景——这意味着，一些人为设定的长尾场景，或有挑战的场景，特斯拉的开发团队无法有针对的对其进行解决。这就使得对于特定场景Bug的解决难度非常大，开发人员无法通过对环境的调整进一步测试在特定长尾场景下的系统表现。最后，让我们说说激光雷达的重要性。Elon Musk一直对激光雷达嗤之以鼻，考虑到激光雷达传感器当前的成本以及可靠性，笔者认为，作为一家年产近14万台电动车的车企，放弃激光雷达方案在当前是一个理智的决定。但对于自动驾驶而言，激光雷达又是如此重要，其重要性体现在，1）绝对距离测量。激光雷达是一种3D绝对距离传感器，3D结果是其天然的优势。而通过2D结果对距离进行恢复总有各种问题。例如摄像头恢复出的距离3D信息，其置信度始终无法提高。并且被测物体距离越远，可靠性越差。这与摄像头的2D检测本质原理有关。Tesla在FSD发布会上称，其算法会通过毫米波雷达对距离进行恢复，毫米波雷达作为一个2D传感器有如下问题需要解决：毫米波雷达在距离及角度分辨度上表现不佳，导致传感器融合容易出现漏检的问题，以及毫米波雷达对于切向运动物体（如横向过马路的卡车），其原理决定了毫米波雷达无法准确计算出切向运动物体的速度，从而容易出现毫米波雷达将横向移动物体归类为静止物体导致误检。2）全天候检测，由于阳光对激光雷达有一定干扰，在晚上激光雷达的性能会高于白天的性能。而摄像头正好相反。由于摄像头被动检测的特性，其在没有光照的情况下的表现落差很大。这一点上激光雷达与摄像头有一定互补性。3）制图/定位的绝对优势。激光雷达还有一个特点在于其可以很容易对环境进行3D测量而无需依赖光照以及环境中特征点的分布。这使得基于激光雷达的制图/定位可以达到非常高的精度（10cm级别）且系统计算资源要求较少。而基于图像的重定位精度则需要花费非常大量的搜索计算才能取得一般的重定位精度。上述问题大部分都是传感器的检测原理中的本质上的问题，在实现自动驾驶过程中，我们很难对其进行改变。激光雷达在这些情况中可以很好地与其他传感器进行互补，在降低系统运算复杂度，提升定位精度，检测精度以及检测距离中有不可替代的作用。既然特斯拉的目标是完全的自动驾驶（L4+），那激光雷达是避不开的方式。无论Elon Musk多么不认可激光雷达，当未来激光雷达价格降至1K美元以内时，钢铁侠必会改变思路——毕竟我们无法改变现有传感器的物理检测原理，有一些问题必须通过激光雷达才能可靠得解决。
&#13;
自动驾驶的银弹诚然，自动驾驶技术的发展已经出现了牺牲。但我们不愿意看到的是无谓的牺牲——即在已知问题上反复出错。希望本事故可以提醒特斯拉以及所有从事自动驾驶的工程师们：“只要一套自动驾驶方案有发生事故的可能性存在，不管可能性多么小，这个事故迟早会发生的。”从传感器冗余，激光雷达的布置，高精地图及语义地图的使用，再到模拟器的技术路径以及方案选择上，我们需要想得更加深远，覆盖足够全面，一切以安全为第一考量，避免那“无谓的牺牲”。
&#13;
作者：夹子（硬件组）（图片来源于网络，有任何问题私信联系.）===========================================马斯克：傻子才用激光雷达</description>
      <content:encoded><![CDATA[<p><b>Mr.Cheung: </b><br>
<span> 本帖最后由 Mr.Cheung 于 2019-5-28 18:43 编辑 </span><br>
<span>lilyblack 发表于 2019-5-28 18:01</span><br>
<span>为什么你会觉得无人车出事故找不到责任主体？</span><br>
<span>车辆零部件质量问题导致事故那么责任归零部件供应商，车辆 ...</span><br>
<span>因为世界上不存在完美的系统，哪怕车辆没有质量问题，没有设计缺陷，没有违规操作，一切的一切都没问题，出现BUG也是必然，BUG出现的几率再低也不可能等于零，一旦BUG导致人员伤亡财产损失怎么办，这种情况下你难道要追究程序员的责任？追究制造商的责任？全天下有程序员敢拍胸口保证自己的代码绝对不会出BUG？有制造商敢拍胸口保证自己的产品绝对不会出现故障？如果有，不是傻子就是骗子。</span><br>
<span>这也是为什么“路况”复杂程度比汽车低得多的民用航空、轨道交通领域现阶段都没能完全用自动驾驶取代人类的原因，哪怕很多民航客机或者地铁列车运行起来绝大部分的时间都是在自动驾驶的状态，驾驶人员的操作用机器取代也完全没有难度，但驾驶舱里还是必须有人，就是为了在一旦系统出现BUG的时候手动介入救场或者事后背锅所以说啥时候波音空客都改生产不要飞行员的全自动客机再来扯自动驾驶私家车的蛋吧</span><br>
</p><p><b>sifi: </b><br>
<span> 本帖最后由 sifi 于 2019-5-28 18:58 编辑 </span><br>
<span>红色福音 发表于 2019-5-28 17:20</span><br>
<span>我反正是很乐意见到这些方便人类的新技术进入社会的</span><br>
<span>但是不管你们这些反对派如何破口大骂、在地上打滚、 ...</span><br>
<span>你讲错了，马一龙是我男神，不过这不阻碍我对他的ap还是有疑问，现在我开的老王家的电车好多年了。您先学会开车吧，然后，哪怕您去马家试驾一下呢。</span><br>
<span>—— 来自 Xiaomi MI 9 Transparent Edition, Android 9上的 S1Next-鹅版 v2.1.2</span><br>
</p><p><b>红色福音: </b><br>
<span>中川夏纪 发表于 2019-5-28 18:07</span><br>
<span>马斯克信徒装傻什么呢。</span><br>
<span>马斯克我到还真没想到……</span><br>
</p><p><b>lancerer: </b><br>
<span>躺着不就刮不到了？</span><br>
<span>反正自称无人驾驶</span><br>
<span>-- 来自 能搜索的 Stage1官方 iOS客户端</span><br>
</p><p><b>aegisangel: </b><br>
<span>任何时候都对可能致死的机械或者电子流一道心理防线，它们都是不可靠的</span><br>
</p><p><b>影武者lvmax: </b><br>
<span>以后开自动驾驶时候躺下不就可以了？</span><br>
</p><p><b>dlboy1981: </b><br>
<span>强制大货车两侧安装防撞带呀</span><br>
</p><p><b>wszweill: </b><br>
<span>红色福音 发表于 2019-5-28 02:15</span><br>
<span>制定避让策略必然也是AI快，这个不能质疑</span><br>
<span>电脑至少不会踩着油门尖叫</span><br>
<span>人眼分割识别物体效率非常高。对计算机而言，128X128的RGB马赛克图像就是三万个点，多快好省的分割图像本来就是个难题。随便找一个图像识别网络都是上百层网络运算，1G的CPU大约能1ms跑个128X128的训练过的网络，没有好的优化比正常人反应慢太正常了</span><br>
</p><p><b>朝仓和美: </b><br>
<span>Mr.Cheung 发表于 2019-5-28 18:35</span><br>
<span>因为世界上不存在完美的系统，哪怕车辆没有质量问题，没有设计缺陷，没有违规操作，一切的一切都 ...</span><br>
<span>单说责任划分的话，ai司机和出租车司机区别不大吧。该找谁找谁呗。</span><br>
</p><p><b>Mr.Cheung: </b><br>
<span> 本帖最后由 Mr.Cheung 于 2019-5-28 23:07 编辑 </span><br>
<span>朝仓和美 发表于 2019-5-28 22:54</span><br>
<span>单说责任划分的话，ai司机和出租车司机区别不大吧。该找谁找谁呗。</span><br>
<span>出租车司机本身就是一个可以视作责任主体的正常人类啊，一旦出事，无论出租车公司会不会帮司机出赔偿，对司机本人的责任追究是跑不掉的，哪怕司机在事故中挂了都不影响这一步；AI司机怎么充当责任主体？把车里的AI主机砸了？如果你说全部都归运营公司赔偿的话，这思路不就和当年福特发现汽车油箱有设计缺陷还照卖的逻辑一样咯，反正只要成本划算赔钱了事就好，你觉得这种运营逻辑真的不会被口水淹死么......</span><br>
<span>当然可能大家都知道，资本家大概是不在乎道德谴责的，但我觉得他们肯定不想像当年福特一样被人打上门来索赔然后大出血一波</span><br>
</p><p><b>eyesradar: </b><br>
<span>nexus1 发表于 2019-5-28 14:18</span><br>
<span>eyesight怎么样</span><br>
<span>斯巴鲁车主路过 eyesight是我用过最好的辅助驾驶系统 包括全方向的sensor都非常灵敏 目前5万多公里下来感觉已经人车一体了 </span><br>
<span>唯一的不满就是斯巴鲁那个破后置摄像头 妈的全车都一堆sensor了 摄像头能不能换个分辨率高点的...</span><br>
</p><p><b>wszweill: </b><br>
<span>塔那 发表于 2019-5-28 02:18</span><br>
<span>一个老头，穿反AI衣，开电动轮椅，突然横穿。</span><br>
<span>这已经是蓄意碰瓷而且生怕自己不死了啊。成全了他吧 ...</span><br>
<span>反AI衣服不见得要很离谱。比如白色（什么鬼屏蔽字）老头衫在白色建筑物背景下就具有反AI效果。我国很多街道都喜欢整齐划一刷一个涂装，穿个纯色衬衫就识别不了也是有可能的。</span><br>
</p><p><b>安産型美羽: </b><br>
<span>红色福音 发表于 2019-5-28 18:20</span><br>
<span>我反正是很乐意见到这些方便人类的新技术进入社会的</span><br>
<span>但是不管你们这些反对派如何破口大骂、在地上打滚、 ...</span><br>
<span>你这不是典型的机械僵化思维么。</span><br>
</p><p><b>pilipala: </b><br>
<span>如果全自动驾驶</span><br>
<span>驾驶员横躺在后座撸管是不是能躲过一劫</span><br>
<span>-- 来自 能看大图的 Stage1官方 iOS客户端</span><br>
</p><p><b>幽远ghofar: </b><br>
<span>xdescat01 发表于 2019-5-28 14:45</span><br>
<span>其实我觉得在评价无人驾驶安全性上一直有个很大的问题，为什么评价无人驾驶安全性的基准是绝对安全？难道不 ...</span><br>
<span>然而每个人的出事概率并不等同。假设你开车水平高，出事的概率比平均概率低很多，也比无人驾驶的概率要低。那么现在要你去放弃自己的优势改无人驾驶，真出了什么事儿你去问责公司，人家用一句“出事的概率已经比以前要低了”，你觉得你能不能服气？</span><br>
</p><p><b>亡亡鱼: </b><br>
<span>Mr.Cheung 发表于 2019-5-28 18:35</span><br>
<span>因为世界上不存在完美的系统，哪怕车辆没有质量问题，没有设计缺陷，没有违规操作，一切的一切都 ...</span><br>
<span>想多了 允许责任传导的话车企永远不缺背锅的</span><br>
<span>—— 来自 HUAWEI EML-AL00, Android 9上的 S1Next-鹅版 v2.1.0-play</span><br>
</p><p><b>ykztt: </b><br>
<span>红色福音 发表于 2019-5-28 17:20</span><br>
<span>我反正是很乐意见到这些方便人类的新技术进入社会的</span><br>
<span>但是不管你们这些反对派如何破口大骂、在地上打滚、 ...</span><br>
<span>起码等技术成熟了再来讨论吧，车道保持定速巡航之类的辅助驾驶还是可以的</span><br>
</p><p><b>ykztt: </b><br>
<span>红色福音 发表于 2019-5-28 17:20</span><br>
<span>我反正是很乐意见到这些方便人类的新技术进入社会的</span><br>
<span>但是不管你们这些反对派如何破口大骂、在地上打滚、 ...</span><br>
<span>只是现在不看好而已，真要可以了就用呗，你最多没驾照的朋友开心点而已</span><br>
</p><p><b>xdescat01: </b><br>
<span>幽远ghofar 发表于 2019-5-29 03:56</span><br>
<span>然而每个人的出事概率并不等同。假设你开车水平高，出事的概率比平均概率低很多，也比无人驾驶的概率要低 ...</span><br>
<span>如果一个人觉得自己水平比自动驾驶高，那么他可以自己开车降低事故率，这够不成他反对无人驾驶的理由，因为等到强制必须无人驾驶才能上路或者商业行为已经购买不到可人类操控的新车的地步，无人驾驶技术早就非常成熟了</span><br>
<span>而因为其他无人驾驶车辆的危险行为导致他事故率上升其实说不通，因为现在也没法禁止马路杀手上路，提高平均驾驶水平反而提高了车神的安全率，至少不用提防遇到小概率刷新的一边尖叫一边踩油门的司机</span><br>
</p>]]></content:encoded>
      <guid isPermaLink="false">1834981[50-100]</guid>
    </item>
    <item>
      <title>为何特斯拉侧撞卡车Bug再次致死无法避免[0-50]</title>
      <link>https://bbs.saraba1st.com/2b/thread-1834981-1-1.html</link>
      <description>为何特斯拉侧撞卡车Bug再次致死无法避免&#13;
 本帖最后由 xburke 于 2019-5-28 13:27 编辑 

原帖 https://zhuanlan.zhihu.com/p/66362276
&#13;
“只要发生事故的可能性存在，不管可能性多么小，这个事故迟早会发生的。”——墨菲定律
&#13;
本周，美国NTSB(国家运输安全委员会)公布了2019年3月1日美国佛罗里达州发生的特斯拉自动驾驶致死事故的初步调查结果。事故中，该特斯拉Model 3以110公里每小时(限速90公里每小时)的速度从侧向撞击了一辆正在穿过马路的白色拖挂卡车：撞击当时车辆处于自动驾驶模式，但司机以及特斯拉的Autopilot系统都未作出任何回避动作，导致车子撞击并从卡车下方穿过，车子上半部分被切掉（如图），50岁男性司机当场毙命，该车滑行了约500m后停在了路中间的绿化带里。https://pic4.zhimg.com/80/v2-53467a20750bad8008ab17dcbf37e63f_hd.pnghttps://pic4.zhimg.com/80/v2-11962149384968058ade271101705b03_hd.png
&#13;
这起事故单独看似乎并不特别显眼，毕竟Autopilot致死事故已经发生多起。但这起事故却与第一起特斯拉Autopilot系统致死事故如出一辙：2016年5月7日弗罗里达州一位名叫Joshua Brown的40岁大哥开着Model S同样钻到了一辆正在过马路中的白色拖挂卡车的下面并变成了敞篷的Tesla Roadster（如图），司机当场死亡。https://pic3.zhimg.com/80/v2-9427acadf88d729809b4cf0d05052d62_hd.jpg
&#13;
https://pic2.zhimg.com/80/v2-9dc3bd7b5ca09c80dfeda215b5edffed_hd.jpg这起发生在2016年的事故中，驾驶员以及特斯拉Autopilot系统同样都未对横在马路中间的卡车进行任何有效的反应（转向或减速）。可以说，面对白色拖挂卡车过马路这个场景，时隔2年9个月特斯拉并未有效地解决这个Bug，马路中横置白色卡车成为了特斯拉自动驾驶系统的“顽疾”。本文暂不谈驾驶员是否应该时刻保持警惕，随时接管。但我们依旧想知道，为什么经过了近3年的发展，1次重大传感器方案升级，3次计算平台升级以及数次重大软件版本升级，特斯拉还是无法解决这一已知致死（足够严重）的Bug？
&#13;
两次事故之间特斯拉做了什么首先我们对比一下2016年出事的Model S与2019年出事的Model 3在自动驾驶配置上的异同：
&#13;
https://pic4.zhimg.com/80/v2-d66889e50f580443995a8f80c72dcf1f_hd.png
&#13;
可以看到，特斯拉通过传感器以及计算平台进行了非常大幅的改进。传感器方面。参与感知的摄像头从1个升级到了7个。从约720p分辨率升级到了约1080p的分辨率。通过前向的3个不同焦距的前视摄像头，从原理上希望可以解决侧向白色卡车的检测问题——通过广角镜头比较完整得看到白色卡车的全貌，从而将其与桥梁/广告牌区分开并进行有效检测。此外，将毫米波雷达安装位置提高到了牌照侧面而不是在牌照下方，并更换了毫米波雷达的供应商。以笔者的了解，大陆ARS毫米波雷达可以支持更多目标点的同时跟踪，并且在相邻车道的有效监测距离上有更好的效果。
&#13;
https://pic2.zhimg.com/80/v2-ef2691a7a97f0032aed265f893ed7185_hd.png
&#13;
这套传感器被特斯拉工程团队认为是可以满足当前自动驾驶所需的一套传感器配置，并被大量安装在所有特斯拉的产品中——无论是Model S 3 X Y，他们的自动驾驶传感器配置都是一致的。计算平台方面，经过2次大幅的重新设计，其计算性能已经提升了很多。但依旧无法满足计算需求：当前的计算平台可以支持6路图像的实时感知（暂时舍弃了长距离前向摄像头），并且只有1路中距离前向摄像头拥有比较高的感知帧率，其余5个摄像头都降频进行处理。笔者认为降频的主要原因是当前的计算平台无法支持如此多的实时图像处理，所以不得已而进行了取舍。与此同时，特斯拉也在研发全新的“全自动驾驶”计算平台，并于2019年4月22日对外发布。该计算平台外部统称FSD（Full Self-Driving）全自动驾驶平台，内部称为HW 3.0版本。其使用自研的SoC芯片对计算能力以及算法进行统一的构架以及性能优化。不过在2019年3月1日事故中的特斯拉Model 3尚未升级为该版本的计算单元。https://pic4.zhimg.com/80/v2-ea37967b2e514f28ff5d5207c609f33b_hd.png虽然特斯拉做了非常多的改进与提升，但为什么这个首次致死的Bug还是没有通过这些方案解决？笔者尝试从一个自动驾驶工程师的角度叙述可能的原因，以及后续避免此类车祸的方式方法。为什么还是漏检了由于在事故发生的时刻，系统并未进行任何有效的规避操作，可以认为系统存在漏检。首先我们从整个系统入手，分析为什么产生漏检：从传感器方面，我们认为当前Tesla的传感器配置只有前向广角近距离摄像头可以有效“看到”正在横过马路的白色拖挂卡车，其余的传感器与2016年版本并无区别：毫米波从拖挂箱体下侧直接穿过；其他前视摄像头只看得到拖挂卡车的局部（悬空），容易误认为是悬空的广告牌或桥梁；超声波雷达监测距离过近，对该场景无效。而基于单目摄像头获取深度也受到拖挂车白色涂装影响无法有效提取特征点，从而无法进行有效的深度恢复(Structure from Motion, SFM)。所以，当一辆特斯拉面前有一辆正在穿过马路的白色拖挂卡车时，正向广角镜头是整个感知系统唯一可用的输入。在这唯一可用传感器的情况下有两个问题：首先，广角摄像头由于视角过大，导致目标可检测距离变短。基于网上公开的2018年10月Autopilot 18.39.6 版本，在同样的算法下，中距离镜头可以得到约100m的有效检测距离，但广角镜头只能看到约50m处的车辆（并且还存在未成功融合的问题，同一辆车通过两个摄像头识别的结果产生了不同的ID以及不同的距离）。在本次事故中，当车辆以30 m/s的速度行驶时，留给系统的反应时间只有短短的2s，这远远满足不了刹车所需的时间与距离。其次，在这一场景上我们的感知输入，也就是传感器配置失去了冗余。在一旦检测失败或传感器失效，这一场景将没有任何可靠的解决方法。从墨菲定律的角度出发，这一Bug的重现完全在意料之中。由于本次事故车辆并未进行任何的规避行为，我们可以认为，在事故中Autopilot系统存在检测失效的问题，这是本次事故的核心原因。从计算平台及感知模块方面分析，当前的HW 2.5基于双Nvidia Parker SoC加单块GP106独立显卡的方案，在多达8路2Mpixel@30fps的摄像头输入下性能捉襟见肘。最终其性能只能支持1路高速视频流及5路低速视频流的实时处理。很不幸广角摄像头被放在了低速视频处理的流水线中，这进一步引入了延迟。从被动安全角度，一旦特斯拉从拖挂车下方穿过，几乎没有任何方式可以保证车上人员的被动安全，因为在这个场景中，没有任何车体溃缩和缓冲的空间与时间。车上人员的死亡在该类事故中的概率非常高。
&#13;
如何解决此类Bug让我们尝试从技术路径上寻找特斯拉解决此类Bug的可能性：首先，传感器方面，需要增加传感器的冗余度，以保证在该场景中，有至少两种传感器可以有效检测出目标物体，使得系统有足够的输入进行判断并作出有效规避。两种传感器代表通过不同测量方式，测量不同物理量的两种传感器，例如摄像头与红外摄像头（波长不同），或摄像头与毫米波雷达（波长及测量方式不同）等，同时也要保证不同传感器间检测距离，可视角度以及分辨率的匹配。其次，需要对道路进行更加细致的分类以及标注，以增加语义道路信息。我们发现，这两起事故都发生在类似高速但有交叉路口的道路上。但在特斯拉的Autopilot系统中并未对两种道路情况进行区分，其决策依据也没有区别。只有通过语义地图，我们才可以在传感器检测范围覆盖前了解到前方的路口以及可能的来车方向，以此提前对来车方向进行检测，并做出减速/预刹车等行为，来提高系统在此类问题上的安全表现。再次，是强调模拟测试的重要性。在今年Tesla的FSD发布会上，Elon Musk也坦承特斯拉的模拟器无法捕捉到每一种现实中的长尾场景(Long tail of weird things that happen in the real word)，这使得特斯拉无法解决它没看到过的场景。特斯拉的模拟器只能模拟其见过的场景——这意味着，一些人为设定的长尾场景，或有挑战的场景，特斯拉的开发团队无法有针对的对其进行解决。这就使得对于特定场景Bug的解决难度非常大，开发人员无法通过对环境的调整进一步测试在特定长尾场景下的系统表现。最后，让我们说说激光雷达的重要性。Elon Musk一直对激光雷达嗤之以鼻，考虑到激光雷达传感器当前的成本以及可靠性，笔者认为，作为一家年产近14万台电动车的车企，放弃激光雷达方案在当前是一个理智的决定。但对于自动驾驶而言，激光雷达又是如此重要，其重要性体现在，1）绝对距离测量。激光雷达是一种3D绝对距离传感器，3D结果是其天然的优势。而通过2D结果对距离进行恢复总有各种问题。例如摄像头恢复出的距离3D信息，其置信度始终无法提高。并且被测物体距离越远，可靠性越差。这与摄像头的2D检测本质原理有关。Tesla在FSD发布会上称，其算法会通过毫米波雷达对距离进行恢复，毫米波雷达作为一个2D传感器有如下问题需要解决：毫米波雷达在距离及角度分辨度上表现不佳，导致传感器融合容易出现漏检的问题，以及毫米波雷达对于切向运动物体（如横向过马路的卡车），其原理决定了毫米波雷达无法准确计算出切向运动物体的速度，从而容易出现毫米波雷达将横向移动物体归类为静止物体导致误检。2）全天候检测，由于阳光对激光雷达有一定干扰，在晚上激光雷达的性能会高于白天的性能。而摄像头正好相反。由于摄像头被动检测的特性，其在没有光照的情况下的表现落差很大。这一点上激光雷达与摄像头有一定互补性。3）制图/定位的绝对优势。激光雷达还有一个特点在于其可以很容易对环境进行3D测量而无需依赖光照以及环境中特征点的分布。这使得基于激光雷达的制图/定位可以达到非常高的精度（10cm级别）且系统计算资源要求较少。而基于图像的重定位精度则需要花费非常大量的搜索计算才能取得一般的重定位精度。上述问题大部分都是传感器的检测原理中的本质上的问题，在实现自动驾驶过程中，我们很难对其进行改变。激光雷达在这些情况中可以很好地与其他传感器进行互补，在降低系统运算复杂度，提升定位精度，检测精度以及检测距离中有不可替代的作用。既然特斯拉的目标是完全的自动驾驶（L4+），那激光雷达是避不开的方式。无论Elon Musk多么不认可激光雷达，当未来激光雷达价格降至1K美元以内时，钢铁侠必会改变思路——毕竟我们无法改变现有传感器的物理检测原理，有一些问题必须通过激光雷达才能可靠得解决。
&#13;
自动驾驶的银弹诚然，自动驾驶技术的发展已经出现了牺牲。但我们不愿意看到的是无谓的牺牲——即在已知问题上反复出错。希望本事故可以提醒特斯拉以及所有从事自动驾驶的工程师们：“只要一套自动驾驶方案有发生事故的可能性存在，不管可能性多么小，这个事故迟早会发生的。”从传感器冗余，激光雷达的布置，高精地图及语义地图的使用，再到模拟器的技术路径以及方案选择上，我们需要想得更加深远，覆盖足够全面，一切以安全为第一考量，避免那“无谓的牺牲”。
&#13;
作者：夹子（硬件组）（图片来源于网络，有任何问题私信联系.）===========================================马斯克：傻子才用激光雷达</description>
      <content:encoded><![CDATA[<p><b>xburke: </b><br>
<span>为何特斯拉侧撞卡车Bug再次致死无法避免</span><br>
<span> 本帖最后由 xburke 于 2019-5-28 13:27 编辑 </span><br>
<span>原帖 https://zhuanlan.zhihu.com/p/66362276</span><br>
<span>“只要发生事故的可能性存在，不管可能性多么小，这个事故迟早会发生的。”——墨菲定律</span><br>
<span>本周，美国NTSB(国家运输安全委员会)公布了2019年3月1日美国佛罗里达州发生的特斯拉自动驾驶致死事故的初步调查结果。事故中，该特斯拉Model 3以110公里每小时(限速90公里每小时)的速度从侧向撞击了一辆正在穿过马路的白色拖挂卡车：撞击当时车辆处于自动驾驶模式，但司机以及特斯拉的Autopilot系统都未作出任何回避动作，导致车子撞击并从卡车下方穿过，车子上半部分被切掉（如图），50岁男性司机当场毙命，该车滑行了约500m后停在了路中间的绿化带里。https://pic4.zhimg.com/80/v2-53467a20750bad8008ab17dcbf37e63f_hd.pnghttps://pic4.zhimg.com/80/v2-11962149384968058ade271101705b03_hd.png</span><br>
<span>这起事故单独看似乎并不特别显眼，毕竟Autopilot致死事故已经发生多起。但这起事故却与第一起特斯拉Autopilot系统致死事故如出一辙：2016年5月7日弗罗里达州一位名叫Joshua Brown的40岁大哥开着Model S同样钻到了一辆正在过马路中的白色拖挂卡车的下面并变成了敞篷的Tesla Roadster（如图），司机当场死亡。https://pic3.zhimg.com/80/v2-9427acadf88d729809b4cf0d05052d62_hd.jpg</span><br>
<span>https://pic2.zhimg.com/80/v2-9dc3bd7b5ca09c80dfeda215b5edffed_hd.jpg这起发生在2016年的事故中，驾驶员以及特斯拉Autopilot系统同样都未对横在马路中间的卡车进行任何有效的反应（转向或减速）。可以说，面对白色拖挂卡车过马路这个场景，时隔2年9个月特斯拉并未有效地解决这个Bug，马路中横置白色卡车成为了特斯拉自动驾驶系统的“顽疾”。本文暂不谈驾驶员是否应该时刻保持警惕，随时接管。但我们依旧想知道，为什么经过了近3年的发展，1次重大传感器方案升级，3次计算平台升级以及数次重大软件版本升级，特斯拉还是无法解决这一已知致死（足够严重）的Bug？</span><br>
<span>两次事故之间特斯拉做了什么首先我们对比一下2016年出事的Model S与2019年出事的Model 3在自动驾驶配置上的异同：</span><br>
<img src="https://pic4.zhimg.com/80/v2-d66889e50f580443995a8f80c72dcf1f_hd.png" title="https://pic4.zhimg.com/80/v2-d66889e50f580443995a8f80c72dcf1f_hd.png"><br>
<span>可以看到，特斯拉通过传感器以及计算平台进行了非常大幅的改进。传感器方面。参与感知的摄像头从1个升级到了7个。从约720p分辨率升级到了约1080p的分辨率。通过前向的3个不同焦距的前视摄像头，从原理上希望可以解决侧向白色卡车的检测问题——通过广角镜头比较完整得看到白色卡车的全貌，从而将其与桥梁/广告牌区分开并进行有效检测。此外，将毫米波雷达安装位置提高到了牌照侧面而不是在牌照下方，并更换了毫米波雷达的供应商。以笔者的了解，大陆ARS毫米波雷达可以支持更多目标点的同时跟踪，并且在相邻车道的有效监测距离上有更好的效果。</span><br>
<img src="https://pic2.zhimg.com/80/v2-ef2691a7a97f0032aed265f893ed7185_hd.png" title="https://pic2.zhimg.com/80/v2-ef2691a7a97f0032aed265f893ed7185_hd.png"><br>
<span>这套传感器被特斯拉工程团队认为是可以满足当前自动驾驶所需的一套传感器配置，并被大量安装在所有特斯拉的产品中——无论是Model S 3 X Y，他们的自动驾驶传感器配置都是一致的。计算平台方面，经过2次大幅的重新设计，其计算性能已经提升了很多。但依旧无法满足计算需求：当前的计算平台可以支持6路图像的实时感知（暂时舍弃了长距离前向摄像头），并且只有1路中距离前向摄像头拥有比较高的感知帧率，其余5个摄像头都降频进行处理。笔者认为降频的主要原因是当前的计算平台无法支持如此多的实时图像处理，所以不得已而进行了取舍。与此同时，特斯拉也在研发全新的“全自动驾驶”计算平台，并于2019年4月22日对外发布。该计算平台外部统称FSD（Full Self-Driving）全自动驾驶平台，内部称为HW 3.0版本。其使用自研的SoC芯片对计算能力以及算法进行统一的构架以及性能优化。不过在2019年3月1日事故中的特斯拉Model 3尚未升级为该版本的计算单元。https://pic4.zhimg.com/80/v2-ea37967b2e514f28ff5d5207c609f33b_hd.png虽然特斯拉做了非常多的改进与提升，但为什么这个首次致死的Bug还是没有通过这些方案解决？笔者尝试从一个自动驾驶工程师的角度叙述可能的原因，以及后续避免此类车祸的方式方法。为什么还是漏检了由于在事故发生的时刻，系统并未进行任何有效的规避操作，可以认为系统存在漏检。首先我们从整个系统入手，分析为什么产生漏检：从传感器方面，我们认为当前Tesla的传感器配置只有前向广角近距离摄像头可以有效“看到”正在横过马路的白色拖挂卡车，其余的传感器与2016年版本并无区别：毫米波从拖挂箱体下侧直接穿过；其他前视摄像头只看得到拖挂卡车的局部（悬空），容易误认为是悬空的广告牌或桥梁；超声波雷达监测距离过近，对该场景无效。而基于单目摄像头获取深度也受到拖挂车白色涂装影响无法有效提取特征点，从而无法进行有效的深度恢复(Structure from Motion, SFM)。所以，当一辆特斯拉面前有一辆正在穿过马路的白色拖挂卡车时，正向广角镜头是整个感知系统唯一可用的输入。在这唯一可用传感器的情况下有两个问题：首先，广角摄像头由于视角过大，导致目标可检测距离变短。基于网上公开的2018年10月Autopilot 18.39.6 版本，在同样的算法下，中距离镜头可以得到约100m的有效检测距离，但广角镜头只能看到约50m处的车辆（并且还存在未成功融合的问题，同一辆车通过两个摄像头识别的结果产生了不同的ID以及不同的距离）。在本次事故中，当车辆以30 m/s的速度行驶时，留给系统的反应时间只有短短的2s，这远远满足不了刹车所需的时间与距离。其次，在这一场景上我们的感知输入，也就是传感器配置失去了冗余。在一旦检测失败或传感器失效，这一场景将没有任何可靠的解决方法。从墨菲定律的角度出发，这一Bug的重现完全在意料之中。由于本次事故车辆并未进行任何的规避行为，我们可以认为，在事故中Autopilot系统存在检测失效的问题，这是本次事故的核心原因。从计算平台及感知模块方面分析，当前的HW 2.5基于双Nvidia Parker SoC加单块GP106独立显卡的方案，在多达8路2Mpixel@30fps的摄像头输入下性能捉襟见肘。最终其性能只能支持1路高速视频流及5路低速视频流的实时处理。很不幸广角摄像头被放在了低速视频处理的流水线中，这进一步引入了延迟。从被动安全角度，一旦特斯拉从拖挂车下方穿过，几乎没有任何方式可以保证车上人员的被动安全，因为在这个场景中，没有任何车体溃缩和缓冲的空间与时间。车上人员的死亡在该类事故中的概率非常高。</span><br>
<span>如何解决此类Bug让我们尝试从技术路径上寻找特斯拉解决此类Bug的可能性：首先，传感器方面，需要增加传感器的冗余度，以保证在该场景中，有至少两种传感器可以有效检测出目标物体，使得系统有足够的输入进行判断并作出有效规避。两种传感器代表通过不同测量方式，测量不同物理量的两种传感器，例如摄像头与红外摄像头（波长不同），或摄像头与毫米波雷达（波长及测量方式不同）等，同时也要保证不同传感器间检测距离，可视角度以及分辨率的匹配。其次，需要对道路进行更加细致的分类以及标注，以增加语义道路信息。我们发现，这两起事故都发生在类似高速但有交叉路口的道路上。但在特斯拉的Autopilot系统中并未对两种道路情况进行区分，其决策依据也没有区别。只有通过语义地图，我们才可以在传感器检测范围覆盖前了解到前方的路口以及可能的来车方向，以此提前对来车方向进行检测，并做出减速/预刹车等行为，来提高系统在此类问题上的安全表现。再次，是强调模拟测试的重要性。在今年Tesla的FSD发布会上，Elon Musk也坦承特斯拉的模拟器无法捕捉到每一种现实中的长尾场景(Long tail of weird things that happen in the real word)，这使得特斯拉无法解决它没看到过的场景。特斯拉的模拟器只能模拟其见过的场景——这意味着，一些人为设定的长尾场景，或有挑战的场景，特斯拉的开发团队无法有针对的对其进行解决。这就使得对于特定场景Bug的解决难度非常大，开发人员无法通过对环境的调整进一步测试在特定长尾场景下的系统表现。最后，让我们说说激光雷达的重要性。Elon Musk一直对激光雷达嗤之以鼻，考虑到激光雷达传感器当前的成本以及可靠性，笔者认为，作为一家年产近14万台电动车的车企，放弃激光雷达方案在当前是一个理智的决定。但对于自动驾驶而言，激光雷达又是如此重要，其重要性体现在，1）绝对距离测量。激光雷达是一种3D绝对距离传感器，3D结果是其天然的优势。而通过2D结果对距离进行恢复总有各种问题。例如摄像头恢复出的距离3D信息，其置信度始终无法提高。并且被测物体距离越远，可靠性越差。这与摄像头的2D检测本质原理有关。Tesla在FSD发布会上称，其算法会通过毫米波雷达对距离进行恢复，毫米波雷达作为一个2D传感器有如下问题需要解决：毫米波雷达在距离及角度分辨度上表现不佳，导致传感器融合容易出现漏检的问题，以及毫米波雷达对于切向运动物体（如横向过马路的卡车），其原理决定了毫米波雷达无法准确计算出切向运动物体的速度，从而容易出现毫米波雷达将横向移动物体归类为静止物体导致误检。2）全天候检测，由于阳光对激光雷达有一定干扰，在晚上激光雷达的性能会高于白天的性能。而摄像头正好相反。由于摄像头被动检测的特性，其在没有光照的情况下的表现落差很大。这一点上激光雷达与摄像头有一定互补性。3）制图/定位的绝对优势。激光雷达还有一个特点在于其可以很容易对环境进行3D测量而无需依赖光照以及环境中特征点的分布。这使得基于激光雷达的制图/定位可以达到非常高的精度（10cm级别）且系统计算资源要求较少。而基于图像的重定位精度则需要花费非常大量的搜索计算才能取得一般的重定位精度。上述问题大部分都是传感器的检测原理中的本质上的问题，在实现自动驾驶过程中，我们很难对其进行改变。激光雷达在这些情况中可以很好地与其他传感器进行互补，在降低系统运算复杂度，提升定位精度，检测精度以及检测距离中有不可替代的作用。既然特斯拉的目标是完全的自动驾驶（L4+），那激光雷达是避不开的方式。无论Elon Musk多么不认可激光雷达，当未来激光雷达价格降至1K美元以内时，钢铁侠必会改变思路——毕竟我们无法改变现有传感器的物理检测原理，有一些问题必须通过激光雷达才能可靠得解决。</span><br>
<span>自动驾驶的银弹诚然，自动驾驶技术的发展已经出现了牺牲。但我们不愿意看到的是无谓的牺牲——即在已知问题上反复出错。希望本事故可以提醒特斯拉以及所有从事自动驾驶的工程师们：“只要一套自动驾驶方案有发生事故的可能性存在，不管可能性多么小，这个事故迟早会发生的。”从传感器冗余，激光雷达的布置，高精地图及语义地图的使用，再到模拟器的技术路径以及方案选择上，我们需要想得更加深远，覆盖足够全面，一切以安全为第一考量，避免那“无谓的牺牲”。</span><br>
<span>作者：夹子（硬件组）（图片来源于网络，有任何问题私信联系.）===========================================马斯克：傻子才用激光雷达</span><br>
</p><p><b>mu1: </b><br>
<span>辅助驾驶就辅助驾驶，不要脸的天天宣传自己自动驾驶，透支无人自动驾驶概念</span><br>
<span>-- 来自 有消息提醒的 Stage1官方 Android客户端</span><br>
</p><p><b>伊可费斯: </b><br>
<span>牛逼，那么有哪家打算把激光雷达用在量产车上呢？现有成本下这根本不可能，机扫激光雷达长期可靠性也难以保证，固态激光只听见吹没见实际量产，只能绝望啦。</span><br>
</p><p><b>シャル: </b><br>
<span>马路上全部联网自动驾驶的话就该没事了吧</span><br>
</p><p><b>伊可费斯: </b><br>
<span>シャル 发表于 2019-5-28 13:49</span><br>
<span>马路上全部联网自动驾驶的话就该没事了吧</span><br>
<span>5g d2d可以解决，不过公路网覆盖成本太大了。</span><br>
</p><p><b>sjbssd: </b><br>
<span>永远禁止白色拖挂车呗</span><br>
<span>—— 来自 OnePlus ONEPLUS A3000, Android 8.0.0上的 S1Next-鹅版 v2.1.0-play</span><br>
</p><p><b>cosx: </b><br>
<span>model s钻出卡车变成roadster</span><br>
</p><p><b>阿狸狸狸狸狸: </b><br>
<span>马斯克：我们把自动驾驶带到了兰博基尼，这下你能从卡车下面穿过了，再也不用担心变成敞篷车了1</span><br>
<span>—— 来自 Google Pixel 3, Android 9上的 S1Next-鹅版 v2.1.2</span><br>
</p><p><b>莫吉: </b><br>
<span>伊可费斯 发表于 2019-5-28 13:36</span><br>
<span>牛逼，那么有哪家打算把激光雷达用在量产车上呢？现有成本下这根本不可能，机扫激光雷达长期可靠性也难以保 ...</span><br>
<span>那么不用雷达而是用摄像头呢，现在的AI能胜任吗</span><br>
</p><p><b>我想要的椅子: </b><br>
<span>信任AI的人才会被AI害死，有点像之前看过的一个讽刺漫画</span><br>
</p><p><b>伊可费斯: </b><br>
<span>莫吉 发表于 2019-5-28 14:10</span><br>
<span>那么不用雷达而是用摄像头呢，现在的AI能胜任吗</span><br>
<span>摄像头是主流啊，比如文中提到的大陆，mobileye(特斯拉的ap就是mobileye方案基础上开发的)都是摄像头为主要传感器的方案，毫米波和超声波雷达也是有容易受天气影响的缺点在的，当然还是因为视觉方案便宜。</span><br>
</p><p><b>masm: </b><br>
<span>可以给车前面安装个番茄酱发射器，随时发射番茄酱，以便检测正面物体</span><br>
</p><p><b>nexus1: </b><br>
<span>eyesight怎么样</span><br>
</p><p><b>aranyakay: </b><br>
<span>只要发生事故的可能性存在，不管可能性多么小，在大样本量反复尝试的情况下这个事故迟早会发生的，并且会反复发生</span><br>
<span>这不是统计学基本定律么，啥时候成了墨菲 </span><br>
</p><p><b>sifi: </b><br>
<span>シャル 发表于 2019-5-28 13:49</span><br>
<span>马路上全部联网自动驾驶的话就该没事了吧</span><br>
<span>突然不知道从哪儿钻出来个开电动轮椅的老头，就问你怕未</span><br>
</p><p><b>红色福音: </b><br>
<span>sifi 发表于 2019-5-28 14:27</span><br>
<span>突然不知道从哪儿钻出来个开电动轮椅的老头，就问你怕未</span><br>
<span>有人驾驶也怕啊，无人驾驶至少反应速度比人类还快点</span><br>
</p><p><b>xdescat01: </b><br>
<span>其实我觉得在评价无人驾驶安全性上一直有个很大的问题，为什么评价无人驾驶安全性的基准是绝对安全？难道不应该是比有人驾驶安全就可以了么</span><br>
<span>每年机动车事故那么多起，是不是因为这种安全性隐患大家就不买车了？</span><br>
</p><p><b>杨松: </b><br>
<span>红色福音 发表于 2019-5-28 14:32</span><br>
<span>有人驾驶也怕啊，无人驾驶至少反应速度比人类还快点</span><br>
<span>这个倒不一定，有的驾驶员没看到窜出行人和飞机，也会预想（臆想）到这里会发生突发状况，在险情出险前已经减速到很低并随时准备制动了。感觉像是料敌机先</span><br>
</p><p><b>sblnrrk: </b><br>
<span>不说激光雷达要1K美元，google waymo号称激光雷达的成本只有7000美元，如果以TESLA这种级别公司量产的话成本还要低，三五千美元成本对自动驾驶来说，真的不可承受么？激光雷达可以直接测3D，辅助摄像头的话，算力要求可以下降一个数量 级</span><br>
</p><p><b>wszweill: </b><br>
<span>红色福音 发表于 2019-05-28 14:32:57</span><br>
<span>有人驾驶也怕啊，无人驾驶至少反应速度比人类还快点快和准往往是矛盾的另外，万一老头穿了个反AI学习衬衫呢 让AI误以为他其实只是个背景，和本文的白色大卡原理类似</span><br>
<span>-- 来自 有消息提醒的 Stage1官方 iOS客户端</span><br>
</p><p><b>sifi: </b><br>
<span>红色福音 发表于 2019-5-28 14:32</span><br>
<span>有人驾驶也怕啊，无人驾驶至少反应速度比人类还快点</span><br>
<span>认出来有东西逼近是快，制定避让的策略又是另一回事了。</span><br>
</p><p><b>2517君: </b><br>
<span>xdescat01 发表于 2019-5-28 14:45</span><br>
<span>其实我觉得在评价无人驾驶安全性上一直有个很大的问题，为什么评价无人驾驶安全性的基准是绝对安全？难道不 ...</span><br>
<span>Ford Pinto当年也是这么评估自己的油箱的</span><br>
</p><p><b>MARCO.BLANCA: </b><br>
<span>xdescat01 发表于 2019-5-28 14:45</span><br>
<span>其实我觉得在评价无人驾驶安全性上一直有个很大的问题，为什么评价无人驾驶安全性的基准是绝对安全？难道不 ...</span><br>
<span>有人驾驶出了问题自己负责，无人驾驶的话当然就要索赔了</span><br>
</p><p><b>红色福音: </b><br>
<span>sifi 发表于 2019-5-28 15:00</span><br>
<span>认出来有东西逼近是快，制定避让的策略又是另一回事了。</span><br>
<span>制定避让策略必然也是AI快，这个不能质疑</span><br>
<span>电脑至少不会踩着油门尖叫</span><br>
</p><p><b>塔那: </b><br>
<span>wszweill 发表于 2019-5-28 14:58</span><br>
<span>快和准往往是矛盾的另外，万一老头穿了个反AI学习衬衫呢 让AI误以为他其实只是个背景，和本 ...</span><br>
<span>一个老头，穿反AI衣，开电动轮椅，突然横穿。</span><br>
<span>这已经是蓄意碰瓷而且生怕自己不死了啊。成全了他吧</span><br>
<span>—— 来自 Xiaomi MIX 2, Android 8.0.0上的 S1Next-鹅版 v2.1.2</span><br>
</p><p><b>sifi: </b><br>
<span>红色福音 发表于 2019-5-28 15:15</span><br>
<span>制定避让策略必然也是AI快，这个不能质疑</span><br>
<span>电脑至少不会踩着油门尖叫</span><br>
<span>踩油门尖叫这种事，人类驾驶员里会这么干的也不多吧，不然上不了新闻啊。</span><br>
<span>至于策略是否快而正确，这不正在质疑嘛~毕竟人脑在判断复杂情况上目前还是有优势的。</span><br>
</p><p><b>opened: </b><br>
<span>这种事放传统车企会不会因为设计漏洞被告赔他几十亿？</span><br>
<span>—— 来自 HUAWEI ALP-AL00, Android 9上的 S1Next-鹅版 v2.1.2</span><br>
</p><p><b>红色福音: </b><br>
<span>sifi 发表于 2019-5-28 15:26</span><br>
<span>踩油门尖叫这种事，人类驾驶员里会这么干的也不多吧，不然上不了新闻啊。</span><br>
<span>至于策略是否快而正确，这不正 ...</span><br>
<span>人类是不多，电脑是完全不会发生，这已经说明其优势了</span><br>
<span>至于判断之类的，我坚信随着技术的进步，人造之物总是胜过天然生成的东西——包括人类</span><br>
</p><p><b>无印凉粉: </b><br>
<span>nexus1 发表于 2019-5-28 14:18</span><br>
<span>eyesight怎么样</span><br>
<span>eyesight在我看来是最顶尖的辅助驾驶系统，没有之一</span><br>
<span>奥迪和通用的自动驾驶不算辅助驾驶</span><br>
</p><p><b>Mr.Cheung: </b><br>
<span> 本帖最后由 Mr.Cheung 于 2019-5-28 15:57 编辑 </span><br>
<span>xdescat01 发表于 2019-05-28 14:45:05</span><br>
<span>其实我觉得在评价无人驾驶安全性上一直有个很大的问题，为什么评价无人驾驶安全性的基准是绝对安全？难道不 ...</span><br>
<span>因为有人驾驶容易区分责任（和稀泥或者乱来的情况不算），无人驾驶就不行了，有人驾驶撞死人，如果司机违规那就司机背锅，该赔钱赔钱该坐牢坐牢，死者违规司机无责那就死者活该；无人驾驶的特斯拉系统出错误撞死人，你是打算让马一龙背锅呢还是让研发算法的程序员背锅呢还是让组装汽车的工人背锅呢？总不能让汽车来背锅吧？“法庭宣判这辆无人车全责，来人啊，把它拉去废车场压碎咯！”这样？</span><br>
<span>-- 来自 能看大图的 Stage1官方 iOS客户端</span><br>
</p><p><b>sifi: </b><br>
<span>红色福音 发表于 2019-5-28 15:31</span><br>
<span>人类是不多，电脑是完全不会发生，这已经说明其优势了</span><br>
<span>至于判断之类的，我坚信随着技术的进步，人造之物 ...</span><br>
<span>现在讨论的不就是电脑会发生的独特的问题嘛，电脑当然有它的优势，然而它的胜出不是现在。</span><br>
<span>换句话说就是：我现在不当小白鼠。</span><br>
</p><p><b>nexus1: </b><br>
<span>无印凉粉 发表于 2019-5-28 15:38</span><br>
<span>eyesight在我看来是最顶尖的辅助驾驶系统，没有之一</span><br>
<span>奥迪和通用的自动驾驶不算辅助驾驶 ...</span><br>
<span>开过多久,感受如何</span><br>
</p><p><b>lxiang: </b><br>
<span>这种路口得监控侧面了吧。。。</span><br>
</p><p><b>kabunsan: </b><br>
<span>转弯让直行，货车全责。至于自动驾驶的bug，多加几个摄像头嘛。</span><br>
<span>—— 来自 Essential Products PH-1, Android 9上的 S1Next-鹅版 v2.1.2</span><br>
</p><p><b>stmule: </b><br>
<span>杨松 发表于 2019-5-28 14:48</span><br>
<span>这个倒不一定，有的驾驶员没看到窜出行人和飞机，也会预想（臆想）到这里会发生突发状况，在险情出险前已 ...</span><br>
<span>明明是nt</span><br>
<span>反正本来就是机动驾驶员证</span><br>
</p><p><b>VALKIRA: </b><br>
<span>シャル 发表于 2019-5-28 13:49</span><br>
<span>马路上全部联网自动驾驶的话就该没事了吧</span><br>
<span>那出个黑客就真的好莱坞大片了</span><br>
</p><p><b>Ursa: </b><br>
<span>kabunsan 发表于 2019-5-28 16:06</span><br>
<span>转弯让直行，货车全责。至于自动驾驶的bug，多加几个摄像头嘛。</span><br>
<span>—— 来自 Essential Products PH-1, Andr ...</span><br>
<span>给驾驶员多加几个头，管够</span><br>
</p><p><b>红色福音: </b><br>
<span>sifi 发表于 2019-5-28 15:58</span><br>
<span>现在讨论的不就是电脑会发生的独特的问题嘛，电脑当然有它的优势，然而它的胜出不是现在。</span><br>
<span>换句话说就是 ...</span><br>
<span>“一个坐着电动轮椅的老人突然冲出来”并不是只有电脑需要面对的独特问题</span><br>
<span>电脑在未来具有全面的、巨大的优势。至于现在，也没有人要你当小白鼠，以后要你当小白鼠的时候（比如自动驾驶全面铺开，人工驾驶被立法禁止）你也没那个力量反抗</span><br>
</p><p><b>scourge411: </b><br>
<span>电动环保杀人车</span><br>
</p><p><b>fang帅: </b><br>
<span>sifi 发表于 2019-5-28 15:26</span><br>
<span>踩油门尖叫这种事，人类驾驶员里会这么干的也不多吧，不然上不了新闻啊。</span><br>
<span>至于策略是否快而正确，这不正 ...</span><br>
<span>你高估人脑了</span><br>
</p><p><b>sifi: </b><br>
<span> 本帖最后由 sifi 于 2019-5-28 17:13 编辑 </span><br>
<span>红色福音 发表于 2019-5-28 17:05</span><br>
<span>“一个坐着电动轮椅的老人突然冲出来”并不是只有电脑需要面对的独特问题</span><br>
<span>电脑在未来具有全面的、巨大的 ...</span><br>
<span>你要现在当小白鼠别拉上别人就好啦。不过如果你真的会尖叫着踩油门，那确实ap更靠谱点。</span><br>
</p><p><b>红色福音: </b><br>
<span>sifi 发表于 2019-5-28 17:12</span><br>
<span>你要现在当小白鼠别拉上别人就好啦。不过如果你真的会尖叫着踩油门，那确实ap更靠谱点。 ...</span><br>
<span>我反正是很乐意见到这些方便人类的新技术进入社会的</span><br>
<span>但是不管你们这些反对派如何破口大骂、在地上打滚、撕扯自己的头发，这些新技术进入社会的速度也不会放慢一天。与其去做历史的小丑，不如放正心态，试着拥抱这些新技术。至少以后在你尖叫着踩死油门的时候，还可能有电脑来救你一条命</span><br>
</p><p><b>treexper: </b><br>
<span>马一龙刚刚才嘲讽过lidar...给点面子。</span><br>
</p><p><b>treexper: </b><br>
<span> 本帖最后由 treexper 于 2019-5-28 17:32 编辑 </span><br>
<span>不过这也体现了深度学习系算法的一个弱点，就是你对算法调整只能影响到整体预测的概率分布，没法完全断绝一个独立事件发生的可能性，除非导入集成学习体系，加入规则判断（但这东西很难形式化描述，人工规则不好写，最后只能做fall back处理）。但是如果是传感器上出问题就没得救。</span><br>
</p><p><b>xburke: </b><br>
<span>红色福音 发表于 2019-5-28 17:20</span><br>
<span>我反正是很乐意见到这些方便人类的新技术进入社会的</span><br>
<span>但是不管你们这些反对派如何破口大骂、在地上打滚、 ...</span><br>
<span>马粉信仰感人</span><br>
</p><p><b>红色福音: </b><br>
<span>xburke 发表于 2019-5-28 17:28</span><br>
<span>马粉信仰感人</span><br>
<span>这个“马”是指的谁？如果你说的是马伯庸的话，我还真不是他的粉，最多只是路人而已；如果你是指的马克思的话，（点头）我还真是马克思的粉</span><br>
</p><p><b>费老师: </b><br>
<span>小马:用雷达的都是弱鸡</span><br>
</p><p><b>lilyblack: </b><br>
<span>Mr.Cheung 发表于 2019-5-28 15:55</span><br>
<span>因为有人驾驶容易区分责任（和稀泥或者乱来的情况不算），无人驾驶就不行了，有人驾驶撞死人，如 ...</span><br>
<span>为什么你会觉得无人车出事故找不到责任主体？</span><br>
<span>车辆零部件质量问题导致事故那么责任归零部件供应商，车辆设计缺陷导致事故那么责任归汽车生产商，驾驶人违章操作或操作失误造成事故责任归驾驶人。无人车只不过没有了驾驶人，怎么会找不到人负责？</span><br>
</p><p><b>中川夏纪: </b><br>
<span>红色福音 发表于 2019-5-28 17:32</span><br>
<span>这个“马”是指的谁？如果你说的是马伯庸的话，我还真不是他的粉，最多只是路人而已；如果你是指的马克思 ...</span><br>
<span>马斯克信徒装傻什么呢。</span><br>
</p><p><b>Yukine_Chris: </b><br>
<span>一个道理，面对的情况要简单很多的民用航空，自动驾驶也没能取代人类。</span><br>
<span>上面某位需要读一下最基本的社会学和交通工程学</span><br>
<span>— from Sony G8142, Android 9 of S1 Next Goose v2.1.0-play</span><br>
</p>]]></content:encoded>
      <guid isPermaLink="false">1834981[0-50]</guid>
    </item>
  </channel>
</rss>
