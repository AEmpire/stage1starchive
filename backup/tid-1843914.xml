<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Data61：全新算法助机器学习抵抗干扰</title>
    <link>https://bbs.saraba1st.com/2b/</link>
    <description>Data61：全新算法助机器学习抵抗干扰</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 09 Jul 2020 19:19:27 +0000</lastBuildDate>
    <item>
      <title>Data61：全新算法助机器学习抵抗干扰[0-50]</title>
      <link>https://bbs.saraba1st.com/2b/thread-1843914-1-1.html</link>
      <description>Data61：全新算法助机器学习抵抗干扰&#13;
科技日报-中国科技网讯 （记者张梦然）机器学习模型受到攻击将产生严重的后果，但如果对这一情形提前预防呢？就像人类针对即将到来的病毒去接种疫苗一样。据澳大利亚联邦科学与工业研究组织（CSIRO）官方网站消息，该机构的一个研究团队，日前开发了一套人工智能（AI）最新算法，可帮助机器学习抵御可能遇到的干扰。机器学习是人工智能的核心，也是使计算机具有智能的根本途径。机器学习主旨是让计算机去模拟或实现人类的学习行为，以获取新的知识或技能，并重新组织已有的知识结构，使之不断改善自身的性能。机器学习虽然可以在大数据训练中学到正确的工作方法，但它也很容易受到恶意干扰。通常攻击者是通过输入恶意数据来“欺骗”机器学习模型，导致其出现严重故障。此次，开发出新算法的研究团队——“Data61”机器学习小组领导者理查德·诺克表示，攻击者会在进行图像识别时，在图像上添加一层干扰波，达到“欺骗”的目的，从而让机器学习模型产生错误的图像分类。诺克及其团队成员研发的新算法，通过一种类似疫苗接种的思路，可以帮助机器学习“修炼”出抗干扰能力。这是针对机器学习模型打造的防干扰训练，譬如，在图片识别领域，该算法能够对图片集合进行微小的修改或使其失真，激发出机器学习模型“领会”到越来越强的抗干扰能力，并形成相关的自我抗干扰训练模型。经过此类小规模的失真训练后，最终的抗干扰训练模型将更加强大，当真正的攻击到来之时，机器学习模型将具备“免疫”功能。总编辑圈点用小伎俩干扰机器对图像的识别，这种手段已经应用在网络黑产中。人眼看起来并无明显区别的图片，覆上一层专门针对机器的干扰波，就能让机器的判断大失水准。所谓接种疫苗，其实也就是“以毒攻毒”，让机器先见识已经被微小修改的图片，并在训练中自我学习，从而最终能识破这层恶意干扰，揭开图片的庐山真面目。机器的学习功能是强大的，教会它应对方法，它便能自我完善。但攻击与防御总是相伴相生，这是一场没有尽头的技术博弈。</description>
      <content:encoded><![CDATA[<p><b>ydd-319: </b><br>
<span>Data61：全新算法助机器学习抵抗干扰</span><br>
<span>科技日报-中国科技网讯 （记者张梦然）机器学习模型受到攻击将产生严重的后果，但如果对这一情形提前预防呢？就像人类针对即将到来的病毒去接种疫苗一样。据澳大利亚联邦科学与工业研究组织（CSIRO）官方网站消息，该机构的一个研究团队，日前开发了一套人工智能（AI）最新算法，可帮助机器学习抵御可能遇到的干扰。机器学习是人工智能的核心，也是使计算机具有智能的根本途径。机器学习主旨是让计算机去模拟或实现人类的学习行为，以获取新的知识或技能，并重新组织已有的知识结构，使之不断改善自身的性能。机器学习虽然可以在大数据训练中学到正确的工作方法，但它也很容易受到恶意干扰。通常攻击者是通过输入恶意数据来“欺骗”机器学习模型，导致其出现严重故障。此次，开发出新算法的研究团队——“Data61”机器学习小组领导者理查德·诺克表示，攻击者会在进行图像识别时，在图像上添加一层干扰波，达到“欺骗”的目的，从而让机器学习模型产生错误的图像分类。诺克及其团队成员研发的新算法，通过一种类似疫苗接种的思路，可以帮助机器学习“修炼”出抗干扰能力。这是针对机器学习模型打造的防干扰训练，譬如，在图片识别领域，该算法能够对图片集合进行微小的修改或使其失真，激发出机器学习模型“领会”到越来越强的抗干扰能力，并形成相关的自我抗干扰训练模型。经过此类小规模的失真训练后，最终的抗干扰训练模型将更加强大，当真正的攻击到来之时，机器学习模型将具备“免疫”功能。总编辑圈点用小伎俩干扰机器对图像的识别，这种手段已经应用在网络黑产中。人眼看起来并无明显区别的图片，覆上一层专门针对机器的干扰波，就能让机器的判断大失水准。所谓接种疫苗，其实也就是“以毒攻毒”，让机器先见识已经被微小修改的图片，并在训练中自我学习，从而最终能识破这层恶意干扰，揭开图片的庐山真面目。机器的学习功能是强大的，教会它应对方法，它便能自我完善。但攻击与防御总是相伴相生，这是一场没有尽头的技术博弈。</span><br>
</p><p><b>误中副車: </b><br>
<span>现在正在训练防止人工智能算法在训练过程中收到干扰而开发的人工智能算法？</span><br>
</p>]]></content:encoded>
      <guid isPermaLink="false">1843914[0-50]</guid>
    </item>
  </channel>
</rss>
