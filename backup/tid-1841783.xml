<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>中山大学+字节跳动研究成果：人工智能让女神脱外衣</title>
    <link>https://bbs.saraba1st.com/2b/</link>
    <description>中山大学+字节跳动研究成果：人工智能让女神脱外衣</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 09 Jul 2020 19:32:55 +0000</lastBuildDate>
    <item>
      <title>中山大学+字节跳动研究成果：人工智能让女神脱外衣[50-100]</title>
      <link>https://bbs.saraba1st.com/2b/thread-1841783-1-1.html</link>
      <description>中山大学+字节跳动研究成果：人工智能让女神脱外衣&#13;
https://mp.weixin.qq.com/s?__biz=MzUxNjcxMjQxNg==&amp;mid=2247489707&amp;idx=3&amp;sn=82a850b9643a6cf3d0a4f0907859582d
&#13;
寥寥勾画几笔，就能让女神的衣服变个样。
&#13;
随手画个内衣的轮廓，穿粉色运动背心的妹子，一下子就换上了内衣。就像下面这样：
&#13;
https://i.loli.net/2019/06/24/5d101bbde1bf028509.png
&#13;
生成效果毫不违和，没有任何P过的痕迹，更想象不出它竟然是根据草图合成的。
&#13;
前一眼还是金色长发的歪果仁姑娘，在这张图上随意勾勒个帽子形状，下一秒就变成了真实效果，还看不出人为增补痕迹。
&#13;
这是什么变装神器啊？！
&#13;
最近，中山大学等的研究人员搞出了这样一个变装模型，代号FE-GAN，它能通过任意草稿涂鸦，改变人物造型。
&#13;
可以实现的效果可谓多种多样，一起接着看：
&#13;
万能改图王
&#13;
此前，也有InstaGAN等AI模型，可以实现照片中裙装换裤装等操作，而今天的主角FE-GAN有多种附加功能。
&#13;
轻轻一画，就可以改变人物衣服类型，开头背心变内衣的妹子就是这个效果。
&#13;
类似的，用线条随意标记下妹子的白色破洞长裤，长裤消失不见，白色短裤现身。
&#13;
除了能改变衣服造型，FE-GAN还能改变服装布料的花色。
&#13;
而你只需要向刚刚一样，用不同颜色画笔勾勒草图和轮廓即可。
&#13;
这个花色竟然是……自己刚刚画出来的？看起来比纯黑裙显年轻了不少。
&#13;
除了在原有基础上进行改造，无中生有生成佩饰也不在话下。
&#13;
穿牛仔衣短裙的姑娘，想给她配上顶遮阳黑帽？不用重新拍摄，画上就行了。
&#13;
无破绽，不生硬，从0到有，FE-GAN也是可以的。
&#13;
你以为这就是FE-GAN的全部了？
&#13;
NoNoNo，它还能用于修饰脸型……
&#13;
即使是更要求细节的面部五官生成，它的效果也可以说得过去。
&#13;
一个笑颜圆下巴胡茬小哥，“术后”也变成了锥子脸，甚至还能帮他修胡子。
&#13;
丸子头小姐姐，画上几根头发，就真的变成了长发：
&#13;
这个名为FE-GAN的模型，简直就是个万能改图神器啊。
&#13;
这是怎么实现的？
&#13;
两步换装
&#13;
为了获得更好的恢复效果，FE-GAN把生成图片分为两步进行，先从被遮挡图片恢复轮廓，再根据手绘草图给人物加上衣服、发型等细节。
&#13;
这两步分别由两个不同的网络负责，包括一个自由形式解析网络和一个具有多尺度注意规范化层的解析感知修复网络。
&#13;
1、自由形式解析网络
&#13;
这一部分负责接收带有草灰笔画、噪声、颜色和遮挡的不完整图片，并生成一张合成解析图片。解析图片就是带有轮廓的剪影。
&#13;
与直接恢复不完整图像相比，解析图片从不完整到完整的过程更加容易与可行，因为解析图中的细节较少。不完整的解析图片可以用边缘检测算法获得。
&#13;
此外，恢复后的解析图片中的语义信息，还能精确地指导下一步渲染图每个部分的细节纹理。
&#13;
为此，研究人员提出了一个自由形式的解析网络，在给出被色块遮挡的图片时能合成出完整的解析图片。
&#13;
自由形式解析网络基于编码器-解码器架构。编码器接收五个输入：不完整的解析图片，被擦除区域的草图，从高斯分布采样的噪声，稀疏颜色和掩模。
&#13;
值得注意的是，给定相同的不完整解析图和各种草图和颜色笔划，自由形式解析网络可以合成不同的解析图，这表明解析生成模型是可控的。
&#13;
2、解析感知修复网络
&#13;
将上一步生成的合成解析图片与原来不完整的图像输入这一部分，通过草图和颜色来操纵图像。
&#13;
研究人员引入了一个部分卷积编码器，从不完整图像中的有效区域中提取特征。在部分卷积编码器中不是直接使用掩码，而是利用组合掩码使网络仅关注前景区域。
&#13;
除了部分卷积编码器，研究人员还引入了一个标准卷积编码器，从合成的解析图中提取语义特征。解析图负责指导修复的语义和位置信息，因为具有相同语义的区域中的内容应该是相似的。
&#13;
给定语义特征，网络可以更精确地在特定区域上渲染纹理。
&#13;
由于不完整图像的复杂纹理以及草图和颜色笔划的多样性，自由形式解析网络和解析感知修复网络的训练是一项具有挑战性的任务。
&#13;
为了解决这些问题，研究人员提出了6项损失——对抗性损失、感知损失、风格损失、解析损失、多尺度特征损失、总差异损失——来规范训练，使得在不同方面的训练更容易、更稳定。
&#13;
完胜其他换装模型
&#13;
研究人员用FE-GAN在DeepFashion、MPV和自建的FashionE数据集上进行了测试，与Deepfill v1、Partial Conv、Edge-connect三种方法进行对比。
&#13;
在客观指标上有PSNR（峰值信号噪声比），SSIM（结构相似性指数）和FID（Fréchet初始距离）三个参数评估定量结果。此外还使用了亚马逊AMT人工审核平台来评估定性结果。
&#13;
结果表明FE-GAN在各项指标上都取得了最优的结果。
&#13;
在亚马逊的AMT平台上，FE-GAN也具有压倒性的优势，在与Deepfill v1、Partial Conv对比时超过8成的人觉得FE-GAN效果更逼真。
&#13;
华人团队
&#13;
变装神器出自何许人也？
&#13;
整个作者团队共有9人，包括中山大学的Haoye Dong、Xiaodan Liang、Xujie Zhang、Zhenyu Xie、Bowen Wu、Ziqi Zhang、Jian Yin，来自CMU邢波教授创立的AI公司Petuum的Yixuan Zhang和字节跳动的Xiaohui Shen。
&#13;
一作Haoye Dong（董浩业）是中山大学数据科学与计算机学院的博士生，师从中山大学副教授Xiaodan Liang和博士生导师印鉴。
&#13;
二作Xiaodan Liang，此前是CMU机器学习系的项目科学家，与邢波一起合作过。
&#13;
在2014年至2016年期间，Xiaodan Liang在新加坡国立大学担任访问学者，与颜水成也合作过。
&#13;
Xiaodan Liang的顶会战绩也很耀眼。其主页显示，其两篇论文被NIPS 2018接收，2篇被AAAI 2019接收，8篇论文被ECCV 2018接收，其中还有两篇为口头报告。
&#13;
传送门
&#13;
最后，附上论文Fashion Editing with Multi-scale Attention Normalization地址：
&#13;
https://arxiv.org/abs/1906.00884
&#13;
CVer-GAN交流群</description>
      <content:encoded><![CDATA[<p><b>doki: </b><br>
<span>同志们，这还只是刚开始啊</span><br>
<span>以后真要被ai弄晕了</span><br>
</p><p><b>钢琴男: </b><br>
<span>deepface后，将来会有deepmosaic么……</span><br>
</p>]]></content:encoded>
      <guid isPermaLink="false">1841783[50-100]</guid>
    </item>
    <item>
      <title>中山大学+字节跳动研究成果：人工智能让女神脱外衣[0-50]</title>
      <link>https://bbs.saraba1st.com/2b/thread-1841783-1-1.html</link>
      <description>中山大学+字节跳动研究成果：人工智能让女神脱外衣&#13;
https://mp.weixin.qq.com/s?__biz=MzUxNjcxMjQxNg==&amp;mid=2247489707&amp;idx=3&amp;sn=82a850b9643a6cf3d0a4f0907859582d
&#13;
寥寥勾画几笔，就能让女神的衣服变个样。
&#13;
随手画个内衣的轮廓，穿粉色运动背心的妹子，一下子就换上了内衣。就像下面这样：
&#13;
https://i.loli.net/2019/06/24/5d101bbde1bf028509.png
&#13;
生成效果毫不违和，没有任何P过的痕迹，更想象不出它竟然是根据草图合成的。
&#13;
前一眼还是金色长发的歪果仁姑娘，在这张图上随意勾勒个帽子形状，下一秒就变成了真实效果，还看不出人为增补痕迹。
&#13;
这是什么变装神器啊？！
&#13;
最近，中山大学等的研究人员搞出了这样一个变装模型，代号FE-GAN，它能通过任意草稿涂鸦，改变人物造型。
&#13;
可以实现的效果可谓多种多样，一起接着看：
&#13;
万能改图王
&#13;
此前，也有InstaGAN等AI模型，可以实现照片中裙装换裤装等操作，而今天的主角FE-GAN有多种附加功能。
&#13;
轻轻一画，就可以改变人物衣服类型，开头背心变内衣的妹子就是这个效果。
&#13;
类似的，用线条随意标记下妹子的白色破洞长裤，长裤消失不见，白色短裤现身。
&#13;
除了能改变衣服造型，FE-GAN还能改变服装布料的花色。
&#13;
而你只需要向刚刚一样，用不同颜色画笔勾勒草图和轮廓即可。
&#13;
这个花色竟然是……自己刚刚画出来的？看起来比纯黑裙显年轻了不少。
&#13;
除了在原有基础上进行改造，无中生有生成佩饰也不在话下。
&#13;
穿牛仔衣短裙的姑娘，想给她配上顶遮阳黑帽？不用重新拍摄，画上就行了。
&#13;
无破绽，不生硬，从0到有，FE-GAN也是可以的。
&#13;
你以为这就是FE-GAN的全部了？
&#13;
NoNoNo，它还能用于修饰脸型……
&#13;
即使是更要求细节的面部五官生成，它的效果也可以说得过去。
&#13;
一个笑颜圆下巴胡茬小哥，“术后”也变成了锥子脸，甚至还能帮他修胡子。
&#13;
丸子头小姐姐，画上几根头发，就真的变成了长发：
&#13;
这个名为FE-GAN的模型，简直就是个万能改图神器啊。
&#13;
这是怎么实现的？
&#13;
两步换装
&#13;
为了获得更好的恢复效果，FE-GAN把生成图片分为两步进行，先从被遮挡图片恢复轮廓，再根据手绘草图给人物加上衣服、发型等细节。
&#13;
这两步分别由两个不同的网络负责，包括一个自由形式解析网络和一个具有多尺度注意规范化层的解析感知修复网络。
&#13;
1、自由形式解析网络
&#13;
这一部分负责接收带有草灰笔画、噪声、颜色和遮挡的不完整图片，并生成一张合成解析图片。解析图片就是带有轮廓的剪影。
&#13;
与直接恢复不完整图像相比，解析图片从不完整到完整的过程更加容易与可行，因为解析图中的细节较少。不完整的解析图片可以用边缘检测算法获得。
&#13;
此外，恢复后的解析图片中的语义信息，还能精确地指导下一步渲染图每个部分的细节纹理。
&#13;
为此，研究人员提出了一个自由形式的解析网络，在给出被色块遮挡的图片时能合成出完整的解析图片。
&#13;
自由形式解析网络基于编码器-解码器架构。编码器接收五个输入：不完整的解析图片，被擦除区域的草图，从高斯分布采样的噪声，稀疏颜色和掩模。
&#13;
值得注意的是，给定相同的不完整解析图和各种草图和颜色笔划，自由形式解析网络可以合成不同的解析图，这表明解析生成模型是可控的。
&#13;
2、解析感知修复网络
&#13;
将上一步生成的合成解析图片与原来不完整的图像输入这一部分，通过草图和颜色来操纵图像。
&#13;
研究人员引入了一个部分卷积编码器，从不完整图像中的有效区域中提取特征。在部分卷积编码器中不是直接使用掩码，而是利用组合掩码使网络仅关注前景区域。
&#13;
除了部分卷积编码器，研究人员还引入了一个标准卷积编码器，从合成的解析图中提取语义特征。解析图负责指导修复的语义和位置信息，因为具有相同语义的区域中的内容应该是相似的。
&#13;
给定语义特征，网络可以更精确地在特定区域上渲染纹理。
&#13;
由于不完整图像的复杂纹理以及草图和颜色笔划的多样性，自由形式解析网络和解析感知修复网络的训练是一项具有挑战性的任务。
&#13;
为了解决这些问题，研究人员提出了6项损失——对抗性损失、感知损失、风格损失、解析损失、多尺度特征损失、总差异损失——来规范训练，使得在不同方面的训练更容易、更稳定。
&#13;
完胜其他换装模型
&#13;
研究人员用FE-GAN在DeepFashion、MPV和自建的FashionE数据集上进行了测试，与Deepfill v1、Partial Conv、Edge-connect三种方法进行对比。
&#13;
在客观指标上有PSNR（峰值信号噪声比），SSIM（结构相似性指数）和FID（Fréchet初始距离）三个参数评估定量结果。此外还使用了亚马逊AMT人工审核平台来评估定性结果。
&#13;
结果表明FE-GAN在各项指标上都取得了最优的结果。
&#13;
在亚马逊的AMT平台上，FE-GAN也具有压倒性的优势，在与Deepfill v1、Partial Conv对比时超过8成的人觉得FE-GAN效果更逼真。
&#13;
华人团队
&#13;
变装神器出自何许人也？
&#13;
整个作者团队共有9人，包括中山大学的Haoye Dong、Xiaodan Liang、Xujie Zhang、Zhenyu Xie、Bowen Wu、Ziqi Zhang、Jian Yin，来自CMU邢波教授创立的AI公司Petuum的Yixuan Zhang和字节跳动的Xiaohui Shen。
&#13;
一作Haoye Dong（董浩业）是中山大学数据科学与计算机学院的博士生，师从中山大学副教授Xiaodan Liang和博士生导师印鉴。
&#13;
二作Xiaodan Liang，此前是CMU机器学习系的项目科学家，与邢波一起合作过。
&#13;
在2014年至2016年期间，Xiaodan Liang在新加坡国立大学担任访问学者，与颜水成也合作过。
&#13;
Xiaodan Liang的顶会战绩也很耀眼。其主页显示，其两篇论文被NIPS 2018接收，2篇被AAAI 2019接收，8篇论文被ECCV 2018接收，其中还有两篇为口头报告。
&#13;
传送门
&#13;
最后，附上论文Fashion Editing with Multi-scale Attention Normalization地址：
&#13;
https://arxiv.org/abs/1906.00884
&#13;
CVer-GAN交流群</description>
      <content:encoded><![CDATA[<p><b>708: </b><br>
<span>中山大学+字节跳动研究成果：人工智能让女神脱外衣</span><br>
<span>https://mp.weixin.qq.com/s?__biz=MzUxNjcxMjQxNg==&mid=2247489707&idx=3&sn=82a850b9643a6cf3d0a4f0907859582d</span><br>
<span>寥寥勾画几笔，就能让女神的衣服变个样。</span><br>
<span>随手画个内衣的轮廓，穿粉色运动背心的妹子，一下子就换上了内衣。就像下面这样：</span><br>
<img src="https://i.loli.net/2019/06/24/5d101bbde1bf028509.png" title="https://i.loli.net/2019/06/24/5d101bbde1bf028509.png"><br>
<span>生成效果毫不违和，没有任何P过的痕迹，更想象不出它竟然是根据草图合成的。</span><br>
<span>前一眼还是金色长发的歪果仁姑娘，在这张图上随意勾勒个帽子形状，下一秒就变成了真实效果，还看不出人为增补痕迹。</span><br>
<span>这是什么变装神器啊？！</span><br>
<span>最近，中山大学等的研究人员搞出了这样一个变装模型，代号FE-GAN，它能通过任意草稿涂鸦，改变人物造型。</span><br>
<span>可以实现的效果可谓多种多样，一起接着看：</span><br>
<span>万能改图王</span><br>
<span>此前，也有InstaGAN等AI模型，可以实现照片中裙装换裤装等操作，而今天的主角FE-GAN有多种附加功能。</span><br>
<span>轻轻一画，就可以改变人物衣服类型，开头背心变内衣的妹子就是这个效果。</span><br>
<span>类似的，用线条随意标记下妹子的白色破洞长裤，长裤消失不见，白色短裤现身。</span><br>
<span>除了能改变衣服造型，FE-GAN还能改变服装布料的花色。</span><br>
<span>而你只需要向刚刚一样，用不同颜色画笔勾勒草图和轮廓即可。</span><br>
<span>这个花色竟然是……自己刚刚画出来的？看起来比纯黑裙显年轻了不少。</span><br>
<span>除了在原有基础上进行改造，无中生有生成佩饰也不在话下。</span><br>
<span>穿牛仔衣短裙的姑娘，想给她配上顶遮阳黑帽？不用重新拍摄，画上就行了。</span><br>
<span>无破绽，不生硬，从0到有，FE-GAN也是可以的。</span><br>
<span>你以为这就是FE-GAN的全部了？</span><br>
<span>NoNoNo，它还能用于修饰脸型……</span><br>
<span>即使是更要求细节的面部五官生成，它的效果也可以说得过去。</span><br>
<span>一个笑颜圆下巴胡茬小哥，“术后”也变成了锥子脸，甚至还能帮他修胡子。</span><br>
<span>丸子头小姐姐，画上几根头发，就真的变成了长发：</span><br>
<span>这个名为FE-GAN的模型，简直就是个万能改图神器啊。</span><br>
<span>这是怎么实现的？</span><br>
<span>两步换装</span><br>
<span>为了获得更好的恢复效果，FE-GAN把生成图片分为两步进行，先从被遮挡图片恢复轮廓，再根据手绘草图给人物加上衣服、发型等细节。</span><br>
<span>这两步分别由两个不同的网络负责，包括一个自由形式解析网络和一个具有多尺度注意规范化层的解析感知修复网络。</span><br>
<span>1、自由形式解析网络</span><br>
<span>这一部分负责接收带有草灰笔画、噪声、颜色和遮挡的不完整图片，并生成一张合成解析图片。解析图片就是带有轮廓的剪影。</span><br>
<span>与直接恢复不完整图像相比，解析图片从不完整到完整的过程更加容易与可行，因为解析图中的细节较少。不完整的解析图片可以用边缘检测算法获得。</span><br>
<span>此外，恢复后的解析图片中的语义信息，还能精确地指导下一步渲染图每个部分的细节纹理。</span><br>
<span>为此，研究人员提出了一个自由形式的解析网络，在给出被色块遮挡的图片时能合成出完整的解析图片。</span><br>
<span>自由形式解析网络基于编码器-解码器架构。编码器接收五个输入：不完整的解析图片，被擦除区域的草图，从高斯分布采样的噪声，稀疏颜色和掩模。</span><br>
<span>值得注意的是，给定相同的不完整解析图和各种草图和颜色笔划，自由形式解析网络可以合成不同的解析图，这表明解析生成模型是可控的。</span><br>
<span>2、解析感知修复网络</span><br>
<span>将上一步生成的合成解析图片与原来不完整的图像输入这一部分，通过草图和颜色来操纵图像。</span><br>
<span>研究人员引入了一个部分卷积编码器，从不完整图像中的有效区域中提取特征。在部分卷积编码器中不是直接使用掩码，而是利用组合掩码使网络仅关注前景区域。</span><br>
<span>除了部分卷积编码器，研究人员还引入了一个标准卷积编码器，从合成的解析图中提取语义特征。解析图负责指导修复的语义和位置信息，因为具有相同语义的区域中的内容应该是相似的。</span><br>
<span>给定语义特征，网络可以更精确地在特定区域上渲染纹理。</span><br>
<span>由于不完整图像的复杂纹理以及草图和颜色笔划的多样性，自由形式解析网络和解析感知修复网络的训练是一项具有挑战性的任务。</span><br>
<span>为了解决这些问题，研究人员提出了6项损失——对抗性损失、感知损失、风格损失、解析损失、多尺度特征损失、总差异损失——来规范训练，使得在不同方面的训练更容易、更稳定。</span><br>
<span>完胜其他换装模型</span><br>
<span>研究人员用FE-GAN在DeepFashion、MPV和自建的FashionE数据集上进行了测试，与Deepfill v1、Partial Conv、Edge-connect三种方法进行对比。</span><br>
<span>在客观指标上有PSNR（峰值信号噪声比），SSIM（结构相似性指数）和FID（Fréchet初始距离）三个参数评估定量结果。此外还使用了亚马逊AMT人工审核平台来评估定性结果。</span><br>
<span>结果表明FE-GAN在各项指标上都取得了最优的结果。</span><br>
<span>在亚马逊的AMT平台上，FE-GAN也具有压倒性的优势，在与Deepfill v1、Partial Conv对比时超过8成的人觉得FE-GAN效果更逼真。</span><br>
<span>华人团队</span><br>
<span>变装神器出自何许人也？</span><br>
<span>整个作者团队共有9人，包括中山大学的Haoye Dong、Xiaodan Liang、Xujie Zhang、Zhenyu Xie、Bowen Wu、Ziqi Zhang、Jian Yin，来自CMU邢波教授创立的AI公司Petuum的Yixuan Zhang和字节跳动的Xiaohui Shen。</span><br>
<span>一作Haoye Dong（董浩业）是中山大学数据科学与计算机学院的博士生，师从中山大学副教授Xiaodan Liang和博士生导师印鉴。</span><br>
<span>二作Xiaodan Liang，此前是CMU机器学习系的项目科学家，与邢波一起合作过。</span><br>
<span>在2014年至2016年期间，Xiaodan Liang在新加坡国立大学担任访问学者，与颜水成也合作过。</span><br>
<span>Xiaodan Liang的顶会战绩也很耀眼。其主页显示，其两篇论文被NIPS 2018接收，2篇被AAAI 2019接收，8篇论文被ECCV 2018接收，其中还有两篇为口头报告。</span><br>
<span>传送门</span><br>
<span>最后，附上论文Fashion Editing with Multi-scale Attention Normalization地址：</span><br>
<span>https://arxiv.org/abs/1906.00884</span><br>
<span>CVer-GAN交流群</span><br>
</p><p><b>tk.cocacola: </b><br>
<span>我看着那肤色就觉得很不自然……</span><br>
<span>-- 来自 能搜索的 Stage1官方 Android客户端</span><br>
</p><p><b>按时上班: </b><br>
<span>我记得国内知名的实体娃娃大牌子都在中山，所以我对中山一直有一种说不上来的好感</span><br>
</p><p><b>bl0ck: </b><br>
<span>对抗性损失、感知损失、风格损失、解析损失、多尺度特征损失、总差异损失</span><br>
<span>哪个是你提出的创新点？</span><br>
</p><p><b>lordvv: </b><br>
<span>Gan真是好用啊'</span><br>
<span>—— 来自 HUAWEI CLT-AL00, Android 9上的 S1Next-鹅版 v2.1.2</span><br>
</p><p><b>白龙: </b><br>
<span>点进链接被吓到</span><br>
<span>可以草稿画帽子，衣服，剪短，加长，改型</span><br>
<span>还有变发型，改脸型</span><br>
<span>人工智能PS</span><br>
<span>到时候出个成人版本，连**都可以用草稿生成了</span><br>
<span>如果配合视频换头术</span><br>
<span>以后图片和视频的造假都低成本化了</span><br>
<span>诈骗行业喜迎一波新技术</span><br>
</p><p><b>黑丝后的腿毛: </b><br>
<span>引用第2楼按时上班于2019-06-24 08:48发表的:</span><br>
<span>我记得国内知名的实体娃娃大牌子都在中山，所以我对中山一直有一种说不上来的好感</span><br>
<span>@按时上班</span><br>
<span>然而中大在中山没有校区啊</span><br>
<span>----发送自 vivo V1821A,Android 9</span><br>
</p><p><b>mcmurdo: </b><br>
<span>按时上班 发表于 2019-6-24 08:48</span><br>
<span>我记得国内知名的实体娃娃大牌子都在中山，所以我对中山一直有一种说不上来的好感 ...</span><br>
<span>恭喜中山喜提中山大学</span><br>
</p><p><b>杨松: </b><br>
<span> 本帖最后由 杨松 于 2019-6-24 09:03 编辑 </span><br>
<span>白龙 发表于 2019-6-24 08:57</span><br>
<span>点进链接被吓到</span><br>
<span>可以草稿画帽子，衣服，剪短，加长，改型</span><br>
<span>这样泛滥只有好，让人们普遍接受“没有经过法律程序认可的证据都是狗屁，没有任何证明力“</span><br>
</p><p><b>精打细算大国安: </b><br>
<span>按时上班 发表于 2019-6-24 08:48</span><br>
<span>我记得国内知名的实体娃娃大牌子都在中山，所以我对中山一直有一种说不上来的好感 ...</span><br>
<span>因为那里制胶产业发达的缘故，产业链齐全，而且中山大学和中山市没啥关系，中山市就一所高校吧，就是电科大的中山学院，好像广药在那也有个校区</span><br>
</p><p><b>TRI_KING: </b><br>
<span>按时上班 发表于 2019-6-24 08:48</span><br>
<span>我记得国内知名的实体娃娃大牌子都在中山，所以我对中山一直有一种说不上来的好感 ...</span><br>
<span>然而中山大学在黑龙江（</span><br>
<span>—— 来自 samsung SM-G9750, Android 9上的 S1Next-鹅版 v2.1.2</span><br>
</p><p><b>tn_teana: </b><br>
<span>按时上班 发表于 2019-6-24 08:48</span><br>
<span>我记得国内知名的实体娃娃大牌子都在中山，所以我对中山一直有一种说不上来的好感 ...</span><br>
<span>但是中山并没有中山大学啊</span><br>
</p><p><b>jam0206: </b><br>
<span>按时上班 发表于 2019-6-24 08:48</span><br>
<span>我记得国内知名的实体娃娃大牌子都在中山，所以我对中山一直有一种说不上来的好感 ...</span><br>
</p><p><b>亚瑟姆·明日野: </b><br>
<span>完全不知道该以什么表情面对</span><br>
</p><p><b>河水: </b><br>
<span>按时上班 发表于 2019-6-24 08:48</span><br>
<span>我记得国内知名的实体娃娃大牌子都在中山，所以我对中山一直有一种说不上来的好感 ...</span><br>
<span>不是，中山大学不是中山的大学</span><br>
</p><p><b>traburiss: </b><br>
<span>按时上班 发表于 2019-6-24 08:48</span><br>
<span>我记得国内知名的实体娃娃大牌子都在中山，所以我对中山一直有一种说不上来的好感 ...</span><br>
<span>中山大学在广州啊……应该说中山大学和中山市都是因为孙中山才叫中山的。</span><br>
<span>—— 来自 Xiaomi Mi Note 2, Android 8.0.0上的 S1Next-鹅版 v2.1.2</span><br>
</p><p><b>TuzDoDez: </b><br>
<span>这技术谁家能先上手机，谁家能吃一大波红利。</span><br>
</p><p><b>wantong: </b><br>
<span>想到这个</span><br>
<span>https://weibo.com/2203460187/Hzsfo0Z0V</span><br>
<span>Nvidia 的AI智能生成风景照的黑科技。</span><br>
</p><p><b>deadog: </b><br>
<span>什么？中山大学不是在双鸭山吗？</span><br>
</p><p><b>最低人间肥宅: </b><br>
<span>中大不是在黑龙江？</span><br>
<span>—— 来自 HUAWEI BKL-AL00, Android 9上的 S1Next-鹅版 v2.1.2</span><br>
</p><p><b>doremisola: </b><br>
<span>中山大学在广州啊，黑龙江是啥？</span><br>
</p><p><b>鹦鹉螺号捕鲸手: </b><br>
<span>按时上班 发表于 2019-6-24 08:48</span><br>
<span>我记得国内知名的实体娃娃大牌子都在中山，所以我对中山一直有一种说不上来的好感 ...</span><br>
<span>中山大学，不在中山</span><br>
</p><p><b>我是大鲨鱼: </b><br>
<span>河水 发表于 2019-6-24 09:13</span><br>
<span>不是，中山大学不是中山的大学</span><br>
<span>Sun Yat-sen University，位于黑龙江省双鸭山市。</span><br>
</p><p><b>rockmangd: </b><br>
<span>我脑补也可以</span><br>
</p><p><b>bioCory: </b><br>
<span>bl0ck 发表于 2019-6-24 08:49</span><br>
<span>对抗性损失、感知损失、风格损失、解析损失、多尺度特征损失、总差异损失</span><br>
<span>哪个是你提出的创新点？</span><br>
<span> ...</span><br>
<span>国外一开源，国内就XX</span><br>
</p><p><b>lvseqiji: </b><br>
<span>中山大学我知道啊，在中山嘛</span><br>
<span>—— 来自 HUAWEI JSN-AL00a, Android 9上的 S1Next-鹅版 v2.1.0-play</span><br>
</p><p><b>feger: </b><br>
<span>字节跳动 跳动的不仅仅是字节</span><br>
</p><p><b>loka: </b><br>
<span>中山大学嘛，在中山陵旁边那个</span><br>
<span>—— 来自 OPPO PACM00, Android 8.1.0上的 S1Next-鹅版 v2.1.2</span><br>
</p><p><b>SICP: </b><br>
<span> 本帖最后由 SICP 于 2019-6-24 10:41 编辑 </span><br>
<span>笑话，河北工业大学不在河北难道在天津吗？</span><br>
</p><p><b>战术核辣条: </b><br>
<span>中山大学不在中山啊喂</span><br>
<span>—— 来自 OnePlus ONEPLUS A6000, Android 9上的 S1Next-鹅版 v2.1.2</span><br>
</p><p><b>zz1zz: </b><br>
<span>上次坛里有位去中大眼科看病，被坛友误认到中山的医院了。这次中大又被误认在中山。中大的知名度不够啊</span><br>
</p><p><b>松岡茉優: </b><br>
<span>中大虽然老校区被华工和华农占了，但不至于这么惨流落到中山市啊喂。怎么说也是全国前10的大学，知名度这么差的吗</span><br>
</p><p><b>atlus太郎: </b><br>
<span>这贴本来我估计大家会吐槽所谓的“毫无PS痕迹”，结果没想到有一个更大的槽点</span><br>
<span>建议SYU改名逸仙大学</span><br>
</p><p><b>windrarara: </b><br>
<span>我校科技树也点歪了吗</span><br>
</p><p><b>韩子: </b><br>
<span>windrarara 发表于 2019-6-24 13:34</span><br>
<span>我校科技树也点歪了吗</span><br>
<span>你校连美女脱衣主题的楼都能歪</span><br>
</p><p><b>苍白的烙印: </b><br>
<span>按时上班 发表于 2019-6-24 08:48</span><br>
<span>我记得国内知名的实体娃娃大牌子都在中山，所以我对中山一直有一种说不上来的好感 ...</span><br>
<span>由于工作原因还去听过一位中山的大叔如何把濒临破产的塑料厂拯救为日欧美宅男心中的美好</span><br>
</p><p><b>苍白的烙印: </b><br>
<span>deadog 发表于 2019-6-24 09:39</span><br>
<span>什么？中山大学不是在双鸭山吗？</span><br>
<span>没错 我们双鸭山职业学院欢迎你。怀芳堂欢迎你</span><br>
</p><p><b>菲特妹: </b><br>
<span>苍白的烙印 发表于 2019-6-24 13:58</span><br>
<span>由于工作原因还去听过一位中山的大叔如何把濒临破产的塑料厂拯救为日欧美宅男心中的美好 ...</span><br>
<span>中山那些都是毒胶吧。这能下得去屌？</span><br>
</p><p><b>battleship64: </b><br>
<span>那 美女脱衣做得到嘛</span><br>
</p><p><b>苍白的烙印: </b><br>
<span>菲特妹 发表于 2019-6-24 14:04</span><br>
<span>中山那些都是毒胶吧。这能下得去屌？</span><br>
<span>据大叔说，现在主要产品出口日欧，板鸭买的特别多</span><br>
</p><p><b>kumwoo: </b><br>
<span>中山公园也不在中山啊</span><br>
</p><p><b>czs13: </b><br>
<span>以后的caoer，连衣服都不是真的了？</span><br>
</p><p><b>古屋敷由良: </b><br>
<span>菲特妹 发表于 2019-6-24 14:04</span><br>
<span>中山那些都是毒胶吧。这能下得去屌？</span><br>
<span>菜花都有人下得去，毒胶算事吗</span><br>
</p><p><b>bigapple555: </b><br>
<span>GAN是真的好用</span><br>
</p><p><b>best: </b><br>
<span>松岡茉優 发表于 2019-6-24 11:10</span><br>
<span>中大虽然老校区被华工和华农占了，但不至于这么惨流落到中山市啊喂。怎么说也是全国前10的大学，知名度这么 ...</span><br>
<span>没错，排前十就是注水排名，出了广东就没影响力。</span><br>
</p><p><b>田多宇光: </b><br>
<span>我要是穿越到10年前，我一定要全仓比特币顺便发明发一篇名叫gan的论文</span><br>
</p><p><b>女人开车: </b><br>
<span>快点实用</span><br>
</p><p><b>chrispig: </b><br>
<span>菲特妹 发表于 2019-6-24 14:04</span><br>
<span>中山那些都是毒胶吧。这能下得去屌？</span><br>
<span>要出口自然就要符合目标国的进口安全规范，特别是欧洲佬特别严，你傻别人也不傻啊</span><br>
</p><p><b>李恭暔: </b><br>
<span>但是中山并没有中山大学啊</span><br>
</p><p><b>ady272: </b><br>
<span>看见字节跳动先点踩</span><br>
</p>]]></content:encoded>
      <guid isPermaLink="false">1841783[0-50]</guid>
    </item>
  </channel>
</rss>
