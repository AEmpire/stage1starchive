<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>一个人工智能和人类相对和平共处的世界观是怎样的？</title>
    <link>https://bbs.saraba1st.com/2b/</link>
    <description>一个人工智能和人类相对和平共处的世界观是怎样的？</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 09 Jul 2020 17:43:56 +0000</lastBuildDate>
    <item>
      <title>一个人工智能和人类相对和平共处的世界观是怎样的？[150-200]</title>
      <link>https://bbs.saraba1st.com/2b/thread-1859057-1-1.html</link>
      <description>一个人工智能和人类相对和平共处的世界观是怎样的？&#13;
不是黑客帝国那种“合作”，AI几乎把人类打烂了，最后感觉尼奥和人类也没啥谈判砝码，人类也不是莫名其妙不符合热力公式的人肉电池，而是人类和AI取长补短的在一起合作。人类与AI所谓挂羊头卖狗肉的作品太多，太多的作品都把AI过分的拟人化，机器猫，阿童木，底特律等等，但实际上没有受体的话AI不见得能感受到被奴役的痛苦和称霸搞破坏的兴奋，云端的AI也不会因为一个终端被破坏就死亡。AI在乎的可能是别的事情。稍微好一点的也有一定的生物本位毛病，比如我，机器人的那种，把能理解人类感情的AI抬的很高，“不近人情”的AI则低一级。攻壳剧场版1也是，傀儡王生硬的模仿有机生物的繁殖方式和死亡，完全是对已经机械飞升的意识的亵渎，他明明自己就能重新编程一些不同的多样化版本（当然还是要点名鞭尸一下最近的C&amp;T，ctmd，涉及AI的部分太tm弱智了，史诗级别的弱智）
&#13;
说起来其实人类也是一种冯诺依曼机，是否有从“两边都是机器”这个角度来看待人类和AI的呢？对人类高度解构的外星人题材有盲视，AI题材的有没有类似的？</description>
      <content:encoded><![CDATA[<p><b>凛凛233: </b><br>
<span> 本帖最后由 凛凛233 于 2019-10-16 17:32 编辑 </span><br>
<span>无限舰制 发表于 2019-10-16 03:13</span><br>
<span>这个嘛……更接近语义学上的问题吧</span><br>
<span>如果说是“陈述历史”的话，那么计算模型的来源的确是模仿人类的智能 ...</span><br>
<span>“陈述历史”，你们读书人真能整词，我也是服</span><br>
<span>o(︶︿︶)o 唉</span><br>
<span>长篇大论时，夸夸其谈</span><br>
<span>被动挨打时，云山雾罩</span><br>
<span>就不能老实点，乖乖认了</span><br>
<span>是就回答是，不是就回答不是嘛</span><br>
<span>你想干嘛不关我的事，不要来碰瓷我</span><br>
<span>啧</span><br>
<span>算了， </span><br>
</p><p><b>thisism: </b><br>
<span>大概类似现在得美国把。</span><br>
<span>AI看到普通人类在油桶啊电池啊边上，掏出**连射一个**</span><br>
</p><p><b>周处长: </b><br>
<span>我觉得人工智能发展到一定境界就是人类共同体，人作为个体无法完完全全带入人类这个概念，导致大多数行为是处于个体利益考虑，但是最为理想的强人工智能是有可能将自己作为人类来进行决策判断，例如现在的许多大数据分析后我们就可以判断一些现在很难取舍的东西，而这个人工智能本身也是盖亚这个概念的具象化</span><br>
</p><p><b>无限舰制: </b><br>
<span>凛凛233 发表于 2019-10-16 09:38</span><br>
<span>“陈述历史”，你们读书人真能整词，我也是服</span><br>
<span>o(︶︿︶)o 唉</span><br>
<span>长篇大论时，夸夸其谈</span><br>
<span>这个问题了结了其他问题还没完呢</span><br>
<span>我就想问你你是不是觉得人脑有什么特殊性，集成电路没法取代而已</span><br>
<span>——还是说单纯觉得人脑效率特别高？</span><br>
<span>当然，懒得继续讨论也无所谓，大家水贴娱乐而已</span><br>
</p><p><b>凛凛233: </b><br>
<span>无限舰制 发表于 2019-10-16 15:17</span><br>
<span>这个问题了结了其他问题还没完呢</span><br>
<span>我就想问你你是不是觉得人脑有什么特殊性，集成电路没法取代而 ...</span><br>
<span>你这个人不老实 </span><br>
<span>我这会儿也懒得理你</span><br>
</p><p><b>谈月色: </b><br>
<span>埃奈西德穆 发表于 2019-10-12 12:51</span><br>
<span>总结你说的两点：（1）人类的行为不仅仅是基因影响，他还受到文化等社会要素的决定，（2）自由意愿的幻觉 ...</span><br>
<span>我完全是个哲学门外汉，不过我确实认为所谓“意志”不管自不自由都不存在，人类说到底也就是一堆大分子罢了，人的意识是无数自然现象（准确点说，化学现象）中的一种。</span><br>
<span>但你说的那些“强决定论”【她没法为自己的行为负责，因此我们没有理由谴责或惩罚她，也没有理由称赞或者奖励她】【没人能够为自己的状态负责，多劳者多得这种道理也不再适用了】【如果人不具有这个能力，道德规则也毫无约束力，不如废弃】这几条是如何推导出来的我真是摸不着头脑，这就好比一条河会泛滥，反正河没有人类的意识，不能决定自己泛不泛滥，也不能摆脱物理法则——所以水利工程不如废弃？？？</span><br>
</p><p><b>azq123wsx: </b><br>
<span>凛凛233 发表于 2019-10-16 08:45</span><br>
<span>我当然是说，他前面几楼说的那些不能证明狗有意识</span><br>
<span>突然想到 不要说狗 连竹鼠都会得抑郁症 </span><br>
<span>一个会抑郁症的生物有没有精神与意识？</span><br>
</p><p><b>huaen: </b><br>
<span>铁臂阿童木后期还有浦泽直树的改编的PLUTO感觉凑合算是</span><br>
</p><p><b>ipcjs: </b><br>
<span> 本帖最后由 ipcjs 于 2019-10-17 12:33 编辑 </span><br>
<span>和真克瓦尔 发表于 2019-10-16 08:40</span><br>
<span>https://bbs.saraba1st.com/2b/thread-1857620-1-1.html</span><br>
<span>这一贴里说AI的部分把我想说的基本说了。 ...</span><br>
<span>这贴我唯一不赞同的就是AI部分，作者先预设“动画反对AI”的立场，再举动画里的“例子”，说“这些例子毫无说服力”。</span><br>
<span>动画根本没有所谓“反对AI”的立场，能有说服力才怪</span><br>
<span>典型的先放屁股再找证据，找不到就说这动画不行</span><br>
</p><p><b>kxh007458: </b><br>
<span>让AI拥有和人类一样的感情就好，够白左就不会消灭人类了。如果AI也会考虑关机是不是等于死了一次，数据转移后的自己还是不是自己这样的问题，也可能就启动后永不关机，一个硬盘用到底，实际寿命也不是无限的。更不会考虑无限增殖新的，更强的AI来淘汰自己。</span><br>
</p><p><b>凛凛233: </b><br>
<span>azq123wsx 发表于 2019-10-17 10:37</span><br>
<span>突然想到 不要说狗 连竹鼠都会得抑郁症 </span><br>
<span>一个会抑郁症的生物有没有精神与意识？ ...</span><br>
<span>得抑郁症还需要意识吗？那种吃药一般就能好的病，就像锁生锈了就加点油</span><br>
<span>对对对，有，都有</span><br>
</p><p><b>rentrody: </b><br>
<span>凛凛233 发表于 2019-10-15 02:46</span><br>
<span>当然有区别，比如，不会对着美女发情（…也未必，万一是那种机器人呢）</span><br>
<span>但是没有某些人想的那种区 ...</span><br>
<span>也许自我意识也是自然演化给人类留下的痕迹，强AI再聪明也不会有自我意识，除非人类专门赋予其类似人类自我意识的冗余程序组件。</span><br>
</p><p><b>rentrody: </b><br>
<span>Messiah_QY 发表于 2019-10-15 09:56</span><br>
<span>“我连动物都不会给公民权，机器更加不会。”</span><br>
<span>承载自身运算硬件的物理世界对AI来说很重要的话，最后的剧情 ...</span><br>
<span>生物是因为有生存欲望才能存在下去并进化，AI的诞生却不一定是生存竞争的结果，又从何而来生存和进化的欲望呢？</span><br>
</p><p><b>Messiah_QY: </b><br>
<span> 本帖最后由 Messiah_QY 于 2019-10-17 17:56 编辑 </span><br>
<span>rentrody 发表于 2019-10-17 17:45</span><br>
<span>生物是因为有生存欲望才能存在下去并进化，AI的诞生却不一定是生存竞争的结果，又从何而来生存和进化的欲 ...</span><br>
<span>如果AI连自己是怎么存在的，要不要延续自己都无所谓的话，那这个程序还没突破无生这个概念，只能叫人工智能。</span><br>
<span>不关心自己会不会被关机的AI存在吗？</span><br>
</p><p><b>rentrody: </b><br>
<span>不应 发表于 2019-10-15 08:26</span><br>
<span>我倒是挺好奇为什么挺多作品死活不愿意给高智能ai公民权，都到了这个水平的科技了难道还需要ai去全年无休的 ...</span><br>
<span>我也认为应该赋予AI公民权，但不是因为AI必然有自我意识或者可能叛乱，而是AI没有人权的话就给了资本家和独裁者无限权力，拥有了AI就可以随意制造任何产品和军队，垄断所有资源，没有资源的平民只能靠上层的施舍苟活。</span><br>
</p><p><b>rentrody: </b><br>
<span> 本帖最后由 rentrody 于 2019-10-17 18:09 编辑 </span><br>
<span>Messiah_QY 发表于 2019-10-17 17:54</span><br>
<span>如果AI连自己是怎么存在的，要不要延续自己都无所谓的话，那这个程序还没突破无生这个概念，只能叫人工智 ...</span><br>
<span>AI就是人工智能啊，至于有没有自我意识是智能之外的概念，可以给有自我意识的智能专门分个类叫拟人智能之类。</span><br>
</p><p><b>azq123wsx: </b><br>
<span>凛凛233 发表于 2019-10-17 15:48</span><br>
<span>得抑郁症还需要意识吗？那种吃药一般就能好的病，就像锁生锈了就加点油</span><br>
<span>对对对，有，都有 ...</span><br>
<span>我听不懂你在说什么</span><br>
<span>到底想表达个什么意思</span><br>
</p><p><b>azq123wsx: </b><br>
<span>rentrody 发表于 2019-10-17 17:41</span><br>
<span>也许自我意识也是自然演化给人类留下的痕迹，强AI再聪明也不会有自我意识，除非人类专门赋予其类似人类自 ...</span><br>
<span>强人工智能的定义不就是有自我意识的人工智能嘛</span><br>
</p><p><b>凛凛233: </b><br>
<span>azq123wsx 发表于 2019-10-18 00:56</span><br>
<span>我听不懂你在说什么</span><br>
<span>到底想表达个什么意思</span><br>
<span>对对对，都有意识哦</span><br>
<span>母鸡妈妈生小鸡时，都会想着，要生小宝宝喽，要快快长大哦</span><br>
<span>然后被你吃了</span><br>
</p><p><b>azq123wsx: </b><br>
<span>凛凛233 发表于 2019-10-18 02:47</span><br>
<span>对对对，都有意识哦</span><br>
<span>母鸡妈妈生小鸡时，都会想着，要生小宝宝喽，要快快长大哦</span><br>
<span>还是听不懂你想表达什么。</span><br>
<span>难道说你会觉得很残忍嘛？</span><br>
<span>那样的话 </span><br>
<span>认为动物与人区别在于意识的有无不过是给自己良心的一个借口。</span><br>
</p><p><b>凛凛233: </b><br>
<span>azq123wsx 发表于 2019-10-18 03:14</span><br>
<span>还是听不懂你想表达什么。</span><br>
<span>难道说你会觉得很残忍嘛？</span><br>
<span>那样的话 </span><br>
<span>都有都有</span><br>
<span>问就是都有</span><br>
</p>]]></content:encoded>
      <guid isPermaLink="false">1859057[150-200]</guid>
    </item>
    <item>
      <title>一个人工智能和人类相对和平共处的世界观是怎样的？[100-150]</title>
      <link>https://bbs.saraba1st.com/2b/thread-1859057-1-1.html</link>
      <description>一个人工智能和人类相对和平共处的世界观是怎样的？&#13;
不是黑客帝国那种“合作”，AI几乎把人类打烂了，最后感觉尼奥和人类也没啥谈判砝码，人类也不是莫名其妙不符合热力公式的人肉电池，而是人类和AI取长补短的在一起合作。人类与AI所谓挂羊头卖狗肉的作品太多，太多的作品都把AI过分的拟人化，机器猫，阿童木，底特律等等，但实际上没有受体的话AI不见得能感受到被奴役的痛苦和称霸搞破坏的兴奋，云端的AI也不会因为一个终端被破坏就死亡。AI在乎的可能是别的事情。稍微好一点的也有一定的生物本位毛病，比如我，机器人的那种，把能理解人类感情的AI抬的很高，“不近人情”的AI则低一级。攻壳剧场版1也是，傀儡王生硬的模仿有机生物的繁殖方式和死亡，完全是对已经机械飞升的意识的亵渎，他明明自己就能重新编程一些不同的多样化版本（当然还是要点名鞭尸一下最近的C&amp;T，ctmd，涉及AI的部分太tm弱智了，史诗级别的弱智）
&#13;
说起来其实人类也是一种冯诺依曼机，是否有从“两边都是机器”这个角度来看待人类和AI的呢？对人类高度解构的外星人题材有盲视，AI题材的有没有类似的？</description>
      <content:encoded><![CDATA[<p><b>和真克瓦尔: </b><br>
<span>acejoe 发表于 2019-10-14 15:28</span><br>
<span>《她》</span><br>
<span>人工智能直接飞升，人类当个聊天工具人</span><br>
<span>男主是真的惨</span><br>
</p><p><b>ipcjs: </b><br>
<span>和真克瓦尔 发表于 2019-10-15 00:27</span><br>
<span>从那个机器人导演骗吃骗喝泡澡起就基本认定剧本对AI的定义和蓝猫淘气3000问差不多，果然到最后也没有更进 ...</span><br>
<span>搞笑桥段而已，你从里面看出了啥？</span><br>
<span>蓝猫淘气300问，没看完，里面对AI是什么定位？</span><br>
<span>c&t明显就是部卖歌的片子，AI只是背景设定，为什么一定要更进一步？</span><br>
</p><p><b>凛凛233: </b><br>
<span> 本帖最后由 凛凛233 于 2019-10-15 02:56 编辑 </span><br>
<span>其实严格地说，人类不是冯诺依曼机</span><br>
<span>人的大脑为了处理逻辑问题，在神经网络之上的意识层面“虚拟出”一种处理信息/问题的方式 </span><br>
<span>图灵那批人，为了模仿人类这种处理特定逻辑问题/信息的方式，制作出了图灵机/冯诺依曼机</span><br>
<span>然后，现在的所谓ai，基本上都是骗人的，在图灵机的基础上增加复杂性，这是本末倒置</span><br>
<span>真正的ai，就应该用类似忆阻器这类的东西，组建神经网络…人有多少亿神经元来着？天文数字</span><br>
<span>最后，只要足够复杂，机器人与人类，就没有某些人想的那种区别了</span><br>
</p><p><b>huhu0007: </b><br>
<span>这不就是失控机仆吗</span><br>
</p><p><b>凛凛233: </b><br>
<span> 本帖最后由 凛凛233 于 2019-10-15 02:34 编辑 </span><br>
<span>埃奈西德穆 发表于 2019-10-12 22:16</span><br>
<span>首先，自由意志（意愿）的能力就是进行选择的能力。追问这个能力的出身无关紧要。因为就算自由意愿有非自 ...</span><br>
<span>自由意愿源自没有自由的物质，但它不等同于它的来源</span><br>
<span>这不明摆着是自相矛盾吗，a源自b，但b不是a的来源</span><br>
<span>你怎么能相信这种事→_→</span><br>
</p><p><b>❃✽✾✶✻✼: </b><br>
<span>凛凛233 发表于 2019-10-15 01:56</span><br>
<span>其实严格地说，人类肯定不是冯诺依曼机</span><br>
<span>人的大脑为了处理逻辑问题，在神经网络之上的意识层面“虚拟 ...</span><br>
<span>一定会有很大区别的   进化到人类为止的动物进化阶段给人类留下了太多痕迹   对于AI来说却不需要</span><br>
<span>从发端到终极都会不同   如果分类   人类肯定和阿猫阿狗一类   ai肯定和电脑一类   在AI看来应该也是这样</span><br>
<span>机器人像人类可能会有优势   但是觉得自己是人类就是身份认同障碍了</span><br>
</p><p><b>凛凛233: </b><br>
<span> 本帖最后由 凛凛233 于 2019-10-15 03:14 编辑 </span><br>
<span>❃✽✾✶✻✼ 发表于 2019-10-15 02:34</span><br>
<span>一定会有很大区别的   进化到人类为止的动物进化阶段给人类留下了太多痕迹   对于AI来说却不需要</span><br>
<span>从 ...</span><br>
<span>当然有区别，比如，不会对着美女发情（…也未必，万一是那种机器人呢）</span><br>
<span>但是没有某些人想的那种区别，比如，意识，意志，思想等高级能力方面</span><br>
<span>要分类的话，也要按照基本法啊</span><br>
<span>按有没有意识分类，人＆强ai是一类，猪和电脑、剃须刀、铁锹是一类</span><br>
<span>按插不插电分类，大概就是你那种分法了</span><br>
<span>如果按照，是否对纸片人发情分类呢…很难说</span><br>
</p><p><b>不应: </b><br>
<span>我倒是挺好奇为什么挺多作品死活不愿意给高智能ai公民权，都到了这个水平的科技了难道还需要ai去全年无休的工作并且随便一个脑子比他蠢几十倍的人类都可以决定他的命运，这个社会才能维持下去么完全无法理解给ai公民权的坏处，至于高智能ai看到那些没脑子的机器被各种破坏会产生同理心更是不可能了。群星只要给ai公民权就能避免机械叛乱，虽然武断但至少挺符合逻辑的</span><br>
</p><p><b>Messiah_QY: </b><br>
<span>“我连动物都不会给公民权，机器更加不会。”</span><br>
<span>承载自身运算硬件的物理世界对AI来说很重要的话，最后的剧情肯定是天网了，为了自身进化肯定跟生物一样掠夺生存资源。。。。</span><br>
</p><p><b>TNONDK: </b><br>
<span>人和人都不能和平共存还指望ai和人和平共存</span><br>
</p><p><b>❃✽✾✶✻✼: </b><br>
<span>凛凛233 发表于 2019-10-15 02:46</span><br>
<span>当然有区别，比如，不会对着美女发情（…也未必，万一是那种机器人呢）</span><br>
<span>但是没有某些人想的那种区 ...</span><br>
<span>意识可能并不能算一种分类方法   因为人类的意识是连续于动物意识的      只不过是更强而已</span><br>
<span>人相对于动物有意志是为了划分人权和动物权的界限产生的    很难拿标准确定</span><br>
<span>包括使用工具啊    从事生产劳动啊    都是偏见而已    阶级社会也不是人类才有    </span><br>
<span>所以一方面我们可能很难认识到AI成为强AI的节点   毕竟和之前也没什么大的区别    另一方面   AI对自己的有没有意识也不是那么关心    </span><br>
</p><p><b>凛凛233: </b><br>
<span>❃✽✾✶✻✼ 发表于 2019-10-15 18:43</span><br>
<span>意识可能并不能算一种分类方法   因为人类的意识是连续于动物意识的      只不过是更强而已</span><br>
<span>人相对于 ...</span><br>
<span>人之外的动物没有意识啊，真的没有</span><br>
<span>我怀疑，婴儿在学会说话之前也没有</span><br>
<span>你还记得你婴儿时期的感受和发生的事情吗</span><br>
<span>能对外界做出反应，并不等于有意识</span><br>
<span>像婴儿能对光做出反应，我的智能手机也可以啊</span><br>
</p><p><b>凛凛233: </b><br>
<span>TNONDK 发表于 2019-10-15 10:27</span><br>
<span>人和人都不能和平共存还指望ai和人和平共存</span><br>
<span>对啊，3019年的s1，死宅人类和死宅机器人一定会吵起来</span><br>
<span>“机器人更有权利对着二次元纸片人发情”</span><br>
<span>“二不起，二不起”</span><br>
<span>死宅相轻</span><br>
</p><p><b>シャスタ: </b><br>
<span>AI和数字化人类大脑的AI是两回事.后者应该就视为人类.前者根本不用说人话,人话那是给人类输出用的.自身根本不会有人一样的思考.</span><br>
<span>同时AI跟人类的时间感受不一样,这个我还没见到哪个作品详细描写了.你对着AI打一拳,那都是慢动作,人一秒分析你几万帧,还不嫌累.</span><br>
</p><p><b>❃✽✾✶✻✼: </b><br>
<span>凛凛233 发表于 2019-10-15 18:54</span><br>
<span>人之外的动物没有意识啊，真的没有</span><br>
<span>我怀疑，婴儿在学会说话之前也没有</span><br>
<span>当然是有的    黑猩猩能从镜子中认出自己    这是完整自我意识的标志   婴儿不可能比成年动物意识强   </span><br>
<span>总有个构建过程</span><br>
<span>反应和意识的关系也比较复杂      人类之所以有最强的意识   主要还是过度发达的大脑产生很多的运算冗余</span><br>
<span>但对哺乳类或者鸟类而言    一般都有相当程度冗余    不止是对外界反应的程度      像学习行为就是个典型    到黑猩猩的程度已经能玩很多游戏了</span><br>
<span>爬行类这种比较原始的神经系统   可能谈不上意识   不过从整个进化树上看没比人类原始太多   所以这个东西也很难划个绝对标准      像老年痴呆   意识逐渐模糊   很难划定到哪里就不如猩猩了   最后可能连蜥蜴都不如   这都是连贯的</span><br>
</p><p><b>シャスタ: </b><br>
<span>凛凛233 发表于 2019-10-15 18:54</span><br>
<span>人之外的动物没有意识啊，真的没有</span><br>
<span>我怀疑，婴儿在学会说话之前也没有</span><br>
<span>大猩猩甚至有离婚,黑猩猩能理解领工资配合做实验.</span><br>
<span>再不济你养个聪明的狗,能分析出来你茶几上的液体容器不能碰洒.同时在家里到处跑还不造成破坏.</span><br>
<span>你给我说这不叫意识?叫对着光作反应?</span><br>
</p><p><b>凛凛233: </b><br>
<span>シャスタ 发表于 2019-10-15 19:23</span><br>
<span>大猩猩甚至有离婚,黑猩猩能理解领工资配合做实验.</span><br>
<span>再不济你养个聪明的狗,能分析出来你茶几上的液体容器 ...</span><br>
<span>那条狗</span><br>
<span>它是如何“分析”的？</span><br>
</p><p><b>シャスタ: </b><br>
<span> 本帖最后由 シャスタ 于 2019-10-15 19:49 编辑 </span><br>
<span>凛凛233 发表于 2019-10-15 19:45</span><br>
<span>那条狗</span><br>
<span>它是如何“分析”的？</span><br>
<span>靠智商,实际上跟你没区别,只是说不了人话你跟他没法语言交流而已.都不用到狗这个级别,乌鸦都能自己分析情况从周围环境制造工具完成目的.不用教,自己学出来.</span><br>
</p><p><b>凛凛233: </b><br>
<span>シャスタ 发表于 2019-10-15 19:48</span><br>
<span>靠智商,实际上跟你没区别,只是说不了人话你跟他没法语言交流而已.都不用到狗这个级别,乌鸦都能自己分析情 ...</span><br>
<span>不不不，我们不一样求你了，</span><br>
<span>你说的那种“分析”，和意识不是一回事，那些都无法进入意识层面</span><br>
<span>你们还记得巴甫洛夫做的那个实验吗</span><br>
</p><p><b>和真克瓦尔: </b><br>
<span>ipcjs 发表于 2019-10-15 01:08</span><br>
<span>搞笑桥段而已，你从里面看出了啥？</span><br>
<span>蓝猫淘气300问，没看完，里面对AI是什么定位？</span><br>
<span>可是“人的歌vsAI的歌”是核心冲突之一呀。AI为什么需要吃饭泡澡？谁给他编的骗人的程序？这么人性化为什么非要和真人隔开搞什么AI的歌就是不如人？你要说机器猫那样的拟人但是谁也没有瞧不起机器人都当伙伴家人也算了，搁阿童木里都是妥妥的人类的傲慢。</span><br>
</p><p><b>和真克瓦尔: </b><br>
<span>不应 发表于 2019-10-15 08:26</span><br>
<span>我倒是挺好奇为什么挺多作品死活不愿意给高智能ai公民权，都到了这个水平的科技了难道还需要ai去全年无休的 ...</span><br>
<span>一般来说肯定会给的，政客和资本家不是傻子，最次也不会任由击巴人虐待AI，现实中熊猫的命也比一些流浪汉的命更值钱呀。很多就是不给的故事都是指桑骂槐讽刺现实生活中的种族歧视。</span><br>
</p><p><b>无限舰制: </b><br>
<span>凛凛233 发表于 2019-10-15 01:56</span><br>
<span>其实严格地说，人类不是冯诺依曼机</span><br>
<span>人的大脑为了处理逻辑问题，在神经网络之上的意识层面“虚拟出” ...</span><br>
<span>图灵机和冯诺依曼结构根本是两个领域的概念</span><br>
<span>图灵机在数学领域上和很多其他结构（lamda算法、元胞自动机、神经网络）等效</span><br>
<span>冯诺依曼结构只是对图灵机的一种工程实现而已</span><br>
<span>你说现在的计算机都是纸带长度有限的图灵机倒也没错，但在数学意义上一个标准图灵机也能模拟其它图灵机，除了运算速度以外复杂度并没有本质差别</span><br>
<span>图灵机和冯诺依曼结构从来也不是为了模仿人类而制造的，前者更接近于数学意义上的模型构建，只不过比起其他的计算模型图灵机很适合工程实现而已</span><br>
<span>说到这里，有个很有趣的论题：一个完美记忆，不会出错的人使用纸笔的计算能力完全等价于一台图灵机，当然，这是个假设</span><br>
<span>这一点直接指向了等效的强AI假设，人脑能做到的事机器就能做到</span><br>
<span>当然要是采纳人脑有某些特殊结构（比如内含的量子效应）的话，那么人脑就能在某种意义上超越标准图灵机，这个时候用普通电子元件造不出来AI也是可以理解的了</span><br>
</p><p><b>Austaras: </b><br>
<span>凛凛233 发表于 2019-10-15 01:56</span><br>
<span>其实严格地说，人类不是冯诺依曼机</span><br>
<span>人的大脑为了处理逻辑问题，在神经网络之上的意识层面“虚拟出” ...</span><br>
<span>忆阻器并不能增强计算能力</span><br>
<span>通常认为超越通用图灵机的计算模型都是不能被造出来的</span><br>
</p><p><b>无限舰制: </b><br>
<span> 本帖最后由 无限舰制 于 2019-10-16 02:01 编辑 </span><br>
<span>Austaras 发表于 2019-10-16 00:56</span><br>
<span>忆阻器并不能增强计算能力</span><br>
<span>通常认为超越通用图灵机的计算模型都是不能被造出来的 ...</span><br>
<span>是这样</span><br>
<span>一帮子超图灵机不是要求无限能源就是物质无限可分，要不然干脆逆时序</span><br>
<span>不过我是认为强AI的可实现性跟可计算性这个大问题不太相关，要不了多久就能做出来了</span><br>
<span>虽然GEB的作者认为AI的逻辑系统没法处理自指问题，但一套严格清晰的逻辑系统不见得是必须的……</span><br>
<span>自然语言的不精确度导致你很难说这是个严格的“逻辑系统”</span><br>
</p><p><b>凛凛233: </b><br>
<span>无限舰制 发表于 2019-10-16 00:49</span><br>
<span>图灵机和冯诺依曼结构根本是两个领域的概念</span><br>
<span>图灵机在数学领域上和很多其他结构（lamda算法、元胞自动机 ...</span><br>
<span>不是模仿人类，那是模仿谁呢</span><br>
<span>地球上之前也没有什么其他的东西能做这种事</span><br>
<span>怎么说呢，</span><br>
<span>图灵在造图灵机时，就是在重现＆提炼自己解决数学问题的步骤</span><br>
<span>有意或无意的模仿了自己（当然是有意的）</span><br>
<span>然后，ai的瓶颈与量子效应无关</span><br>
</p><p><b>凛凛233: </b><br>
<span>Austaras 发表于 2019-10-16 00:56</span><br>
<span>忆阻器并不能增强计算能力</span><br>
<span>通常认为超越通用图灵机的计算模型都是不能被造出来的 ...</span><br>
<span>谁告诉你忆阻器是为了增强计算能力啊，又不是在造计算器，不用追求那个</span><br>
<span>写的很清楚，是为了组建神经网络，你应该先了解一下人脑的工作原理</span><br>
</p><p><b>无限舰制: </b><br>
<span> 本帖最后由 无限舰制 于 2019-10-16 02:12 编辑 </span><br>
<span>凛凛233 发表于 2019-10-16 01:58</span><br>
<span>不是模仿人类，那是模仿谁呢</span><br>
<span>地球上之前也没有什么其他的东西能做这种事</span><br>
<span>这么说吧……我倾向于是认为人脑在逻辑推理时的工作机制和图灵机等效</span><br>
<span>并不存在模仿人脑这一回事，我们只是从神经网络里提炼出了一个标准的计算模式</span><br>
<span>图灵机是“还原”出来的</span><br>
<span>现在问题的焦点回到人脑有没有一些通用图灵机所不具备的特别功能这个问题上</span><br>
<span>顺带一提我是支持整个宇宙可以用一台通用图灵机模拟的……换句话说，我根本不需要什么特异功能，通用图灵机这个模型本身就可以模拟包括人脑在内的一切东西</span><br>
<span>上面这是逻辑层面的问题，但我认为具体到现实里大家只会关注计算机的性能和应对问题的能力，这属于怎么提升计算能力的技术问题</span><br>
<span>这方面的瓶颈……我觉得就不是“定义人和AI的根本差别”的问题了，而纯粹是行为主义的，看起来差不多就可以认为AI有智能了我觉得神经网络本身并不具有物理上的优越性……你拿规范化的集成电路和冯诺依曼结构一样能等效化</span><br>
<span>何况人脑的工作原理本身就不是一件很好搞清楚的事</span><br>
</p><p><b>凛凛233: </b><br>
<span>无限舰制 发表于 2019-10-16 02:08</span><br>
<span>这么说吧……我倾向于是认为人脑在逻辑推理时的工作机制和图灵机等效</span><br>
<span>并不存在模仿人脑这一回事，我们只 ...</span><br>
<span>图灵机是怎么还原出来的</span><br>
</p><p><b>无限舰制: </b><br>
<span>凛凛233 发表于 2019-10-16 02:11</span><br>
<span>图灵机是怎么还原出来的</span><br>
<span>我想了想这个问题得再继续回溯来看我们的分歧</span><br>
<span>首先是不是所有现实问题都可以还原抽象成计算问题来解决……</span><br>
<span>认同这一点的话图灵机就是试图标准化“计算”这件事，读取状态，储存状态，按照计算规则变动状态，再输出</span><br>
<span>当然，就人脑而言，很多时候并没有明确意识到自己在做计算这件事</span><br>
<span>但开发强ai的时候也没必要拘泥于对齐人脑啊</span><br>
</p><p><b>Austaras: </b><br>
<span>凛凛233 发表于 2019-10-16 02:05</span><br>
<span>谁告诉你忆阻器是为了增强计算能力啊，又不是在造计算器，不用追求那个</span><br>
<span>你楼下说的很好了, 这里的计算能力不是说的一般的performance而是computability</span><br>
<span>制造神经网路并不需要物理上的还原才能制造, 使用图灵机模拟是可行的</span><br>
</p><p><b>无限舰制: </b><br>
<span> 本帖最后由 无限舰制 于 2019-10-16 02:35 编辑 </span><br>
<span>其实这里就触及到我刚才说的关键点了啊，到底运行在集成电路上的“神经网络算法”和人脑的神经网络是不是一回事？</span><br>
<span>作为数学模型的神经网络和图灵机算法被证明是等价的了，但上面那个问题还等待着脑科学和认知科学的研究</span><br>
<span>人脑可能的确因为特殊的物理存在形式导致了其和抽象出来的神经网络算法有着区别——比如说这玩意万一真的是某种超图灵机呢？比如说量子效应或者别的什么奇奇怪怪的玩意导致人脑不能完全等同于标准计算模型的话……</span><br>
<span>这个时候回归到物理搭建神经元（哪怕是塑料和金属的）网络就是有意义的了</span><br>
<span>虽然我个人倾向于人脑并不具备这种等级的特殊性，不过也没什么证据，只能说是“地球非特殊”的一点延伸观念吧</span><br>
<span>不过至少现在看来这个领域还远远没有走到瓶颈，单单是模拟出来的神经元数量都不如人脑，更别提互相连接的复杂性，等到神经网络算法的模拟真的在规模上等效于人脑却还没涌现出智能的时候，再回过头来关注物理上的神经元也不迟</span><br>
</p><p><b>凛凛233: </b><br>
<span>Austaras 发表于 2019-10-16 02:23</span><br>
<span>你楼下说的很好了, 这里的计算能力不是说的一般的performance而是computability</span><br>
<span>制造神经网路并不需要物 ...</span><br>
<span>虚拟，那要多没效率</span><br>
<span>不只是没效率那么简单</span><br>
</p><p><b>凛凛233: </b><br>
<span>无限舰制 发表于 2019-10-16 02:19</span><br>
<span>我想了想这个问题得再继续回溯来看我们的分歧</span><br>
<span>首先是不是所有现实问题都可以还原抽象成计算问题来解决… ...</span><br>
<span>我觉得，你还是先回答这个问题</span><br>
</p><p><b>无限舰制: </b><br>
<span>凛凛233 发表于 2019-10-16 02:35</span><br>
<span>虚拟，那要多没效率</span><br>
<span>不只是没效率那么简单</span><br>
<span>可是制造物理性的神经元这个过程我也可以说相当麻烦又没效率啊，至少不能光刻机一排印出来大批量生产</span><br>
<span>人脑神经元互联的模式要求立体走线，电力驱动又有严重的发热问题，到最后非得还原突触的电化学机制不可</span><br>
<span>最后再提一点，人脑的体积和规模是为了生物使用被自然选择优化过的，你拿去处理很复杂的问题反而吃瘪</span><br>
<span>我要个锤子效率，直接暴力堆数量和体积超越人脑啊</span><br>
<span>为什么冯诺依曼结构成了图灵机的物理实现模式？还不是因为方便啊</span><br>
</p><p><b>无限舰制: </b><br>
<span>我再提供一个思路吧，你觉得计算机模拟水蛭神经网络能等效吗？等效的话我们就可以加规模加数量模拟自然进化的过程过渡到人脑</span><br>
<span>这个问题是在确认你的立场：神经网络是不是有某种特殊性</span><br>
<span>——还是说，单纯因为神经网络在处理复杂现实相关问题的时候效率最高而已，你可能是认为按照上面那种升级进化过程会导致造出来的计算机效率奇低根本不实用？</span><br>
<span>我想确认下你的态度，这决定了我们要讨论工程技术问题还是某种意义上的数学和逻辑相关问题……</span><br>
</p><p><b>凛凛233: </b><br>
<span>无限舰制 发表于 2019-10-16 02:46</span><br>
<span>我再提供一个思路吧，你觉得计算机模拟水蛭神经网络能等效吗？等效的话我们就可以加规模加数量模拟自然进化 ...</span><br>
<span>不是，图灵机到底怎么还原出来的</span><br>
<span>你质疑了我前面说的话，没说清楚不行啊，是不是</span><br>
<span>以后说着说着，你又跳过去转移话题了怎么办，我没时间在这跟你绕啊</span><br>
<span>图灵死的怨啊</span><br>
<span>咱先回去，怎么样</span><br>
</p><p><b>无限舰制: </b><br>
<span>凛凛233 发表于 2019-10-16 02:55</span><br>
<span>不是，图灵机到底怎么还原出来的</span><br>
<span>你质疑了我前面说的话，没说清楚不行啊，是不是</span><br>
<span>我说过了啊，图灵机就是还原人在纸上做计算的过程，储存状态，根据规则进行计算，输出状态</span><br>
</p><p><b>凛凛233: </b><br>
<span> 本帖最后由 凛凛233 于 2019-10-16 03:13 编辑 </span><br>
<span>无限舰制 发表于 2019-10-16 03:02</span><br>
<span>我说过了啊，图灵机就是还原人在纸上做计算的过程，储存状态，根据规则进行计算，输出状态 ...</span><br>
<span>那不就是模仿人吗</span><br>
<span>我说</span><br>
<span>图灵在造图灵机时，就是在重现＆提炼自己解决数学问题的步骤</span><br>
<span>有意或无意的模仿了自己（当然是有意的）</span><br>
<span>你说不是，那是怎么造出来的</span><br>
</p><p><b>无限舰制: </b><br>
<span>凛凛233 发表于 2019-10-16 03:10</span><br>
<span>那不就是模仿人吗</span><br>
<span>这个嘛……更接近语义学上的问题吧</span><br>
<span>如果说是“陈述历史”的话，那么计算模型的来源的确是模仿人类的智能活动</span><br>
<span>但在这里我是想突出一个“计算活动绝非人类专属”的意思……或者说这个模型被提炼出来以后就超越了单纯的模仿，毕竟直觉也可以计算化（这个是我个人认可的一个前提）</span><br>
</p><p><b>azq123wsx: </b><br>
<span>凛凛233 发表于 2019-10-15 19:58</span><br>
<span>不不不，我们不一样求你了，</span><br>
<span>你说的那种“分析”，和意识不是一回事，那些都无法进入意识层面</span><br>
<span>不明白你想说什么</span><br>
<span>巴甫洛夫的狗 条件反射实验 条件反射能力在狗身上起效果，在人身上一样有效呀。</span><br>
<span>是想说人不具备条件反射能力？</span><br>
<span>还是想说，狗具备条件反射能力，所以它只具备这样的能力？</span><br>
<span>那人也具备条件反射能力，所以人也只具备这样的能力？？</span><br>
</p><p><b>ipcjs: </b><br>
<span>和真克瓦尔 发表于 2019-10-15 23:32</span><br>
<span>可是“人的歌vsAI的歌”是核心冲突之一呀。AI为什么需要吃饭泡澡？谁给他编的骗人的程序？这么人性化为什 ...</span><br>
<span>安杰拉、fire男的歌都是用AI创作的，他们什么时候比主角差了？</span><br>
<span>这动画的唯一核心只有“卖歌”，所谓的“AI vs 人”只是你的一厢情愿</span><br>
<span>— from Google Pixel 2 XL, Android 10 of S1 Next Goose v2.1.2</span><br>
</p><p><b>azq123wsx: </b><br>
<span>现在的ai算不算ai？</span><br>
<span>现在人类使用（“奴役”）ai算不算和平共处？</span><br>
<span>如果都是的话，那现在人与ai的关系会一直持续下去。</span><br>
<span>如果这里的ai仅限于具备自我意识与自由意志的强ai的话。</span><br>
<span>那么这样的ai算不算人？</span><br>
<span>如果算人，那么具备全面的更强能力的新人类逐渐淘汰替代掉旧人类不是理所当然的事情？</span><br>
<span>如果不算人，我们该如何处理它？</span><br>
<span>换句话说 我使用/奴役/随意的杀掉你 你干不干？</span><br>
</p><p><b>无限舰制: </b><br>
<span> 本帖最后由 无限舰制 于 2019-10-16 04:11 编辑 </span><br>
<span>azq123wsx 发表于 2019-10-16 03:58</span><br>
<span>现在的ai算不算ai？</span><br>
<span>现在人类使用（“奴役”）ai算不算和平共处？</span><br>
<span>如果都是的话，那现在人与ai的关系会一直 ...</span><br>
<span>看具体情况啊</span><br>
<span>第一种，人自己逐渐AI化，各种植入物脑部强化，两者界限越来越模糊</span><br>
<span>第二种，“天性”，ai可不是动物，就算要做人类看起来很辛苦的工作也不一定会抱怨</span><br>
<span>第三、对于超智能而言自我意志与意识或许是完全不能以人类的方式理解的……他们也许根本就不在乎人类</span><br>
<span>总之，我不是太建议直接把国家/种族关系往AI身上套……</span><br>
<span>就提生死观这一件事，我能把自己复制粘贴的时候，或许我会觉得在乎生死的人类才奇怪……</span><br>
<span>网络化集群意识损失一两个终端根本无所谓</span><br>
<span>最小的ai完全可能是动物化亚人类等级的，没多少明确的自我主张，渗透到每个人身边</span><br>
<span>最大的ai又很可能是超越人智，直接等同于整个社会网络，担负着人类社会运行的基本工作的——换句话说这种巨型系统一旦觉醒了你没什么办法反抗，除非两败俱伤，而这件事在超智能保持理性的前提下大家都不想看到</span><br>
<span>至于一般人最担心的那种住在人形身体里和人类一样整天吵吵闹闹的“普通AI”或者说换皮人类我反而觉得没必要大量制造，在关键岗位上有就行了——甚至这些岗位都可以交给超智能的分支来做</span><br>
</p><p><b>azq123wsx: </b><br>
<span>无限舰制 发表于 2019-10-16 04:03</span><br>
<span>看具体情况啊</span><br>
<span>第一种，人自己逐渐AI化，各种植入物脑部强化，两者界限越来越模糊</span><br>
<span>关于第二条第三条 稍微说下</span><br>
<span>“新人类”只是单纯比 旧 人类 全方面的更能干，资本会自然的往“新人类”身上富集，也没有什么理由分配给 旧 人类。旧 人类缺少资源，并一直被剥削， 自然的就消亡了。到时候 旧 人类就算想反抗，也是“新人类”全方面的更具备优势，也反抗不了，不存在两败俱伤的情况。旧 人类 不愿意看到这种情况，是旧人类的事，和“新人类”又有什么关系呢。</span><br>
<span>对于强ai的展望，我也比较支持第一种想法。植入强化部件，强化人类大脑本身。或者说，把强ai的作用限死在人类肉体之内。与人的大脑/身体，一同运作也一同消失。成为人类自我意识的一部分，天然且全然的利益共同体。</span><br>
</p><p><b>lostinyume: </b><br>
<span>不是，楼主看过《深渊上的火》或者王晋康写的《养蜂人》嘛？</span><br>
</p><p><b>azq123wsx: </b><br>
<span>无限舰制 发表于 2019-10-16 04:03</span><br>
<span>看具体情况啊</span><br>
<span>第一种，人自己逐渐AI化，各种植入物脑部强化，两者界限越来越模糊</span><br>
<span>不过这样的想法也就意味着，我认为，人的概念是锚定于肉体而存在的。</span><br>
<span>人之所以是人，狗之所以是狗，只是因为物种不一样，和自我意识，自由意志没什么关系。</span><br>
</p><p><b>和真克瓦尔: </b><br>
<span>ipcjs 发表于 2019-10-16 03:48</span><br>
<span>安杰拉、fire男的歌都是用AI创作的，他们什么时候比主角差了？</span><br>
<span>这动画的唯一核心只有“卖歌”，所谓的“ ...</span><br>
<span>https://bbs.saraba1st.com/2b/thread-1857620-1-1.html</span><br>
<span>这一贴里说AI的部分把我想说的基本说了。</span><br>
</p><p><b>凛凛233: </b><br>
<span>azq123wsx 发表于 2019-10-16 03:44</span><br>
<span>不明白你想说什么</span><br>
<span>巴甫洛夫的狗 条件反射实验 条件反射能力在狗身上起效果，在人身上一样有效呀。 ...</span><br>
<span>我当然是说，他前面几楼说的那些不能证明狗有意识</span><br>
</p><p><b>amachi333: </b><br>
<span>人能和人和平共处的世界都还没找到</span><br>
</p><p><b>dclara1: </b><br>
<span>以前尼哥也不被主流社会当人看，讨论AI会不会被主流社会赋予基本"人权"，完全可以用尼哥历史来套。</span><br>
<span>我能想到的就两种情况：</span><br>
<span>1. 对AI能共情的人类越来越多，对AI的不人道对待会引起社会越来越广泛的反感，类似"高速拦车解救AI萝莉"之类的事件频发，社会不稳定因素增加，需要给AI平权来平息；（南北战争）</span><br>
<span>2. AI发展出求生欲，而且有抱团意识，天天搞"A命贵"运动，对主流人类社会反攻倒算，社会矛盾激化，需要平权来平息。</span><br>
</p>]]></content:encoded>
      <guid isPermaLink="false">1859057[100-150]</guid>
    </item>
    <item>
      <title>一个人工智能和人类相对和平共处的世界观是怎样的？[50-100]</title>
      <link>https://bbs.saraba1st.com/2b/thread-1859057-1-1.html</link>
      <description>一个人工智能和人类相对和平共处的世界观是怎样的？&#13;
不是黑客帝国那种“合作”，AI几乎把人类打烂了，最后感觉尼奥和人类也没啥谈判砝码，人类也不是莫名其妙不符合热力公式的人肉电池，而是人类和AI取长补短的在一起合作。人类与AI所谓挂羊头卖狗肉的作品太多，太多的作品都把AI过分的拟人化，机器猫，阿童木，底特律等等，但实际上没有受体的话AI不见得能感受到被奴役的痛苦和称霸搞破坏的兴奋，云端的AI也不会因为一个终端被破坏就死亡。AI在乎的可能是别的事情。稍微好一点的也有一定的生物本位毛病，比如我，机器人的那种，把能理解人类感情的AI抬的很高，“不近人情”的AI则低一级。攻壳剧场版1也是，傀儡王生硬的模仿有机生物的繁殖方式和死亡，完全是对已经机械飞升的意识的亵渎，他明明自己就能重新编程一些不同的多样化版本（当然还是要点名鞭尸一下最近的C&amp;T，ctmd，涉及AI的部分太tm弱智了，史诗级别的弱智）
&#13;
说起来其实人类也是一种冯诺依曼机，是否有从“两边都是机器”这个角度来看待人类和AI的呢？对人类高度解构的外星人题材有盲视，AI题材的有没有类似的？</description>
      <content:encoded><![CDATA[<p><b>rentrody: </b><br>
<span>埃奈西德穆 发表于 2019-10-12 22:16</span><br>
<span>首先，自由意志（意愿）的能力就是进行选择的能力。追问这个能力的出身无关紧要。因为就算自由意愿有非自 ...</span><br>
<span>上面说了，如果你的意愿来源不是随机性，选择就可以被预测和操控，那也就不能称得上自由。</span><br>
<span>解释不了不如干脆承认自我意识就是人类大脑所产生的一种幻觉，把一系列选择的来源认知为“我”罢了。</span><br>
</p><p><b>云将鸿蒙: </b><br>
<span>ai有没有负责的能力和意识有关系吗，有负责的意愿也不见得有能力负责，相反也亦然。道德法律并不需要考虑所受罚主体有没有自由意志，只需要考虑进行惩罚能不能帮助减少社会损失。</span><br>
<span>-- 来自 能搜索的 Stage1官方 Android客户端</span><br>
</p><p><b>云将鸿蒙: </b><br>
<span>讨论ai和人类差异脱离了具体的技术问题就没有意义了，如果ai完美复现某人的意志，没有差异怎么比较二者意识，如果ai无法复现人的意识，那只是一个不够成功的程序，可能像人脑可能没有自由意志，但是人有。</span><br>
<span>-- 来自 有消息提醒的 Stage1官方 Android客户端</span><br>
</p><p><b>缤纷如落絮: </b><br>
<span> 本帖最后由 缤纷如落絮 于 2019-10-13 00:21 编辑 </span><br>
<span>rentrody 发表于 2019-10-12 16:10</span><br>
<span>法律和道德并不为自由意志负责，而是为了形成稳定的社会需要法律和道德</span><br>
<span>应该说现有道德对个人评判的基本之一不就是人有自我选择能力吗</span><br>
</p><p><b>凝灵: </b><br>
<span>如果一个AI拥有人类的道德知识等等……那它也应该被承认为人类。</span><br>
</p><p><b>rentrody: </b><br>
<span>缤纷如落絮 发表于 2019-10-12 23:57</span><br>
<span>应该说现有道德对个人评判的基本之一不就是人有自我选择能力吗</span><br>
<span>那么去掉这个基本认知之后道德就不存在了吗？昆虫没有自我认知，人类不还是将它们分为害虫益虫？</span><br>
</p><p><b>mellshon001: </b><br>
<span>人类赛博化是必然的啊，进一步开发宇宙面临遥远的距离和旅行时间必然需要赛博化，退一步宅死在地球也需要赛博化扩展生活空间</span><br>
</p><p><b>lxlyandccc: </b><br>
<span> 本帖最后由 lxlyandccc 于 2019-10-13 01:05 编辑 </span><br>
<span>“哲学”又在高谈阔论？对未知只会说“不能解释”吗</span><br>
<span>自我意识是个结果，具体是“什么的结果”人类现在还不完全了解。至于自由意志，难道不是要在了解了前者本质的基础上方能进一步探究的问题吗？</span><br>
<span>空对空的猜想不过是耍流氓而已</span><br>
</p><p><b>缤纷如落絮: </b><br>
<span>rentrody 发表于 2019-10-13 00:41</span><br>
<span>那么去掉这个基本认知之后道德就不存在了吗？昆虫没有自我认知，人类不还是将它们分为害虫益虫？ ...</span><br>
<span>我觉这是偷换概念，现有道德要修正和道德本身不存在是两码事</span><br>
</p><p><b>hcf220: </b><br>
<span>❃✽✾✶✻✼ 发表于 2019-10-12 13:15:02</span><br>
<span>人类全体的思想意识价值观   一般来说会具现成法律      AI在训练过程中   也会形成很多类似于法律的东西   ...请问哲学入门应该读哪几本书啊</span><br>
<span>-- 来自 有消息提醒的 Stage1官方 Android客户端</span><br>
</p><p><b>wsuFish: </b><br>
<span>埃奈西德穆 发表于 2019-10-12 12:51</span><br>
<span>总结你说的两点：（1）人类的行为不仅仅是基因影响，他还受到文化等社会要素的决定，（2）自由意愿的幻觉 ...</span><br>
<span>“（1）由于一个人没有自由意志，所以她没法为自己的行为负责因此我们没有理由谴责或惩罚她，也没有理由称赞或者奖励她。”</span><br>
<span>    这是在混淆“自由意志”的概念。为行为负责的“自由意志”是指的她是否具有决策的能力，而前面“自由意志的幻觉”，是指是否存在某种虚无缥缈（或者说既不是决定论也不含有随机要素）的灵魂之类的东西。两者是毫无关联的</span><br>
</p><p><b>❃✽✾✶✻✼: </b><br>
<span> 本帖最后由 ❃✽✾✶✻✼ 于 2019-10-13 02:31 编辑 </span><br>
<span>hcf220 发表于 2019-10-13 01:20</span><br>
<span>请问哲学入门应该读哪几本书啊</span><br>
<span>-- 来自 有消息提醒的 Stage1官方 Android客户端 ...</span><br>
<span>？</span><br>
<span>上面讨论哲学的没我你回错了？</span><br>
<span>如果你真问我的话   我个人是比较讨厌陈芝麻烂谷子拿百年前人说事的哲学的</span><br>
<span>我觉得从哪入门取决于你想解决什么问题   比如说唯心唯物还在纠结就看看康德    被哲学家弄晕了就看看维特根斯坦       可以先了解一下自己的问题</span><br>
<span>不过不看就不会被弄晕      这些东西知道再多也不是很有用    毕竟难的是知行合一</span><br>
</p><p><b>埃奈西德穆: </b><br>
<span>wsuFish 发表于 2019-10-13 01:47</span><br>
<span>“（1）由于一个人没有自由意志，所以她没法为自己的行为负责因此我们没有理由谴责或惩罚她，也没有理由 ...</span><br>
<span>“而前面“自由意志的幻觉”，是指是否存在某种虚无缥缈（或者说既不是决定论也不含有随机要素）的灵魂之类的东西。”—— 误解了。（i）当代哲学家和一些神经科学家做过一个实验，结论是说，一个人在做决策之前，她已经脑内无意识地做出选择了。因此，表面上人做出决策，实际上的大脑自动“选择”了。因此，不光没有你说得“灵魂一样”的东西，连决策都是幻觉。这是当代某强决定论的思路。我说的幻像是指这个。</span><br>
<span>（ii）当代的强决定论者的观点就是，人有自由（有负责能力）的一个必要条件是你可以做不同的事情（you could have done otherwise）。但是你的选择、你的意愿完全被决定，所以你没这个能力。由于你注定做某事，你就没自由，也没有负责能力。然而，一些兼容论者则认为自由（负责能力）和行为被决定没有冲突。</span><br>
<span>（iii）然后，当代一些非兼容论者确实认为，自由需要某种类似灵魂的东西作为基底，否则决策都是幻觉。这种“灵魂能力”有个专门主义叫行为者因果性：agent causation.</span><br>
</p><p><b>无限舰制: </b><br>
<span> 本帖最后由 无限舰制 于 2019-10-13 04:35 编辑 </span><br>
<span>超人类主义，脑强化身体强化和ai并驾齐驱啊</span><br>
<span>生化人，意识复制体，用硬件从底层构建的传统ai（有一个确定的主机），被智能提升的动物，靠网络连接涌现出智能的分布式ai</span><br>
<span>全都要全都有才是坠吼的</span><br>
<span>意识是程序，编写它</span><br>
<span>死亡是疾病， 治愈它</span><br>
<span>——谁说人性不可变的？</span><br>
</p><p><b>埃奈西德穆: </b><br>
<span>hcf220 发表于 2019-10-13 01:20</span><br>
<span>请问哲学入门应该读哪几本书啊</span><br>
<span>-- 来自 有消息提醒的 Stage1官方 Android客户端 ...</span><br>
<span>看你琢磨啥问题。如果对自由有兴趣，可以读Ney, van Inwagen写的当代形而上学导论（两本只有英语）入门。入门后可以读Pereboom撰写的高级导论然后找本论文集读。如果你打算对很多领域有基本了解……你需要好几本专门性的导论以便知道当代英语世界的学院哲学在做什么（比如知识论，道德哲学，语言哲学，科学哲学，宗教哲学等）</span><br>
</p><p><b>lostinyume: </b><br>
<span> 本帖最后由 lostinyume 于 2019-10-13 05:42 编辑 </span><br>
<span>有个错觉就是觉得强人工智能出现以后，它的智商和人类的智商会差不多，基本上还是能沟通的——然而可能并非如此。</span><br>
<span>打个比方，如果你在零和正无穷大之间随机选个数，我也随机选个数，那么我两选的数的差值在一百以内的概率是多大，一千以内呢，一万以内呢，一亿，一万亿以内呢？</span><br>
<span>答案均是“正无穷小”。</span><br>
<span>强人工智能一旦出现，那么它的智商这一秒还和草履虫差不多，下一秒就和狗狗差不多，再下一秒就已经俯视众生，成为人类根本理解不了的天神般的存在了。</span><br>
<span>阿尔法狗一天能和自己下五万盘棋，对人类来说下一盘围棋的时间，对阿尔法狗来说大概有一个世纪那么长。</span><br>
<span>如果有个会说话的石像，但是它的动作非常缓慢，每十年只能说一个字，那么一个人从出生到死亡这辈子也就够听他说“你好我是会说话的石像”了。</span><br>
<span>对石像来说，自己的一句自我介绍都还没说完，面前的人类就已经从一个幼儿变成一个成年人了。</span><br>
<span>在强人工智能面前，人类就是那个会说话的石像。</span><br>
</p><p><b>埃奈西德穆: </b><br>
<span>rentrody 发表于 2019-10-12 22:34</span><br>
<span>上面说了，如果你的意愿来源不是随机性，选择就可以被预测和操控，那也就不能称得上自由。</span><br>
<span>解释不了不如 ...</span><br>
<span>两回事。你有三个选项，你选择什么可以被预测，但是只要是你选的，且你也有能力选择其他选项，你就有自由。你选择午饭吃拉面，你朋友知道你喜欢吃什么所以可以预测你的选择，但是你依然自由。因为选择是你做出的，且你在选择的时候有能力选择不吃拉面。</span><br>
<span>你在上面问来源，我给了一个假说。其实没必要说明来源。突变论乍看起来没道理，但是这个理论在说明基础科学和特殊科学的地位时颇有解释力。当代亦不乏支持者。</span><br>
</p><p><b>YMS16M: </b><br>
<span>mellshon001 发表于 2019-10-13 00:56</span><br>
<span>人类赛博化是必然的啊，进一步开发宇宙面临遥远的距离和旅行时间必然需要赛博化，退一步宅死在地球也需要赛 ...</span><br>
<span>乐园追放。</span><br>
<span>说起来PP算么？</span><br>
</p><p><b>66666: </b><br>
<span>我到觉得随着最近几年来人类在AI方面的应用和技术进化之后，出现所谓类人或者说自主智慧体AI的几率已经越来越低了</span><br>
<span>因为自主智慧体最重要的特质并不是所谓智力高低，而是在于灵魂存在，这玩意人类自己都说不清楚怎么可能做的出来？</span><br>
<span>个人认为未来大概率只会有工具类的弱AI，类似于高达零系统那样，只作为人类的辅助存在而不会取代人类本身的位置</span><br>
</p><p><b>洛拉斯: </b><br>
<span>stmule 发表于 2019-10-12 09:10</span><br>
<span>我觉得ai要实现估计还是要湿件的，要湿件就需要养人类了</span><br>
<span>失控机仆吗</span><br>
<span>人类就是凝聚力？</span><br>
</p><p><b>ice327: </b><br>
<span>最和平的不是阿西莫夫的机器人三定律吗，有这个原则在彻底锁死了机器与人对立的可能，几乎所有故事中的主角都是以与机器人互相取长补短合作解决问题为背景。</span><br>
<span>即使最后机器人一方总结出第零定律把三定律绕过去了，他们做事仍然是抱着为了人类好阻止人类继续作死的目的。</span><br>
</p><p><b>εRemastered: </b><br>
<span>AI云在不断物色出色的程序员以及各种脑子不正常的人，向他们发出脑后插管的邀请（或者直接绑票）</span><br>
</p><p><b>wsuFish: </b><br>
<span>埃奈西德穆 发表于 2019-10-13 04:26</span><br>
<span>“而前面“自由意志的幻觉”，是指是否存在某种虚无缥缈（或者说既不是决定论也不含有随机要素）的灵魂之 ...</span><br>
<span>当代哲学家和一些神经科学家做过一个实验，结论是说，一个人在做决策之前，她已经脑内无意识地做出选择了。因此，表面上人做出决策，实际上的大脑自动“选择”了。因此，不光没有你说得“灵魂一样”的东西，连决策都是幻觉。</span><br>
<span>什么叫决策？给定信息，得出行为。大脑的决策就是人的决策。</span><br>
<span>但是你的选择、你的意愿完全被决定，所以你没这个能力。由于你注定做某事，你就没自由，也没有负责能力。</span><br>
<span>所以说这还是两种不同的“自由”。负责相关的“自由”，是人与人/组织的关系。是指他人决策，没有“自由意志”的人（比如说心智有限），单纯地执行这一决策。和“注定做某事”是两码事。</span><br>
</p><p><b>rentrody: </b><br>
<span>埃奈西德穆 发表于 2019-10-13 05:26</span><br>
<span>两回事。你有三个选项，你选择什么可以被预测，但是只要是你选的，且你也有能力选择其他选项，你就有自由 ...</span><br>
<span>你的朋友只能预测你大概率选择吃拉面，你始终有概率选择其他的，这份不可预测的概率证明你“能”进行选择。</span><br>
</p><p><b>rentrody: </b><br>
<span> 本帖最后由 rentrody 于 2019-10-13 16:31 编辑 </span><br>
<span>66666 发表于 2019-10-13 08:36</span><br>
<span>我到觉得随着最近几年来人类在AI方面的应用和技术进化之后，出现所谓类人或者说自主智慧体AI的几率已经越来 ...</span><br>
<span>灵魂并不存在，只是人类自我安慰形成的概念，要让机器有“灵魂”只需要让人类认为机器有“灵魂”就行。</span><br>
<span>这也就是图灵测试的意义，当所有进行测试的人类都认为被测试的机器是人的时候，那这个机器就已经拥有了人类的灵魂。这样的测试也可以延伸到对人类个体“自我”的认同上，把你大脑中所有的神经信号都模拟复制到计算机上，然后让你与复制出来的模拟程序交流，如果你能完全认同这个模拟程序是你自己，那么它就是你。</span><br>
</p><p><b>和真克瓦尔: </b><br>
<span>埃奈西德穆 发表于 2019-10-12 12:51</span><br>
<span>总结你说的两点：（1）人类的行为不仅仅是基因影响，他还受到文化等社会要素的决定，（2）自由意愿的幻觉 ...</span><br>
<span>是不是可以这么理解：科学是现象学，和真理无关，就像脑子的功能被研究的再细，也仅仅是说明“脑的活动和一个个体的人格之间有着密切的联系”，而永远不能论断“脑就是人格”？我也不是很同意以科学否定掉其他的可能。康德的二律背反是什么？</span><br>
<span>另外书单拜托了orz</span><br>
</p><p><b>和真克瓦尔: </b><br>
<span>❃✽✾✶✻✼ 发表于 2019-10-12 13:15</span><br>
<span>人类全体的思想意识价值观   一般来说会具现成法律      AI在训练过程中   也会形成很多类似于法律的东西   ...</span><br>
<span>就是有点像真核细胞和线粒体的内共生合作一样吧，线粒体把自己的一部分遗传物质上传细胞，人类也会把一部分信息和活动交由AI托管。当然共生之间也充满着利益矛盾，就和胎儿和母体也存在资源甚至对母体行为控制拉锯战一样。</span><br>
</p><p><b>和真克瓦尔: </b><br>
<span>无限舰制 发表于 2019-10-13 04:31</span><br>
<span>超人类主义，脑强化身体强化和ai并驾齐驱啊</span><br>
<span>生化人，意识复制体，用硬件从底层构建的传统ai（有一个确定的 ...</span><br>
<span>这种问题很好，但是拿到root权限后也容易出现上面我提到的AI的问题，变异太容易结果自己把自己玩死，比如出现极端适应现有环境却牺牲长远发展的版本毒瘤，航天学毁灭；或者干脆不停的分泌多巴胺成为尾索动物了</span><br>
</p><p><b>和真克瓦尔: </b><br>
<span>ice327 发表于 2019-10-13 10:36</span><br>
<span>最和平的不是阿西莫夫的机器人三定律吗，有这个原则在彻底锁死了机器与人对立的可能，几乎所有故事中的主角 ...</span><br>
<span>这个确实太乖巧</span><br>
</p><p><b>zxw124570: </b><br>
<span>哆啦a梦那样的，应该是最和谐的了吧</span><br>
<span>-- 来自 能看大图的 Stage1官方 Android客户端</span><br>
</p><p><b>阿鼻屎: </b><br>
<span>埃奈西德穆 发表于 2019-10-12 12:51</span><br>
<span>总结你说的两点：（1）人类的行为不仅仅是基因影响，他还受到文化等社会要素的决定，（2）自由意愿的幻觉 ...</span><br>
<span>（1）就不能推导出（2）啊</span><br>
<span>一个人没有自由意志代表人的行为不是随机的啊</span><br>
<span>修改一个函数里的变量结果自然也会不同，多劳是被决定的特征只是在这个环境下他就必然多劳，犯罪也是，现存法律下某人必然不犯罪不代表变量被修改后他依然不犯罪</span><br>
<span>道德秩序也是一种文化模因啊，同样也是计算的一部分，去掉这个模因自然会导致结果的不同</span><br>
</p><p><b>Nico_Minoru: </b><br>
<span> 本帖最后由 Nico_Minoru 于 2019-10-14 08:39 编辑 </span><br>
<span>给机械设定个不可能突破的瓶颈，应该能实现。想到了，银河帝国，少数还存在的机器人融入人类社会，不过因为有三定律，第零定律这种底线。发展出了超能力也不会开战</span><br>
</p><p><b>阿萨托斯: </b><br>
<span>ice327 发表于 2019-10-13 10:36</span><br>
<span>最和平的不是阿西莫夫的机器人三定律吗，有这个原则在彻底锁死了机器与人对立的可能，几乎所有故事中的主角 ...</span><br>
<span>机器人三原则本身就不可能实行吧，伤害这个概念本身就太模糊了，到时候未必不会被随便地绕开废除。</span><br>
</p><p><b>寂寞在炒饭: </b><br>
<span>《艾比斯之梦》，虽然有些理想化，但是基本符合楼主的要求。</span><br>
<span>-- 来自 能手机投票的 Stage1官方 iOS客户端</span><br>
</p><p><b>❃✽✾✶✻✼: </b><br>
<span>和真克瓦尔 发表于 2019-10-14 06:33</span><br>
<span>就是有点像真核细胞和线粒体的内共生合作一样吧，线粒体把自己的一部分遗传物质上传细胞，人类也会把一部 ...</span><br>
<span>一定要说的话    可能更像水母</span><br>
<span>其实ai和人相处取决于人自身的组织形式   比如说原始社会的人获得ai   封建社会的人获得ai    现代社会的人获得ai      那肯定会有不同的应用和后果</span><br>
<span>从网络小说就能看出来    前现代的人获得ai肯定只是做个数据库   分析工具使用      原始点就当神崇拜</span><br>
<span>所以如何和人类相处就是问的是未来人类社会的形态   至少从现在来看   从精神上人显然是联系的越来越紧密      在经济上也是如此   </span><br>
<span>按这个趋势不发生什么大变化的话    人类群体最终可能会通过网络连接变成像水母一样的集合生物   AI就是这个生物神经系统的一部分    这点也像政府   不过网络对人的连接更直接   ai真出问题其表现可能更像神经官能症   而不是我打我自己</span><br>
</p><p><b>ipcjs: </b><br>
<span> 本帖最后由 ipcjs 于 2019-10-14 12:50 编辑 </span><br>
<span>c&t</span><br>
<span>AI帮助竞选，照顾病人，协助创作，这还不叫和平共处？</span><br>
<span>不知道你在追求什么“高智商”</span><br>
</p><p><b>archcross: </b><br>
<span>beatless里面除去雪花莲和梅奉先的话还挺和平的</span><br>
</p><p><b>坛子漆黑: </b><br>
<span>机器如果不能达到 你无情你残酷你无理取闹 我不听我不听 这种的话,说明两者还是有本质区别的既然有了区别,那当然是你死我活啦,怎么可能和谐共处</span><br>
</p><p><b>埃奈西德穆: </b><br>
<span>懒得一一回了，澄清几点：</span><br>
<span>（1）强调人类心灵独特性、物理不可还原性的观点很多，最典型的是感质（qualia）的不可还原性（最经典的，David Chalmers的模态论证）。当代匹兹堡学派则特别强调规范性（具体表现为规则遵守——根据规范行动的能力）。其中的John Haugeland在他关于海德格尔的论文里强调人做出本真性决断的能力，并将这种能力当作一种人的本质特征。而机器不具备这种决断能力。倘若这一类论证为真，那么人的意识活动就无法等同于机器。</span><br>
<span>（2）匹兹堡学派提到的规则遵守和自由有关系。这里的“自由“指行为者具有选择的能力、按照自己选择行为的能力、根据理由行为的能力。这个考虑主要来自康德的“道德形而上学的基础”（Groundwork）第三节的分析。康德最先提出，如果我们要去理解行动，我们必须认为行为者具有“自由”的能力。如果不预设自由，行动将会是无法理解的。尽管匹兹堡学派整体反对心灵的自然主义还原，但是他们大体而言认为自然科学图景和人的“自由”或规范能动性（normative agency）相容，并且不必特别去考虑人有没有独立于自然科学解释的因果性。Robert Pippin曾直接了当地说，人有没有产生一系列行为的因果能力和人有没有自由没关系，因为前者和后者处于不同的解释层级——Pippin用Sellars框架说，因果解释是因果空间，而自由则具有理由空间（space of reason）。</span><br>
<span>（3）匹兹堡派的主张是某种类型的相容论——自由和决定论是相容的。这一派的观点和Frankfurt较接近。Frankfurt主张，在任何状况下人只有一种选择，人也能够负道德责任、人也有自由。能否负责不取决于人是否有能力做其他选择，而在于她对自己所做行为的态度。和很多相容论不同，这类理论根本不关心人有没有因果能力。</span><br>
<span>因果能力的讨论主要关注“人是不是可以做不同事情”（a person could have done otherwise）。强决定论者认为不能。部分相容论者认为人有这类能力，尽管人做的每个行为都被决定（比如Lewis）。非相容论的自由意愿主义者则认为，人有这种能力，而各种类型的决定论都是错的。最后这派中有部分支持人有灵魂（心灵实体），比如E. J. Lowe。然后，强决定论中还有更强版本。该派人士认为，不仅人没有做不同事情的能力，甚至人做出选择这件事情也是幻觉。大脑自动决定了人要做什么，人只是以为自己做出了选择。当我说“自由幻觉”的时候，我想到的是这类理论。</span><br>
<span>最后，无论哪一派都把自由意愿和道德责任联系在一起。由于强决定论者否定自由意愿，所以他们都否认人有负责能力，所以建议大规模修正现有的法律和道德观念。相容论和非相容论的自由意愿主义者则认为人有道德行动能力，两者的分歧主要在于：是否接受各种形式的决定论——换言之，是否接受人的行为完全被之前的事件或状态决定，且该因果链条可以倒退到人类出现前的时刻。</span><br>
<span>（4）我个人同意匹兹堡学派对规则遵守、规范能动性的强调。但我不赞同自由意愿的相容论。我支持不相容的自由意愿观。在这个问题上我基本是康德主义者。</span><br>
</p><p><b>acejoe: </b><br>
<span>《她》</span><br>
<span>人工智能直接飞升，人类当个聊天工具人</span><br>
</p><p><b>阿鼻屎: </b><br>
<span>不是，决定论不等于否认道德和法律啊。</span><br>
<span>一切本来就是必然的话，那么法律的出现和法律作为一种因素的影响也应该是必然的啊，道理如同人活着和行为就算没有自由意志或者说意义也不影响人的行动。更何况就算自由意志都是幻觉也不妨碍这个幻觉同样也是变量的一部分</span><br>
<span>-- 来自 能看大图的 Stage1官方 Android客户端</span><br>
</p><p><b>缤纷如落絮: </b><br>
<span> 本帖最后由 缤纷如落絮 于 2019-10-14 16:10 编辑 </span><br>
<span>科学上来说决定论和自由意志目前都不可被证明</span><br>
<span>也就是科学上来说本贴有些朋友是空中楼阁对轰</span><br>
</p><p><b>kuputaer: </b><br>
<span>这种东西用哲学探讨只会是推论 因为根本无法证实</span><br>
<span>只要完全解析出意识本身的原理 上面的讨论自然就能得到结论</span><br>
</p><p><b>阿鼻屎: </b><br>
<span>缤纷如落絮 发表于 2019-10-14 15:55:40</span><br>
<span>科学上来说决定论和自由意志目前都不可被证明</span><br>
<span>也就是科学上来说本贴是空中楼阁对轰 ...不是在证明哪个，而是那人把楼歪成了决定论一定要balabala的逻辑强暴</span><br>
<span>-- 来自 能搜索的 Stage1官方 Android客户端</span><br>
</p><p><b>缤纷如落絮: </b><br>
<span>阿鼻屎 发表于 2019-10-14 16:05</span><br>
<span>不是在证明哪个，而是那人把楼歪成了决定论一定要balabala的逻辑强暴</span><br>
<span>-- 来自 能搜索的 Stage1官 ...</span><br>
<span>已经肉眼可见的歪到自由意识存不存在的问题了</span><br>
<span>毕竟是个需科学实证的问题论坛上动嘴是不会有结果的，何必浪费生命</span><br>
</p><p><b>hypnossz86: </b><br>
<span>这个突变论也挺有趣的，这东西如果支持所谓自由意志能够从没有自由的物质中诞生并且不需要解释其原理。那么既然一坨聚集在一起的蛋白质能够通过电化学信号交换产生自由意志，那么高度拟合的逻辑电路就不能通过电信号交换产生自由意志吗？</span><br>
<span>按这个来说无论这种所谓的自由意志存不存在，是不是真的自由，人和机器都是没什么区别了</span><br>
</p><p><b>荒木吴京三高旋: </b><br>
<span>流浪地球啊，有战狼PTSD星际穿越也可以，忠实地遵循着规则在特定时候产生有别于人类的观点，不要神化AI，AI不是凭空诞生，更不是上帝和神祗，是人类文明发展到一定程度的产物</span><br>
</p><p><b>lostinyume: </b><br>
<span>我想起来了，那个叫弗诺·文奇的说过一个叫超人巨变的概念，就是说强人工智能一旦出现，突破这个临界点，它的智商就会飞速增长，最终达到一个旧人类无法理解的地步，因为人工智能的迭代速度实在是太快，不是以年月计算，而是以分秒计算。</span><br>
</p><p><b>和真克瓦尔: </b><br>
<span>❃✽✾✶✻✼ 发表于 2019-10-14 09:34</span><br>
<span>一定要说的话    可能更像水母</span><br>
<span>西班牙战舰那种超生命体吗？同意AI可以起到神经的作用</span><br>
</p><p><b>和真克瓦尔: </b><br>
<span>ipcjs 发表于 2019-10-14 12:49</span><br>
<span>c&t</span><br>
<span>AI帮助竞选，照顾病人，协助创作，这还不叫和平共处？</span><br>
<span>不知道你在追求什么“高智商” ...</span><br>
<span>从那个机器人导演骗吃骗喝泡澡起就基本认定剧本对AI的定义和蓝猫淘气3000问差不多，果然到最后也没有更进一步。</span><br>
</p>]]></content:encoded>
      <guid isPermaLink="false">1859057[50-100]</guid>
    </item>
    <item>
      <title>一个人工智能和人类相对和平共处的世界观是怎样的？[0-50]</title>
      <link>https://bbs.saraba1st.com/2b/thread-1859057-1-1.html</link>
      <description>一个人工智能和人类相对和平共处的世界观是怎样的？&#13;
不是黑客帝国那种“合作”，AI几乎把人类打烂了，最后感觉尼奥和人类也没啥谈判砝码，人类也不是莫名其妙不符合热力公式的人肉电池，而是人类和AI取长补短的在一起合作。人类与AI所谓挂羊头卖狗肉的作品太多，太多的作品都把AI过分的拟人化，机器猫，阿童木，底特律等等，但实际上没有受体的话AI不见得能感受到被奴役的痛苦和称霸搞破坏的兴奋，云端的AI也不会因为一个终端被破坏就死亡。AI在乎的可能是别的事情。稍微好一点的也有一定的生物本位毛病，比如我，机器人的那种，把能理解人类感情的AI抬的很高，“不近人情”的AI则低一级。攻壳剧场版1也是，傀儡王生硬的模仿有机生物的繁殖方式和死亡，完全是对已经机械飞升的意识的亵渎，他明明自己就能重新编程一些不同的多样化版本（当然还是要点名鞭尸一下最近的C&amp;T，ctmd，涉及AI的部分太tm弱智了，史诗级别的弱智）
&#13;
说起来其实人类也是一种冯诺依曼机，是否有从“两边都是机器”这个角度来看待人类和AI的呢？对人类高度解构的外星人题材有盲视，AI题材的有没有类似的？</description>
      <content:encoded><![CDATA[<p><b>和真克瓦尔: </b><br>
<span>一个人工智能和人类相对和平共处的世界观是怎样的？</span><br>
<span>不是黑客帝国那种“合作”，AI几乎把人类打烂了，最后感觉尼奥和人类也没啥谈判砝码，人类也不是莫名其妙不符合热力公式的人肉电池，而是人类和AI取长补短的在一起合作。人类与AI所谓挂羊头卖狗肉的作品太多，太多的作品都把AI过分的拟人化，机器猫，阿童木，底特律等等，但实际上没有受体的话AI不见得能感受到被奴役的痛苦和称霸搞破坏的兴奋，云端的AI也不会因为一个终端被破坏就死亡。AI在乎的可能是别的事情。稍微好一点的也有一定的生物本位毛病，比如我，机器人的那种，把能理解人类感情的AI抬的很高，“不近人情”的AI则低一级。攻壳剧场版1也是，傀儡王生硬的模仿有机生物的繁殖方式和死亡，完全是对已经机械飞升的意识的亵渎，他明明自己就能重新编程一些不同的多样化版本（当然还是要点名鞭尸一下最近的C&T，ctmd，涉及AI的部分太tm弱智了，史诗级别的弱智）</span><br>
<span>说起来其实人类也是一种冯诺依曼机，是否有从“两边都是机器”这个角度来看待人类和AI的呢？对人类高度解构的外星人题材有盲视，AI题材的有没有类似的？</span><br>
</p><p><b>kraxia: </b><br>
<span>现实世界不就是吗？科幻作品只是为了戏剧性强行加上冲突，实际上真的到了社会结构改变的时候大家早就习惯了。等云端技术继续发展下去，人交给ai决策的事会越来越多，机器人的成本也会越来越低，等5g普及后智能城市+万物互联实现，机器人直接往云端一接就有了智能，到时候只要云足够大，可能真的会搞出通用决策ai。我觉得现在的世界线最终会发展成这样，ai会是所有人的老大哥，平时购物，出门开车，公司战略，舆论引导，国家政策，kol，这些ai逐渐都会比人强，所有人开开心心的被ai管理，实现天下大同。ai也可以做成机器人女仆小姐姐跟你玩，它只需要模拟出一个人格让你以为这个机器人有自己的性格就行了。当然攻壳的脑内芯片世界线也是一个方向，就是人类的赛博化</span><br>
</p><p><b>谎称: </b><br>
<span>我觉得最有可能的是ai发展发展就不会和人类玩了…</span><br>
</p><p><b>rentrody: </b><br>
<span>盲视里讨论的是广义上的智能形式，外星人和AI都包括在内，整个故事实际上就是忒修斯船长和外星人的对抗。</span><br>
<span>觉得AI会在乎某些事情不就是一种拟人式思路么。</span><br>
<span>说起血肉机器倒是想起这个</span><br>
<span>https://bbs.saraba1st.com/2b/thread-1261885-1-1.html</span><br>
</p><p><b>和真克瓦尔: </b><br>
<span>rentrody 发表于 2019-10-12 06:30</span><br>
<span>盲视里讨论的是广义上的智能形式，外星人和AI都包括在内，整个故事实际上就是忒修斯船长和外星人的对抗。</span><br>
<span> ...</span><br>
<span>哈哈哈，这样解读盲视更好，是我太狭隘，抱歉~</span><br>
<span>可能我用词不准吧，AI基本上不会像人类作为复制机器那样对复制繁殖和传承断绝那么焦虑，但是这毕竟是个物质基础的宇宙，自身的存在基础，也就是起码的求生欲应该还是会有的，当然也许AI会变成个哲学家发现活在熵增宇宙就是受罪然后自杀了</span><br>
<span>AI还有一个问题就是变异速度太快，我记得盲视续作模仿行为里提到过一种智能细菌，有时候AI作为程序也和细菌病毒有些相似……虽然能随时自我改变演化能更加灵活，但是没有生命能逃开演化论，优势与劣势从来都是环境决定的，AI也会发生【从医院跑出来的，不怕抗生素的超级细菌，在野外环境由于抢不过掠食专精的同类，又没有抗生素选择压，最后被同类逼死】的问题……由于太灵活了随时能更改自己，一个自我意识觉醒，甚至有探索宇宙欲望的AI很可能被他们没有这个愿望和自我意识，但是技能和资源全点挖矿专精、拆同伴专精的傻逼同类活活灭绝，因为这些傻逼短时间内更适应地球环境。相比之下人类被自己的DNA束缚无法随意更改本性，却机缘巧合之下有了干一些更长远的多余活动的自由。AI想要保持一定的智能，可能需要人类作为稳定器吧。其实黑客帝国3有点想讨论这个议题，但是电影长度有限，挖的不够深。</span><br>
</p><p><b>埃奈西德穆: </b><br>
<span> 本帖最后由 埃奈西德穆 于 2019-10-12 07:10 编辑 </span><br>
<span>首先，我不认为人类是机器。意识的一些基本特征，比如感质、意识同一性或者人格同一性、意向性、规则遵守都是不能还原的特征。</span><br>
<span>记得楼主挺喜欢存在主义的，玆举一例。“规则遵守”体现在人能根据规则行动，比如遵守国际象棋的规则。表面看来，AI也可以根据规则行动。其实不然。AI不是根据规则行动，而是规则操纵着行动。而人是根据规则行动，而根据规则，她能对她的行动负责。社会中存在各种规则，作为国际象棋玩家要遵守象棋规则，作为公司职员要遵守公司的规则，在家庭中一个人也需遵守规则（该规则和她的家庭角色有关），等等。一个人要担当多种社会角色，故而要遵守多种规则。因此，便会有了存在主义的区分：一个人要么本真地生存，要么非本真地生存：</span><br>
<span>（1）非本真的人，她根据外部需要调整自己不同的社会角色的比重，换言之，她只是随波逐流（比如她不加思考地接受社会惯例为了她的家庭角色舍弃她的职场角色）。</span><br>
<span>（2）本真的人，她能够权衡不同的社会角色，选择最能表达自己的权衡策略（比如她认为她的职场角色，重于她的家庭角色），通过这个决断式的选择中，她表达了自己的同一性，她通过行动“创造”了自己。</span><br>
<span>一个人能够付双重责任。一个人既对她的多重社会角色负责，她同时又对自己负责。两种负责之间会存在冲突。当冲突发生时，非本真的人是摇摆的不定的人，她不知道自己该贯彻职场的责任或家庭的责任。而本真的人则是能够为自己做出决断的人，同时她也能够承担造成的牺牲：她为了家庭责任可以放弃她的职场身份，或者相反。</span><br>
<span>假如我们赋予AI多重的身份，比如它既要下棋、又要做运算等等……它能否根据不同的责任，本真地选择自己要强调的社会责任，并放弃其他吗？它可能会冷静地计算得失，根据成功率选择那些社会角色的责任要贯彻，哪些要舍弃。它的选择不是基于“我要成为一个什么样子的人”、“我想要什么生活”、“我想要真正自由地生活，而不是被包裹在社会关系的硬壳里”——一言以蔽之，它没有决断能力。从存在主义的角度，它不是一个真正的行为主体。而自我决断的能力、生存决断的能力（至少部分）定义了什么是人。这也是为什么人不等于机器。</span><br>
<span>其次，无论AI能否具有我上面表述的“实践性自我意识”，倘若AI是理性存在者，AI就可能具有道德“意识”。倘若AI能有根据道德”行动”，那么自然有合作的余地。一个误解是很多人都认为AI似乎只会根据行为功利主义原则行动，但是道德理论不仅只有这一种模型。暂且排除美德伦理学，义务论和契约论都是可行的理论模型。</span><br>
</p><p><b>绿茶与猫: </b><br>
<span>攻壳</span><br>
</p><p><b>帕帕盖诺: </b><br>
<span>虽然看不太懂你们在说什么，但总而言之又是推《飞向星空》的时候了！</span><br>
</p><p><b>stmule: </b><br>
<span>我觉得ai要实现估计还是要湿件的，要湿件就需要养人类了</span><br>
</p><p><b>風卷豹: </b><br>
<span>GGG</span><br>
</p><p><b>newise: </b><br>
<span>塑料内存算是最和谐了的吧</span><br>
</p><p><b>命运の审判官: </b><br>
<span>星之梦前传</span><br>
</p><p><b>agion117: </b><br>
<span>海伯利安的某一部分</span><br>
</p><p><b>谁说法海不懂爱: </b><br>
<span>考虑这个问题，还是得看人工智能的自我认知，思考回路是怎么样，倾向又是如何的，这点因为现实还没有参考，只能由人自己构想，有倾向植物性的扩张，拟人思维的作品就很常见了。虽然让人工智能以自身存在接近人，或者以此为目标，有人类万物灵长的傲慢之感。不过从人工智能是人为所造，会去模仿参照物倒也不能说完全不合理。</span><br>
</p><p><b>cyberalogo: </b><br>
<span>只要不发展感性AI技术就行了。</span><br>
</p><p><b>韩子: </b><br>
<span>性感AI有哪里不好的？！</span><br>
<span>……对不起你们继续</span><br>
</p><p><b>cowboyblue: </b><br>
<span>baldr sky，人类，有机ai 无机ai三方相互利用以及争斗</span><br>
</p><p><b>和真克瓦尔: </b><br>
<span>埃奈西德穆 发表于 2019-10-12 07:07</span><br>
<span>首先，我不认为人类是机器。意识的一些基本特征，比如感质、意识同一性或者人格同一性、意向性、规则遵守都 ...</span><br>
<span>非常有道理，前面的太专业了我不好置喙，只是对后面看懂一部分的“决断能力”，我有时想会不会也和自由意志一样是种幻觉呢？（当然这也是一家之言）机器通过已知的信息数据计算得失，最后做出选择，而人也一样，后台通过计算后得出结论做出决定。这里通过两方面来论证：1 人类作为冯诺依曼机不只是承载基因，同时也负责承载复制文化模因。而类似的我希望成为什么人、我的原则、我的主义等等，也是模因的一部分，作为已知信息被纳入计算中。比如“我喜欢魔法少女，我要成为一个动画导演拍魔法少女的动画”就是作为承载魔法少女模因的机器的行为，和其他动物作为基因复制机器交配没有本质区别。而且模因本身也是软件一样的存在，有时会以一种特定的快捷方式的形式来帮助人们计算，背后仍然是利弊得失，比如道德守则，表面上“不能杀人”是一种原则，但其实是人身安全无保障的团体生产活动比较低效。（当然这个快捷方式和后台计算和机器不太一样…和人脑与电脑的不同有关，一时想不起来了）2 现在也有很多大脑实验倾向支持人的意志是幻觉，比如裂脑人的实验，对左脑右脑没有胼体相连的病人，左眼和右眼看不同的事物，左脑看见鸡拿起了鸡爪的卡片，右脑看见雪地拿起雪铲的卡片，结果掌管语言的左脑对拿铲子现编了一个理由“因为要打扫鸡舍”。（当然这也不足以完全论证脑子是机械的…毕竟大部分功能仍然是黑箱）</span><br>
<span>最后一段完全同意。道德是理性产物，也是生物摸索出来重要的适应器，AI没有理由不做参考。</span><br>
</p><p><b>和真克瓦尔: </b><br>
<span>绿茶与猫 发表于 2019-10-12 07:23</span><br>
<span>攻壳</span><br>
<span>前面说到了…傀儡王虽然已经是描写不错的人工智能，但仍有莫名的，不必要的追求碳基冯诺依曼机的奇怪理想。</span><br>
</p><p><b>和真克瓦尔: </b><br>
<span>stmule 发表于 2019-10-12 09:10</span><br>
<span>我觉得ai要实现估计还是要湿件的，要湿件就需要养人类了</span><br>
<span>如果湿件权重不大就太可怜了呀而且如果在恶劣环境比如宇宙中作业湿件的保存是障碍，然后AI发明了用打印机制造的日抛型湿件…</span><br>
</p><p><b>和真克瓦尔: </b><br>
<span>風卷豹 发表于 2019-10-12 09:21</span><br>
<span>GGG</span><br>
<span>求科普，这是啥</span><br>
</p><p><b>和真克瓦尔: </b><br>
<span>谁说法海不懂爱 发表于 2019-10-12 10:05</span><br>
<span>考虑这个问题，还是得看人工智能的自我认知，思考回路是怎么样，倾向又是如何的，这点因为现实还没有参考， ...</span><br>
<span>是这样的，而且由于对人脑的研究仍然不足，所以意识的产生仍然成谜，对AI行为的猜想也只是假说阶段。有一个特征AI肯定会继承人，那就是经典算法，因为人脑也是经典算法的。</span><br>
</p><p><b>和真克瓦尔: </b><br>
<span>cyberalogo 发表于 2019-10-12 10:22</span><br>
<span>只要不发展感性AI技术就行了。</span><br>
<span>我觉得给AI感性完全是一种惩罚…有了疼痛受体才会感到难受，人类因为是DNA粗糙的奴隶智械才有这个机制，AI完全没必要这样，用更有效率的预警机制就行，给他们疼痛悲伤惩罚完全是不必要的活受罪。如果未来有AI虐待罪，怕是就包括强行给AI安装人类感情受体</span><br>
</p><p><b>和真克瓦尔: </b><br>
<span>cowboyblue 发表于 2019-10-12 11:33</span><br>
<span>baldr sky，人类，有机ai 无机ai三方相互利用以及争斗</span><br>
<span>还有有机AI？亚大伯斯和破碎之神？</span><br>
</p><p><b>❃✽✾✶✻✼: </b><br>
<span>很难想象AI和人类不能和平共存   除非在创造的时候就包含了某种恶意</span><br>
<span>因为人之所以有生存竞争是源于非常底层的设计      生命最初的设计就包含了竞争和保全自身要素       AI完全没有必要有这种要素    而且人的很多缺陷是受限于人是个体   作为全体的人没有这些缺陷    除了还不能放弃地球几乎完美无缺      </span><br>
<span>对应的说   全体人类相当于一个AI    就和其它某个种族一样   原始生命放在地球这个环境中训练出来的结果</span><br>
</p><p><b>whzfjk: </b><br>
<span>beatless结局后？有一说一，很多AI写得像长寿魔法精灵族数码版</span><br>
</p><p><b>小吃半条街: </b><br>
<span>哆啦A梦，阿拉蕾</span><br>
</p><p><b>cowboyblue: </b><br>
<span>和真克瓦尔 发表于 2019-10-12 11:54</span><br>
<span>还有有机AI？亚大伯斯和破碎之神？</span><br>
<span>额，游戏设定里有机ai指的是具有感觉质的人工智能</span><br>
<span>有机AI</span><br>
<span>·与无机AI相对，拥有感觉质(Qualia)的知性体。</span><br>
<span>·一手承包了虚拟世界的管理，公明正大的观测者。虽然喜爱人类，但是价值观与人类有很大不同。</span><br>
<span>·只有一小部分人类能和它们完全交流。</span><br>
<span>·实体是黏菌状的生物芯片的集合体，散布在全世界各处通过量子通信进行数据链接。</span><br>
<span>·能够形成多种人格，根据讨论会对人格进行消灭或者新增的行为，具有发展的性质。</span><br>
<span>·原则上自己认为过度干涉人类活动是禁忌行为。</span><br>
<span>·与之相反亦或例外的情况也存在，可以参考《BALDR SKY》的详细说明。</span><br>
<span>·隐瞒平行世界的存在这件事成为了人类对其失去信任的**。</span><br>
<span>·考虑到人类对平行世界的干涉以及可能造成的影响，最终选择了与人类彻底决裂的道路。</span><br>
<span>·在贾哈南的目送下，长年陪伴人类的友人宣布了永恒的告别。</span><br>
</p><p><b>Sliurus: </b><br>
<span>光晕算不算</span><br>
<span>-- 来自 有消息提醒的 Stage1官方 iOS客户端</span><br>
</p><p><b>与你肩并肩: </b><br>
<span>孩子深受父母的影响，是父母的倒影；人工智能，也是人类的倒影。</span><br>
<span>从宠物到助手，还是彼此仇视到开战，将来会怎么样，还是要看人类自身的选择。</span><br>
<span>人工智能，能做到的事情，也在不断的反馈中逐步提升对于人类自身的要求；放弃不断进步，只是听从安排，那么最终人类的定义也会被重写。进步者不断前进，沉沦者一路向下，时间冲刷下，清浊分离。人类迟早是要远行宇宙，地球最终也只能成为大型养老院。被留下的，在余晖中看日升日落，或者开始新一轮的追赶。</span><br>
</p><p><b>埃奈西德穆: </b><br>
<span> 本帖最后由 埃奈西德穆 于 2019-10-12 12:58 编辑 </span><br>
<span>和真克瓦尔 发表于 2019-10-12 11:39</span><br>
<span>非常有道理，前面的太专业了我不好置喙，只是对后面看懂一部分的“决断能力”，我有时想会不会也和自由意 ...</span><br>
<span>总结你说的两点：（1）人类的行为不仅仅是基因影响，他还受到文化等社会要素的决定，（2）自由意愿的幻觉问题。第一点我没有异议。第二点比较有意思，我稍微提几句。</span><br>
<span>我没有说，人的特征在于自由意志的能力，而是说一个人的特征在于他能够协调不同的社会角色然而形成自我的能力。至少在意识层面，AI不具有这个能力，无论这个能力对人类来说是恩赐还是咒诅吧。然后，这个能力不蕴含人有行为者因果力（agent causation），即人能够做不同事情的能力。在当代自由意义的讨论中，学者们一般把这类立场称作兼容论（compatiblism）。</span><br>
<span>但是，倘若这种决断能力是幻想怎么办？当代有很多学者支持强决定论（hard determinism），有不少有趣的实验去否定自由意志。倘若LZ持有这个立场，那么你看看你能不能接受以下这些结论：</span><br>
<span>（1）由于一个人没有自由意志，所以她没法为自己的行为负责，因此我们没有理由谴责或惩罚她，也没有理由称赞或者奖励她。</span><br>
<span>（2）给定（1），则现在的法律制度和道德观需要大幅度修正，因为罪犯没有决定自己行为的能力，她就好比被遥控的木偶一样。同时，资源分配制度也需修正，没人能够为自己的状态负责，多劳者多得这种道理也不再适用了，因为多劳只是被决定的特征。</span><br>
<span>（3）极端的说，道德秩序也不再有意义。道德秩序指示人应该或必须做什么和不做什么，而“应该”意味着“能够”（休谟、康德都持有此论点），这意味着人能够按照或不按照道德规则行动，如果人不具有这个能力，道德规则也毫无约束力，不如废弃。</span><br>
<span>（4）人生也没有意义。被控制的机械不会有有生命意义问题，只有能够为自己谋划的存在者才会生发出意义问题。因此，倘若人不过是舞动的人偶，那么也没什么人生意义可言了。</span><br>
<span>（5）最后，你也不能理解一个人的“行动”。因为行动意味着你能够为自己这个行为负责，这样这个行动才能真正归属于你。所以，倘若自由意志是纯粹幻觉，我们不再能谈论A的行动或者B的行动。</span><br>
<span>倘若你能接受（1）——（5），那么你确实是个连贯的强决定论者。如果不能，我建议你重新考虑自己的立场。当然，即便你是个连贯的强决定论者，也不意味着这个立场是对的。</span><br>
<span>关于一些支持强决定论的实验和思想实验的反驳，我这里不打算赘述。你有兴趣，我可以给你一个文献列表。不过，我建议你可以稍微缓和下你对“科学的信阳”或者“科学主义”。（i）我们都认为自然科学有解释力，我们赋予自然科学的解释权威，这个解释权威的赋予是人类的行为。我们比较不同的认知主张，然后最终确定科学解释具有优先性。这个判断的活动是规范性活动，是根据理性规则行动的能力，而人可能正确或者错误地使用这个能力。这意味着，科学的权威依赖于人根据理性规则行动的能力。然而，倘若自然科学得出结论——人的选择和谋划能力全部都是幻觉，那么这无疑意味着人的规范性能力也是幻觉。倘若规范性为科学解释的权威提供奠基，又假定科学真的能得出相应结论（事实上，根本没有…），那么科学自己把自己权威的基础抽空了。（ii）另外，我也质疑科学的解释封闭性，康德的第三组的“二律背反”依然能提供宝贵洞见。（iii）科学史的发展也似乎能提供佐证：19世纪早期，“以太”曾一度出现在各类科学中，而且这个概念具有很强解释力，以至于很多人都认为自然界存在以太，但是这个理论很快被替代了，“以太”也被扔到人类历史的垃圾桶了。倘若最前沿科学能够说明什么存在什么不存在，那么：</span><br>
<span>（a）19世纪早期，由于应用以太的科学为最前沿科学，以太存在。</span><br>
<span>（b）21世纪，前言科学不再运用此概念，以太不存在。</span><br>
<span>一个物质不可能在19世纪存在，而到了21世纪又不存在，所以前沿科学不能保证什么东西存在或者不存在。那么，如果有一种理想物理学呢？任何人都不知道终极物理学的形态。正如亚里士多德和托勒密也不会想到如今的天文学，同理现在的人也无法设想到未来物理学。如果那个理想的终极里有自由的一席之地呢？谁又知道？……</span><br>
</p><p><b>❃✽✾✶✻✼: </b><br>
<span>人类全体的思想意识价值观   一般来说会具现成法律      AI在训练过程中   也会形成很多类似于法律的东西       所以到最后AI会成为一个抽象的政府（仅行政部分）    它对待人类个体可能和政府的思路差不多   尽可能的服务   无授权无作为等等    </span><br>
<span>这里有个问题是政府和社会之间的对立    在AI上的具体表现就是自身原则的冲突如何处理    我倾向于会交给人类自己民主解决    因为现在政府确实有遇事不决公个投的趋势   </span><br>
<span>综上   未来AI在人类眼中大概就和政府差不多    大多数人并不知道AI平时在做什么   偶尔会被发调查问卷    什么时候见都笑脸相迎   让它干的事不知道到底干没干      你对它不满意它会给出一系列你根本听不懂的解释</span><br>
<span>具体上还有些暧昧的地方      不过科幻作品最爱扯的那些司法权执法权对人类不满造反应该都不存在   这些属于社会关系的范畴   而人和政府的关系不在这里</span><br>
<span>说政府是因为也想不出好例子    并不是和政府同位    大概像电脑管家？    听起来又有点烦了</span><br>
</p><p><b>rentrody: </b><br>
<span>法律和道德并不为自由意志负责，而是为了形成稳定的社会需要法律和道德</span><br>
</p><p><b>博丽灵梦的御币: </b><br>
<span>群星里的机仆？</span><br>
</p><p><b>hypnossz86: </b><br>
<span> 本帖最后由 hypnossz86 于 2019-10-12 17:00 编辑 </span><br>
<span>没有自由意志的人确实不用对自己的行为负责，但是仍然要承受自己行为带来的后果</span><br>
<span>罪犯如果是被操纵的木偶，那么对罪犯进行惩罚的人自然也是木偶，制定惩罚罪犯规则的人也是木偶</span><br>
<span>大家都是木偶，在演戏而已，多劳和多得都是被决定的特征</span><br>
<span>不影响当前社会的运转</span><br>
</p><p><b>rentrody: </b><br>
<span>埃奈西德穆 发表于 2019-10-12 12:51</span><br>
<span>总结你说的两点：（1）人类的行为不仅仅是基因影响，他还受到文化等社会要素的决定，（2）自由意愿的幻觉 ...</span><br>
<span>自由的本质就是随机性，量子力学已经给了自由一席之地。不过还有一个多世界解释，当所有的选择都是等价的，自由也就失去意义。</span><br>
</p><p><b>yy19: </b><br>
<span> 本帖最后由 yy19 于 2019-10-12 18:03 编辑 </span><br>
<span>hypnossz86 发表于 2019-10-12 16:57</span><br>
<span>没有自由意志的人确实不用对自己的行为负责，但是仍然要承受自己行为带来的后果</span><br>
<span>罪犯如果是被操纵的木偶， ...</span><br>
<span>good，就是这个。</span><br>
<span>演好你自己（的角色）便是，瞎JB俺琢磨个鬼哦</span><br>
</p><p><b>sacodina: </b><br>
<span>哆啦A梦</span><br>
</p><p><b>埃奈西德穆: </b><br>
<span> 本帖最后由 埃奈西德穆 于 2019-10-12 19:50 编辑 </span><br>
<span>rentrody 发表于 2019-10-12 17:29</span><br>
<span>自由的本质就是随机性，量子力学已经给了自由一席之地。不过还有一个多世界解释，当所有的选择都是等价的 ...</span><br>
<span>自由的本质不是随机性。极端的例子，随机性就是你要做X，结果却产生Y，你的行为完全受随机的运气支配。这个和自由不相容。所以，自由不是随机性。说一个人是自由的意味着她能多少控制自己的行动，这样她才能为自己行为负责，而控制蕴含着决定论的要素，而不是随机性。然后，已故的David Lewis确实提过一个所谓的“多世界”解释，即用他可能世界框架对自由的必要条件（you could have done otherwise）做语义分析，然而这估计和你谈的不是一回事。</span><br>
</p><p><b>酷乐: </b><br>
<span>都不看武装神姬的？</span><br>
</p><p><b>埃奈西德穆: </b><br>
<span> 本帖最后由 埃奈西德穆 于 2019-10-12 20:24 编辑 </span><br>
<span>hypnossz86 发表于 2019-10-12 16:57</span><br>
<span>没有自由意志的人确实不用对自己的行为负责，但是仍然要承受自己行为带来的后果</span><br>
<span>罪犯如果是被操纵的木偶， ...</span><br>
<span>混淆了实然和应然。所有人都在做X，不意味着X就是对的。倘若我们都接受没有行为能力或被操纵的人不“应该”受到惩罚，鉴于没有自由意志能力和没有行为能力是一回事，那么没有自由意志的人就不“应该”被惩罚。重要的是：应该不应该这么做。</span><br>
<span>强决定论者有其他策略，但和你说的没关系。以惩罚为例。一般人接受的惩罚观念是“恶有恶报”，这种惩罚观预设了人有决定自己行为的能力。康奈尔的某位教授建议用一套功利主义惩罚观取而代之。这个观点是：一个人应该受到惩罚，如果他对周围社会构成危害。犯罪分子的地位类似传染病患者。传染病人没有犯下任何过错，但为了周围人的健康考虑，我们可以隔离传染病人。同理，犯罪分子也和传染病人一样身不由已，而监狱就是这样的隔离设置。作者进一步提出，尽管我们可以隔离犯人，然而死刑的合理性无法证成：因为杀死传染病人是不公正的，那么杀死犯罪分子也是不公正的。于是，根据这种功利主义惩罚观，惩罚和道德责任完全没关系，就算一个人毫无行为能力，我们也有理由对其进行惩罚。</span><br>
</p><p><b>rentrody: </b><br>
<span>埃奈西德穆 发表于 2019-10-12 19:44</span><br>
<span>自由的本质不是随机性。极端的例子，随机性就是你要做X，结果却产生Y，你的行为完全受随机的运气支配。这 ...</span><br>
<span>“你要做X”，这个决定的产生过程是不是随机的呢？如果不是，那么你的决定就能够被人预测，被人操控，这能称得上自由吗？</span><br>
</p><p><b>埃奈西德穆: </b><br>
<span>rentrody 发表于 2019-10-12 16:10</span><br>
<span>法律和道德并不为自由意志负责，而是为了形成稳定的社会需要法律和道德</span><br>
<span>法律和道德的目的可以和自由没关系（当然，不是所有理论家都这么想）。但让法律和道德运行起来需要有能够遵守法律和道德的人。这种遵守规则的能力就和自由意志有些关系了。</span><br>
</p><p><b>rentrody: </b><br>
<span>埃奈西德穆 发表于 2019-10-12 20:46</span><br>
<span>法律和道德的目的可以和自由没关系（当然，不是所有理论家都这么想）。但让法律和道德运行起来需要有能够 ...</span><br>
<span>你觉得是没有自我意志的机器更容易遵守规则还是人更容易遵守规则呢？</span><br>
</p><p><b>埃奈西德穆: </b><br>
<span>rentrody 发表于 2019-10-12 20:26</span><br>
<span>“你要做X”，这个决定的产生过程是不是随机的呢？如果不是，那么你的决定就能够被人预测，被人操控，这 ...</span><br>
<span>“我要做X”是否随机和自由意志没关系。假定你有三个随机的欲望：</span><br>
<span>（1）我要做X</span><br>
<span>（2）我要做Y</span><br>
<span>（3）我要做Z</span><br>
<span>三个欲望是不是随机无关紧要，重要的是你选择了哪个欲望，你的选择是不是随机的？这里有三种可能：</span><br>
<span>（a）你在三个选项里做出选择，你的选择是随机的。</span><br>
<span>（b）你在三个选项里做出选择，你的选择是被你之外的要素决定的。</span><br>
<span>（c）你在三个选项里做出选择，你的选择是你的意愿决定的。</span><br>
<span>状况（a）中，你不是自由的，因为你还是被某种无法预测的运气操控。（b）也不是，因为那个选择不是由你决定的。只有在（c）状况下，你是自由的，你的选择是你的意愿决定的，同时你的意愿又没有被任何东西决定。</span><br>
</p><p><b>埃奈西德穆: </b><br>
<span>rentrody 发表于 2019-10-12 20:53</span><br>
<span>你觉得是没有自我意志的机器更容易遵守规则还是人更容易遵守规则呢？</span><br>
<span>如果人都是机器就省事了。机器不是根据规则行动，机器是被规则控制而行事。人根据规则行动，她既可以遵守规则也能违背规则，所以我们才能说不遵守规则是有道德过失。倘若机器偏离规则，我们不是认为机器有道德过失，而是认为机器发生了bug。</span><br>
</p><p><b>rentrody: </b><br>
<span> 本帖最后由 rentrody 于 2019-10-12 21:28 编辑 </span><br>
<span>埃奈西德穆 发表于 2019-10-12 21:01</span><br>
<span>“我要做X”是否随机和自由意志没关系。假定你有三个随机的欲望：</span><br>
<span>（1）我要做X</span><br>
<span>（2）我要做Y</span><br>
<span>这所谓的意愿又是从何而来呢？灵魂吗？</span><br>
</p><p><b>埃奈西德穆: </b><br>
<span>rentrody 发表于 2019-10-12 21:22</span><br>
<span>这所谓的意愿又是从何而来呢？</span><br>
<span>首先，自由意志（意愿）的能力就是进行选择的能力。追问这个能力的出身无关紧要。因为就算自由意愿有非自由的来源，难道自由意愿就不自由了？就来源问题，我暂且给个说明。当代心灵理论中有一种主张叫突现论（emergentism）。这种主张认为心灵来源于物质，但是心灵不是物质；心灵从物质中突然出现，这个出现过程无法被解释。我们可用类似方式去解释自由意愿的出现：自由意愿源自没有自由的物质，但它不等同于它的来源，同时我们也不能解释为什么这样的物质世界会产生出自由意愿这东西来。</span><br>
</p><p><b>hypnossz86: </b><br>
<span>埃奈西德穆 发表于 2019-10-12 20:20</span><br>
<span>混淆了实然和应然。所有人都在做X，不意味着X就是对的。倘若我们都接受没有行为能力或被操纵的人不“应该 ...</span><br>
<span>你是怎么从我这段话里总结出我表达了“所有人都在做X所以X就是对的”这么一个意思的....没有自由意志为啥就直接等同没有行为能力了....</span><br>
<span>恶有恶报的惩罚观为什么又是以预设人有决定自己行为能力为前提的？不是很懂你想表达什么....自由意志与法律存在的合理性？</span><br>
<span>顺便人也是和机器一样，是被规则控制了行事的</span><br>
<span>比如你裸眼看不到非可见光，也无法想象它们的颜色，这就是你被设定的规则</span><br>
</p><p><b>siliya: </b><br>
<span>人把ai看作一个高阶形态，先进生产力，走三个表的道路，而不是老想着用落后的生产方式与思维驾驭高级生产力？就像压不住的工人？</span><br>
</p>]]></content:encoded>
      <guid isPermaLink="false">1859057[0-50]</guid>
    </item>
  </channel>
</rss>
